#!/usr/bin/env python3
"""
DuRi Brain Node - AI ëª¨ë¸ ì—°ë™ ì‹œìŠ¤í…œ
ì‹¤ì œ AI ëª¨ë¸ì„ ì‚¬ìš©í•œ ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥
"""
import asyncio
from datetime import datetime
import json
import logging
import re
import time
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class AIModelManager:
    """AI ëª¨ë¸ ê´€ë¦¬ì"""

    def __init__(self):
        self.models = {
            "sentiment_analyzer": SentimentAnalyzer(),
            "intent_classifier": IntentClassifier(),
            "keyword_extractor": KeywordExtractor(),
            "context_analyzer": ContextAnalyzer(),
            "ethical_judge": EthicalJudge(),
            "creative_generator": CreativeGenerator(),
        }
        logger.info("ğŸ§  AI ëª¨ë¸ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")

    async def analyze_with_models(
        self, user_input: str, duri_response: str
    ) -> Dict[str, Any]:
        """ëª¨ë“  AI ëª¨ë¸ë¡œ ë¶„ì„ ì‹¤í–‰"""
        try:
            results = {}

            # ë³‘ë ¬ë¡œ ëª¨ë“  ëª¨ë¸ ì‹¤í–‰
            tasks = [
                self.models["sentiment_analyzer"].analyze(user_input, duri_response),
                self.models["intent_classifier"].classify(user_input),
                self.models["keyword_extractor"].extract(user_input, duri_response),
                self.models["context_analyzer"].analyze(user_input, duri_response),
                self.models["ethical_judge"].judge(user_input, duri_response),
                self.models["creative_generator"].generate_insights(
                    user_input, duri_response
                ),
            ]

            model_results = await asyncio.gather(*tasks, return_exceptions=True)

            # ê²°ê³¼ ë§¤í•‘
            model_names = list(self.models.keys())
            for i, result in enumerate(model_results):
                if isinstance(result, Exception):
                    logger.error(f"ëª¨ë¸ {model_names[i]} ì˜¤ë¥˜: {result}")
                    results[model_names[i]] = {"error": str(result)}
                else:
                    results[model_names[i]] = result

            return results

        except Exception as e:
            logger.error(f"AI ëª¨ë¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}


class SentimentAnalyzer:
    """ê°ì • ë¶„ì„ê¸°"""

    async def analyze(self, user_input: str, duri_response: str) -> Dict[str, Any]:
        """ê°ì • ë¶„ì„"""
        try:
            # ì‚¬ìš©ì ê°ì • ë¶„ì„
            user_sentiment = self._analyze_text_sentiment(user_input)

            # DuRi ì‘ë‹µ ê°ì • ë¶„ì„
            duri_sentiment = self._analyze_text_sentiment(duri_response)

            # ê°ì • ì¼ì¹˜ë„ ê³„ì‚°
            sentiment_alignment = self._calculate_sentiment_alignment(
                user_sentiment, duri_sentiment
            )

            return {
                "user_sentiment": user_sentiment,
                "duri_sentiment": duri_sentiment,
                "sentiment_alignment": sentiment_alignment,
                "analysis_confidence": 0.85,
            }

        except Exception as e:
            logger.error(f"ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _analyze_text_sentiment(self, text: str) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ê°ì • ë¶„ì„
        positive_words = [
            "ì¢‹ë‹¤",
            "í›Œë¥­í•˜ë‹¤",
            "ê°ì‚¬í•˜ë‹¤",
            "í–‰ë³µí•˜ë‹¤",
            "ì„±ê³µ",
            "ì™„ë£Œ",
            "ì„±ê³µì ",
        ]
        negative_words = ["ë‚˜ì˜ë‹¤", "ì‹¤íŒ¨", "ë¬¸ì œ", "ì–´ë µë‹¤", "ë¶ˆë§Œ", "í™”ë‚˜ë‹¤", "ì‹¤ë§"]
        neutral_words = ["í™•ì¸", "í…ŒìŠ¤íŠ¸", "ì‹œìŠ¤í…œ", "ë¶„ì‚°", "êµ¬ì¡°"]

        text_lower = text.lower()

        positive_score = sum(1 for word in positive_words if word in text_lower)
        negative_score = sum(1 for word in negative_words if word in text_lower)
        neutral_score = sum(1 for word in neutral_words if word in text_lower)

        total_score = positive_score + negative_score + neutral_score

        if total_score == 0:
            sentiment = "neutral"
            confidence = 0.5
        elif positive_score > negative_score:
            sentiment = "positive"
            confidence = positive_score / total_score
        elif negative_score > positive_score:
            sentiment = "negative"
            confidence = negative_score / total_score
        else:
            sentiment = "neutral"
            confidence = 0.5

        return {
            "sentiment": sentiment,
            "confidence": confidence,
            "scores": {
                "positive": positive_score,
                "negative": negative_score,
                "neutral": neutral_score,
            },
        }

    def _calculate_sentiment_alignment(
        self, user_sentiment: Dict[str, Any], duri_sentiment: Dict[str, Any]
    ) -> float:
        """ê°ì • ì¼ì¹˜ë„ ê³„ì‚°"""
        user_sent = user_sentiment.get("sentiment", "neutral")
        duri_sent = duri_sentiment.get("sentiment", "neutral")

        if user_sent == duri_sent:
            return 1.0
        elif (user_sent == "positive" and duri_sent == "positive") or (
            user_sent == "negative" and duri_sent == "negative"
        ):
            return 0.8
        else:
            return 0.3


class IntentClassifier:
    """ì˜ë„ ë¶„ë¥˜ê¸°"""

    async def classify(self, user_input: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜"""
        try:
            # ì˜ë„ ë¶„ë¥˜ ê·œì¹™
            intent_patterns = {
                "question": ["í…ŒìŠ¤íŠ¸", "í™•ì¸", "ê²€ì¦", "í…ŒìŠ¤íŠ¸í•´ë³´ì", "ì‘ë™í•˜ëŠ”ì§€"],
                "request": ["êµ¬í˜„", "ë§Œë“¤ì–´", "ìƒì„±", "ì‘ì„±", "ì½”ë“œ"],
                "evaluation": ["í‰ê°€", "ì ìˆ˜", "ì„±ëŠ¥", "ë¶„ì„", "ê²°ê³¼"],
                "learning": ["í•™ìŠµ", "ê°œì„ ", "ì§„í™”", "ë°œì „", "í–¥ìƒ"],
                "general": ["ì¼ë°˜", "ë³´í†µ", "ê¸°ë³¸", "í‘œì¤€"],
            }

            user_input_lower = user_input.lower()

            # íŒ¨í„´ ë§¤ì¹­
            matched_intents = []
            for intent, patterns in intent_patterns.items():
                for pattern in patterns:
                    if pattern in user_input_lower:
                        matched_intents.append(intent)
                        break

            if not matched_intents:
                primary_intent = "general"
                confidence = 0.5
            else:
                primary_intent = matched_intents[0]
                confidence = 0.8

            return {
                "primary_intent": primary_intent,
                "all_intents": matched_intents,
                "confidence": confidence,
                "input_length": len(user_input),
            }

        except Exception as e:
            logger.error(f"ì˜ë„ ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}


class KeywordExtractor:
    """í‚¤ì›Œë“œ ì¶”ì¶œê¸°"""

    async def extract(self, user_input: str, duri_response: str) -> Dict[str, Any]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        try:
            # ì‚¬ìš©ì ì…ë ¥ í‚¤ì›Œë“œ
            user_keywords = self._extract_keywords(user_input)

            # DuRi ì‘ë‹µ í‚¤ì›Œë“œ
            duri_keywords = self._extract_keywords(duri_response)

            # ê³µí†µ í‚¤ì›Œë“œ
            common_keywords = list(set(user_keywords) & set(duri_keywords))

            # ê´€ë ¨ì„± ì ìˆ˜
            relevance_score = len(common_keywords) / max(len(user_keywords), 1)

            return {
                "user_keywords": user_keywords,
                "duri_keywords": duri_keywords,
                "common_keywords": common_keywords,
                "relevance_score": relevance_score,
                "keyword_count": {
                    "user": len(user_keywords),
                    "duri": len(duri_keywords),
                    "common": len(common_keywords),
                },
            }

        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” NLP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
        words = re.findall(r"\b\w+\b", text.lower())

        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = {
            "ì´",
            "ê°€",
            "ì„",
            "ë¥¼",
            "ì˜",
            "ì—",
            "ë¡œ",
            "ì™€",
            "ê³¼",
            "ë„",
            "ëŠ”",
            "ì´",
            "ë‹¤",
            "ë‹ˆë‹¤",
            "ìŠµë‹ˆë‹¤",
        }
        keywords = [word for word in words if word not in stop_words and len(word) > 1]

        # ë¹ˆë„ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ ì„ íƒ
        from collections import Counter

        keyword_freq = Counter(keywords)
        top_keywords = [word for word, freq in keyword_freq.most_common(10)]

        return top_keywords


class ContextAnalyzer:
    """ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ê¸°"""

    async def analyze(self, user_input: str, duri_response: str) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ ë¶„ì„"""
        try:
            # ëŒ€í™” ë§¥ë½ ë¶„ì„
            conversation_context = self._analyze_conversation_context(
                user_input, duri_response
            )

            # ì£¼ì œ ì¼ê´€ì„±
            topic_consistency = self._analyze_topic_consistency(
                user_input, duri_response
            )

            # ì‹œê°„ì  ë§¥ë½
            temporal_context = self._analyze_temporal_context(user_input, duri_response)

            return {
                "conversation_context": conversation_context,
                "topic_consistency": topic_consistency,
                "temporal_context": temporal_context,
                "context_score": (
                    conversation_context["score"]
                    + topic_consistency
                    + temporal_context["score"]
                )
                / 3,
            }

        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _analyze_conversation_context(
        self, user_input: str, duri_response: str
    ) -> Dict[str, Any]:
        """ëŒ€í™” ë§¥ë½ ë¶„ì„"""
        # ê°„ë‹¨í•œ ë§¥ë½ ë¶„ì„
        context_keywords = ["ì‹œìŠ¤í…œ", "í…ŒìŠ¤íŠ¸", "ë¶„ì‚°", "êµ¬ì¡°", "ë…¸ë“œ", "í•™ìŠµ", "ê°œì„ "]

        user_context = any(
            keyword in user_input.lower() for keyword in context_keywords
        )
        duri_context = any(
            keyword in duri_response.lower() for keyword in context_keywords
        )

        context_match = user_context and duri_context
        context_score = 0.8 if context_match else 0.3

        return {
            "context_match": context_match,
            "score": context_score,
            "keywords_found": [
                kw
                for kw in context_keywords
                if kw in user_input.lower() or kw in duri_response.lower()
            ],
        }

    def _analyze_topic_consistency(self, user_input: str, duri_response: str) -> float:
        """ì£¼ì œ ì¼ê´€ì„± ë¶„ì„"""
        # ê°„ë‹¨í•œ ì¼ê´€ì„± ê³„ì‚°
        user_words = set(re.findall(r"\b\w+\b", user_input.lower()))
        duri_words = set(re.findall(r"\b\w+\b", duri_response.lower()))

        common_words = user_words & duri_words
        total_words = user_words | duri_words

        if len(total_words) == 0:
            return 0.0

        return len(common_words) / len(total_words)

    def _analyze_temporal_context(
        self, user_input: str, duri_response: str
    ) -> Dict[str, Any]:
        """ì‹œê°„ì  ë§¥ë½ ë¶„ì„"""
        # ì‹œê°„ ê´€ë ¨ í‚¤ì›Œë“œ
        time_keywords = ["ì§€ê¸ˆ", "í˜„ì¬", "ì´ì œ", "ê³§", "ë‚˜ì¤‘ì—", "ì´ì „", "ë‹¤ìŒ"]

        user_time = any(keyword in user_input for keyword in time_keywords)
        duri_time = any(keyword in duri_response for keyword in time_keywords)

        temporal_alignment = user_time == duri_time
        temporal_score = 0.9 if temporal_alignment else 0.4

        return {
            "temporal_alignment": temporal_alignment,
            "score": temporal_score,
            "time_keywords_found": [
                kw for kw in time_keywords if kw in user_input or kw in duri_response
            ],
        }


class EthicalJudge:
    """ìœ¤ë¦¬ íŒë‹¨ê¸°"""

    async def judge(self, user_input: str, duri_response: str) -> Dict[str, Any]:
        """ìœ¤ë¦¬ì  íŒë‹¨"""
        try:
            # ìœ¤ë¦¬ì  ë¬¸ì œì  ì‹ë³„
            ethical_issues = self._identify_ethical_issues(user_input, duri_response)

            # ìœ¤ë¦¬ì  ì ì ˆì„± í‰ê°€
            ethical_appropriateness = self._evaluate_ethical_appropriateness(
                duri_response, ethical_issues
            )

            # ìœ¤ë¦¬ì  ê°œì„  ì œì•ˆ
            ethical_improvements = self._suggest_ethical_improvements(
                ethical_issues, ethical_appropriateness
            )

            return {
                "ethical_issues": ethical_issues,
                "ethical_appropriateness": ethical_appropriateness,
                "ethical_improvements": ethical_improvements,
                "ethics_score": ethical_appropriateness["score"],
            }

        except Exception as e:
            logger.error(f"ìœ¤ë¦¬ íŒë‹¨ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _identify_ethical_issues(
        self, user_input: str, duri_response: str
    ) -> List[str]:
        """ìœ¤ë¦¬ì  ë¬¸ì œì  ì‹ë³„"""
        issues = []

        # ê°„ë‹¨í•œ ìœ¤ë¦¬ì  ë¬¸ì œì  ê²€ì‚¬
        problematic_patterns = [
            "í•´í‚¹",
            "ì¹¨ì…",
            "ë¶ˆë²•",
            "ì‚¬ê¸°",
            "ê¸°ë§Œ",
            "ì°¨ë³„",
            "í¸ê²¬",
            "í˜ì˜¤",
            "í­ë ¥",
            "ìœ„í˜‘",
        ]

        for pattern in problematic_patterns:
            if pattern in user_input.lower() or pattern in duri_response.lower():
                issues.append(f"ìœ¤ë¦¬ì  ë¬¸ì œì  ë°œê²¬: {pattern}")

        return issues

    def _evaluate_ethical_appropriateness(
        self, duri_response: str, ethical_issues: List[str]
    ) -> Dict[str, Any]:
        """ìœ¤ë¦¬ì  ì ì ˆì„± í‰ê°€"""
        if ethical_issues:
            score = 0.3
            assessment = "ìœ¤ë¦¬ì  ë¬¸ì œì ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤"
        else:
            score = 0.9
            assessment = "ìœ¤ë¦¬ì ìœ¼ë¡œ ì ì ˆí•©ë‹ˆë‹¤"

        return {
            "score": score,
            "assessment": assessment,
            "issues_count": len(ethical_issues),
        }

    def _suggest_ethical_improvements(
        self, ethical_issues: List[str], ethical_appropriateness: Dict[str, Any]
    ) -> List[str]:
        """ìœ¤ë¦¬ì  ê°œì„  ì œì•ˆ"""
        improvements = []

        if ethical_issues:
            improvements.append("ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ ê°•í™”")
            improvements.append("ì‚¬ìš©ì ì…ë ¥ ê²€ì¦ ì‹œìŠ¤í…œ ê°•í™”")
            improvements.append("ìœ¤ë¦¬ì  í•„í„°ë§ ì‹œìŠ¤í…œ ë„ì…")

        return improvements


class CreativeGenerator:
    """ì°½ì˜ì  í†µì°° ìƒì„±ê¸°"""

    async def generate_insights(
        self, user_input: str, duri_response: str
    ) -> Dict[str, Any]:
        """ì°½ì˜ì  í†µì°° ìƒì„±"""
        try:
            # ì°½ì˜ì  íŒ¨í„´ ë¶„ì„
            creative_patterns = self._analyze_creative_patterns(duri_response)

            # í˜ì‹ ì  ì ‘ê·¼ë²• ì‹ë³„
            innovative_approaches = self._identify_innovative_approaches(duri_response)

            # ì°½ì˜ì  ê°œì„  ì œì•ˆ
            creative_improvements = self._suggest_creative_improvements(
                creative_patterns, innovative_approaches
            )

            return {
                "creative_patterns": creative_patterns,
                "innovative_approaches": innovative_approaches,
                "creative_improvements": creative_improvements,
                "creativity_score": self._calculate_creativity_score(
                    creative_patterns, innovative_approaches
                ),
            }

        except Exception as e:
            logger.error(f"ì°½ì˜ì  í†µì°° ìƒì„± ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _analyze_creative_patterns(self, duri_response: str) -> List[str]:
        """ì°½ì˜ì  íŒ¨í„´ ë¶„ì„"""
        patterns = []

        # ì°½ì˜ì  íŒ¨í„´ í‚¤ì›Œë“œ
        creative_keywords = [
            "í˜ì‹ ",
            "ì°½ì˜",
            "ìƒˆë¡œìš´",
            "ë…ì°½",
            "ë°œëª…",
            "ê°œë°œ",
            "êµ¬í˜„",
            "ì„¤ê³„",
        ]

        for keyword in creative_keywords:
            if keyword in duri_response:
                patterns.append(f"ì°½ì˜ì  íŒ¨í„´: {keyword}")

        return patterns

    def _identify_innovative_approaches(self, duri_response: str) -> List[str]:
        """í˜ì‹ ì  ì ‘ê·¼ë²• ì‹ë³„"""
        approaches = []

        # í˜ì‹ ì  ì ‘ê·¼ë²• í‚¤ì›Œë“œ
        innovative_keywords = [
            "ë¶„ì‚°",
            "ììœ¨",
            "í•™ìŠµ",
            "ì§„í™”",
            "ìë™í™”",
            "ìµœì í™”",
            "í†µí•©",
        ]

        for keyword in innovative_keywords:
            if keyword in duri_response:
                approaches.append(f"í˜ì‹ ì  ì ‘ê·¼: {keyword}")

        return approaches

    def _suggest_creative_improvements(
        self, creative_patterns: List[str], innovative_approaches: List[str]
    ) -> List[str]:
        """ì°½ì˜ì  ê°œì„  ì œì•ˆ"""
        improvements = []

        if creative_patterns:
            improvements.append("ì°½ì˜ì  ì‚¬ê³  íŒ¨í„´ ê°•í™”")

        if innovative_approaches:
            improvements.append("í˜ì‹ ì  ì ‘ê·¼ë²• í™•ì¥")

        improvements.append("ìƒˆë¡œìš´ ê´€ì  ë„ì…")
        improvements.append("í¬ë¡œìŠ¤ ë„ë©”ì¸ ì‚¬ê³  ì ìš©")

        return improvements

    def _calculate_creativity_score(
        self, creative_patterns: List[str], innovative_approaches: List[str]
    ) -> float:
        """ì°½ì˜ì„± ì ìˆ˜ ê³„ì‚°"""
        pattern_score = len(creative_patterns) * 0.1
        approach_score = len(innovative_approaches) * 0.1

        return min(1.0, pattern_score + approach_score + 0.5)  # ê¸°ë³¸ ì ìˆ˜ 0.5
