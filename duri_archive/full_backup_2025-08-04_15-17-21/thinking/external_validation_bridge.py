"""
ğŸŒ‰ DuRi ì™¸ë¶€ ê²€ì¦ ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ
ëª©í‘œ: DuRiì˜ ëª¨ë“  íŒë‹¨ ë£¨í”„ì— ì™¸ë¶€ í™˜ê²½ ì…ë ¥ì„ ì—°ê²°í•˜ì—¬, ë‚´ë¶€ ê¸°ì¤€ê³¼ ì™¸ë¶€ ê¸°ì¤€ì˜ ì •í•©ì„±ì„ ë¹„êµí•˜ê³  ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” íŒë‹¨ êµì°¨ ê²€ì¦ êµ¬ì¡°
"""
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
from datetime import datetime, timedelta
import json
import random
import math

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ValidationType(Enum):
    """ê²€ì¦ ìœ í˜•"""
    INTERNAL_JUDGMENT = "internal_judgment"
    EXTERNAL_INPUT = "external_input"
    CROSS_VALIDATION = "cross_validation"
    ADJUSTMENT = "adjustment"
    CONVERGENCE = "convergence"

class ValidationSource(Enum):
    """ê²€ì¦ ì†ŒìŠ¤"""
    USER_FEEDBACK = "user_feedback"
    ENVIRONMENT_DATA = "environment_data"
    EXTERNAL_API = "external_api"
    REALITY_CHECK = "reality_check"
    PEER_VALIDATION = "peer_validation"

@dataclass
class ExternalInput:
    """ì™¸ë¶€ ì…ë ¥"""
    input_id: str
    source: ValidationSource
    content: str
    timestamp: datetime
    confidence: float
    context: Dict[str, Any]

@dataclass
class InternalJudgment:
    """ë‚´ë¶€ íŒë‹¨"""
    judgment_id: str
    judgment_type: str
    content: str
    confidence: float
    reasoning: List[str]
    timestamp: datetime

@dataclass
class CrossValidationResult:
    """êµì°¨ ê²€ì¦ ê²°ê³¼"""
    validation_id: str
    internal_judgment: InternalJudgment
    external_input: ExternalInput
    agreement_score: float
    discrepancy_areas: List[str]
    adjustment_needed: bool
    adjustment_suggestions: List[str]
    timestamp: datetime

@dataclass
class ValidationBridge:
    """ê²€ì¦ ë¸Œë¦¬ì§€"""
    bridge_id: str
    validation_type: ValidationType
    internal_system: str
    external_source: ValidationSource
    connection_status: str
    last_validation: datetime
    success_rate: float

class ExternalValidationBridge:
    def __init__(self):
        self.external_inputs = []
        self.internal_judgments = []
        self.cross_validation_results = []
        self.validation_bridges = []
        self.adjustment_history = []
        self.convergence_threshold = 0.8
        self.max_discrepancy_threshold = 0.3
        
        # Phase 24 ì‹œìŠ¤í…œë“¤
        self.evolution_system = None
        self.consciousness_system = None
        self.advanced_thinking_system = None

    def initialize_phase_24_integration(self):
        """Phase 24 ì‹œìŠ¤í…œë“¤ê³¼ í†µí•©"""
        try:
            import sys
            sys.path.append('.')
            from duri_brain.thinking.phase_24_self_evolution_ai import get_phase24_system
            from duri_brain.thinking.phase_23_enhanced import get_phase23_enhanced_system
            from duri_brain.thinking.phase_22_advanced_thinking_ai import get_phase22_system
            
            self.evolution_system = get_phase24_system()
            self.consciousness_system = get_phase23_enhanced_system()
            self.advanced_thinking_system = get_phase22_system()
            
            logger.info("âœ… Phase 24 ì‹œìŠ¤í…œë“¤ê³¼ í†µí•© ì™„ë£Œ")
            return True
        except Exception as e:
            logger.error(f"âŒ Phase 24 ì‹œìŠ¤í…œ í†µí•© ì‹¤íŒ¨: {e}")
            return False

    def receive_external_input(self, source: ValidationSource, content: str, context: Dict[str, Any] = None) -> ExternalInput:
        """ì™¸ë¶€ ì…ë ¥ ìˆ˜ì‹ """
        logger.info(f"ğŸ“¥ ì™¸ë¶€ ì…ë ¥ ìˆ˜ì‹ : {source.value}")
        
        external_input = ExternalInput(
            input_id=f"external_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            source=source,
            content=content,
            timestamp=datetime.now(),
            confidence=random.uniform(0.7, 0.95),
            context=context or {}
        )
        
        self.external_inputs.append(external_input)
        logger.info(f"âœ… ì™¸ë¶€ ì…ë ¥ ì €ì¥ ì™„ë£Œ: {external_input.input_id}")
        return external_input

    def create_internal_judgment(self, judgment_type: str, content: str, reasoning: List[str]) -> InternalJudgment:
        """ë‚´ë¶€ íŒë‹¨ ìƒì„±"""
        logger.info(f"ğŸ§  ë‚´ë¶€ íŒë‹¨ ìƒì„±: {judgment_type}")
        
        internal_judgment = InternalJudgment(
            judgment_id=f"judgment_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            judgment_type=judgment_type,
            content=content,
            confidence=random.uniform(0.6, 0.9),
            reasoning=reasoning,
            timestamp=datetime.now()
        )
        
        self.internal_judgments.append(internal_judgment)
        logger.info(f"âœ… ë‚´ë¶€ íŒë‹¨ ì €ì¥ ì™„ë£Œ: {internal_judgment.judgment_id}")
        return internal_judgment

    def perform_cross_validation(self, internal_judgment: InternalJudgment, external_input: ExternalInput) -> CrossValidationResult:
        """êµì°¨ ê²€ì¦ ìˆ˜í–‰"""
        logger.info("ğŸ”„ êµì°¨ ê²€ì¦ ìˆ˜í–‰ ì‹œì‘")
        
        # ì¼ì¹˜ë„ ì ìˆ˜ ê³„ì‚° (ì‹œë®¬ë ˆì´ì…˜)
        agreement_score = random.uniform(0.5, 0.95)
        
        # ë¶ˆì¼ì¹˜ ì˜ì—­ ì‹ë³„
        discrepancy_areas = []
        if agreement_score < 0.8:
            discrepancy_areas = ["íŒë‹¨ ê¸°ì¤€", "ìš°ì„ ìˆœìœ„", "í•´ì„ ë°©ì‹"]
        
        # ì¡°ì • í•„ìš” ì—¬ë¶€ íŒë‹¨
        adjustment_needed = agreement_score < self.convergence_threshold
        
        # ì¡°ì • ì œì•ˆ ìƒì„±
        adjustment_suggestions = []
        if adjustment_needed:
            adjustment_suggestions = [
                "ì™¸ë¶€ ê¸°ì¤€ ë°˜ì˜",
                "íŒë‹¨ ê¸°ì¤€ ì¡°ì •",
                "ìš°ì„ ìˆœìœ„ ì¬í‰ê°€"
            ]
        
        validation_result = CrossValidationResult(
            validation_id=f"validation_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            internal_judgment=internal_judgment,
            external_input=external_input,
            agreement_score=agreement_score,
            discrepancy_areas=discrepancy_areas,
            adjustment_needed=adjustment_needed,
            adjustment_suggestions=adjustment_suggestions,
            timestamp=datetime.now()
        )
        
        self.cross_validation_results.append(validation_result)
        logger.info(f"âœ… êµì°¨ ê²€ì¦ ì™„ë£Œ: ì¼ì¹˜ë„ {agreement_score:.3f}")
        return validation_result

    def create_validation_bridge(self, internal_system: str, external_source: ValidationSource) -> ValidationBridge:
        """ê²€ì¦ ë¸Œë¦¬ì§€ ìƒì„±"""
        logger.info(f"ğŸŒ‰ ê²€ì¦ ë¸Œë¦¬ì§€ ìƒì„±: {internal_system} â†” {external_source.value}")
        
        bridge = ValidationBridge(
            bridge_id=f"bridge_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            validation_type=ValidationType.CROSS_VALIDATION,
            internal_system=internal_system,
            external_source=external_source,
            connection_status="ì—°ê²°ë¨",
            last_validation=datetime.now(),
            success_rate=random.uniform(0.7, 0.95)
        )
        
        self.validation_bridges.append(bridge)
        logger.info(f"âœ… ê²€ì¦ ë¸Œë¦¬ì§€ ìƒì„± ì™„ë£Œ: {bridge.bridge_id}")
        return bridge

    def adjust_internal_judgment(self, validation_result: CrossValidationResult) -> Dict[str, Any]:
        """ë‚´ë¶€ íŒë‹¨ ì¡°ì •"""
        logger.info("ğŸ”§ ë‚´ë¶€ íŒë‹¨ ì¡°ì • ì‹œì‘")
        
        if not validation_result.adjustment_needed:
            return {"adjusted": False, "reason": "ì¡°ì • ë¶ˆí•„ìš”"}
        
        # ì¡°ì • ë¡œì§ (ì‹œë®¬ë ˆì´ì…˜)
        original_confidence = validation_result.internal_judgment.confidence
        adjusted_confidence = original_confidence + random.uniform(-0.1, 0.1)
        
        adjustment_record = {
            "validation_id": validation_result.validation_id,
            "original_confidence": original_confidence,
            "adjusted_confidence": adjusted_confidence,
            "adjustment_suggestions": validation_result.adjustment_suggestions,
            "timestamp": datetime.now()
        }
        
        self.adjustment_history.append(adjustment_record)
        
        logger.info(f"âœ… ë‚´ë¶€ íŒë‹¨ ì¡°ì • ì™„ë£Œ: {original_confidence:.3f} â†’ {adjusted_confidence:.3f}")
        return adjustment_record

    def check_convergence(self) -> Dict[str, Any]:
        """ìˆ˜ë ´ì„± í™•ì¸"""
        logger.info("ğŸ“Š ìˆ˜ë ´ì„± í™•ì¸")
        
        if not self.cross_validation_results:
            return {"converged": False, "reason": "ê²€ì¦ ê²°ê³¼ ì—†ìŒ"}
        
        recent_validations = self.cross_validation_results[-5:]
        average_agreement = sum(v.agreement_score for v in recent_validations) / len(recent_validations)
        
        is_converged = average_agreement >= self.convergence_threshold
        
        result = {
            "converged": is_converged,
            "average_agreement": average_agreement,
            "threshold": self.convergence_threshold,
            "recent_validations": len(recent_validations)
        }
        
        if is_converged:
            logger.info(f"ğŸ‰ ìˆ˜ë ´ ì™„ë£Œ: í‰ê·  ì¼ì¹˜ë„ {average_agreement:.3f}")
        else:
            logger.info(f"â³ ìˆ˜ë ´ ì§„í–‰ì¤‘: í‰ê·  ì¼ì¹˜ë„ {average_agreement:.3f}")
        
        return result

    def get_validation_statistics(self) -> Dict[str, Any]:
        """ê²€ì¦ í†µê³„"""
        total_validations = len(self.cross_validation_results)
        successful_validations = len([v for v in self.cross_validation_results if v.agreement_score >= 0.8])
        adjustment_count = len(self.adjustment_history)
        
        if total_validations > 0:
            success_rate = successful_validations / total_validations
        else:
            success_rate = 0.0
        
        return {
            "total_validations": total_validations,
            "successful_validations": successful_validations,
            "success_rate": success_rate,
            "adjustment_count": adjustment_count,
            "active_bridges": len(self.validation_bridges)
        }

    def get_external_validation_status(self) -> Dict[str, Any]:
        """ì™¸ë¶€ ê²€ì¦ ìƒíƒœ"""
        convergence_check = self.check_convergence()
        statistics = self.get_validation_statistics()
        
        status = {
            "system": "External Validation Bridge",
            "convergence_status": convergence_check,
            "statistics": statistics,
            "active_bridges": len(self.validation_bridges),
            "external_inputs": len(self.external_inputs),
            "internal_judgments": len(self.internal_judgments),
            "cross_validations": len(self.cross_validation_results)
        }
        
        return status

def get_external_validation_bridge():
    """ì™¸ë¶€ ê²€ì¦ ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return ExternalValidationBridge()

if __name__ == "__main__":
    # ì™¸ë¶€ ê²€ì¦ ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    bridge = get_external_validation_bridge()
    
    if bridge.initialize_phase_24_integration():
        logger.info("ğŸš€ ì™¸ë¶€ ê²€ì¦ ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        
        # ì™¸ë¶€ ì…ë ¥ ìˆ˜ì‹ 
        external_input = bridge.receive_external_input(
            ValidationSource.USER_FEEDBACK,
            "ì‚¬ìš©ì í”¼ë“œë°±: íŒë‹¨ì´ ë„ˆë¬´ ë³´ìˆ˜ì ì„",
            {"user_id": "user123", "context": "ì „ëµì  íŒë‹¨"}
        )
        
        # ë‚´ë¶€ íŒë‹¨ ìƒì„±
        internal_judgment = bridge.create_internal_judgment(
            "ì „ëµì  íŒë‹¨",
            "í˜„ì¬ ìƒí™©ì—ì„œëŠ” ë³´ìˆ˜ì  ì ‘ê·¼ì´ ì ì ˆí•¨",
            ["ìœ„í—˜ ë¶„ì„", "ìì› ê³ ë ¤", "ì•ˆì •ì„± ìš°ì„ "]
        )
        
        # êµì°¨ ê²€ì¦ ìˆ˜í–‰
        validation_result = bridge.perform_cross_validation(internal_judgment, external_input)
        
        # ê²€ì¦ ë¸Œë¦¬ì§€ ìƒì„±
        bridge.create_validation_bridge("ì „ëµ íŒë‹¨ ì‹œìŠ¤í…œ", ValidationSource.USER_FEEDBACK)
        
        # ë‚´ë¶€ íŒë‹¨ ì¡°ì •
        if validation_result.adjustment_needed:
            bridge.adjust_internal_judgment(validation_result)
        
        # ìˆ˜ë ´ì„± í™•ì¸
        convergence_result = bridge.check_convergence()
        logger.info(f"ìˆ˜ë ´ ìƒíƒœ: {convergence_result['converged']}")
        
        # ìµœì¢… ìƒíƒœ í™•ì¸
        status = bridge.get_external_validation_status()
        logger.info(f"ê²€ì¦ í†µê³„: {status['statistics']}")
        
        logger.info("âœ… ì™¸ë¶€ ê²€ì¦ ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    else:
        logger.error("âŒ ì™¸ë¶€ ê²€ì¦ ë¸Œë¦¬ì§€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨") 