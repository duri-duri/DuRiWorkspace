"""
DuRi ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ

ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘, ì €ì¥, ë¶„ì„í•˜ì—¬ ë¦¬íŒ©í„°ë§ ì˜ˆì¸¡ì— í™œìš©í•©ë‹ˆë‹¤.
"""

import json
import logging
import sqlite3
import threading
import time
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


class PerformanceMetric(Enum):
    """ì„±ëŠ¥ ì§€í‘œ ìœ í˜•"""

    CPU_USAGE = "cpu_usage"
    MEMORY_USAGE = "memory_usage"
    RESPONSE_TIME = "response_time"
    ERROR_RATE = "error_rate"
    LEARNING_CYCLE_TIME = "learning_cycle_time"
    MEMORY_GROWTH_RATE = "memory_growth_rate"
    SYSTEM_COMPLEXITY = "system_complexity"


@dataclass
class PerformanceSnapshot:
    """ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ·"""

    timestamp: datetime
    metrics: Dict[str, float]
    module_name: str
    operation_type: str
    duration_ms: float
    success: bool
    error_message: Optional[str] = None


@dataclass
class PerformanceTrend:
    """ì„±ëŠ¥ ê²½í–¥"""

    metric_name: str
    start_time: datetime
    end_time: datetime
    initial_value: float
    final_value: float
    change_rate: float  # ë³€í™”ìœ¨ (%)
    trend_direction: str  # "improving", "degrading", "stable"
    confidence: float  # ì‹ ë¢°ë„ (0.0 ~ 1.0)


class PerformanceHistory:
    """DuRi ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self, db_path: str = "duri_performance.db"):
        """PerformanceHistory ì´ˆê¸°í™”"""
        self.db_path = db_path
        self.snapshots: List[PerformanceSnapshot] = []
        self.trends: List[PerformanceTrend] = []
        self.is_collecting = False
        self.collection_thread: Optional[threading.Thread] = None

        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        self._init_database()

        # ìˆ˜ì§‘ ì„¤ì •
        self.collection_interval = 30  # 30ì´ˆë§ˆë‹¤ ìˆ˜ì§‘
        self.max_history_days = 30  # 30ì¼ê°„ ë³´ê´€
        self.trend_analysis_window = 24  # 24ì‹œê°„ ìœˆë„ìš°ë¡œ ê²½í–¥ ë¶„ì„

        logger.info("PerformanceHistory ì´ˆê¸°í™” ì™„ë£Œ")

    def _init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ· í…Œì´ë¸”
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS performance_snapshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    module_name TEXT NOT NULL,
                    operation_type TEXT NOT NULL,
                    duration_ms REAL NOT NULL,
                    success INTEGER NOT NULL,
                    error_message TEXT,
                    metrics TEXT NOT NULL
                )
            """
            )

            # ì„±ëŠ¥ ê²½í–¥ í…Œì´ë¸”
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS performance_trends (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    metric_name TEXT NOT NULL,
                    start_time TEXT NOT NULL,
                    end_time TEXT NOT NULL,
                    initial_value REAL NOT NULL,
                    final_value REAL NOT NULL,
                    change_rate REAL NOT NULL,
                    trend_direction TEXT NOT NULL,
                    confidence REAL NOT NULL
                )
            """
            )

            conn.commit()
            conn.close()
            logger.info("ì„±ëŠ¥ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def start_collection(self):
        """ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
        if self.is_collecting:
            logger.warning("ì´ë¯¸ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤.")
            return

        self.is_collecting = True
        self.collection_thread = threading.Thread(
            target=self._collection_loop, daemon=True
        )
        self.collection_thread.start()
        logger.info("ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")

    def stop_collection(self):
        """ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ì„ ì¤‘ì§€í•©ë‹ˆë‹¤."""
        self.is_collecting = False
        if self.collection_thread:
            self.collection_thread.join(timeout=5)
        logger.info("ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì§€")

    def _collection_loop(self):
        """ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ ë£¨í”„"""
        while self.is_collecting:
            try:
                # í˜„ì¬ ì„±ëŠ¥ ìƒíƒœ ìˆ˜ì§‘
                current_metrics = self._collect_current_metrics()

                # ìŠ¤ëƒ…ìƒ· ìƒì„±
                snapshot = PerformanceSnapshot(
                    timestamp=datetime.now(),
                    metrics=current_metrics,
                    module_name="system_overview",
                    operation_type="periodic_collection",
                    duration_ms=0.0,
                    success=True,
                )

                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                self._save_snapshot(snapshot)

                # ê²½í–¥ ë¶„ì„ (24ì‹œê°„ë§ˆë‹¤)
                if self._should_analyze_trends():
                    self._analyze_performance_trends()

                # ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ (7ì¼ë§ˆë‹¤)
                if self._should_cleanup_old_data():
                    self._cleanup_old_data()

                time.sleep(self.collection_interval)

            except Exception as e:
                logger.error(f"ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
                time.sleep(5)  # ì˜¤ë¥˜ ì‹œ ì ì‹œ ëŒ€ê¸°

    def _collect_current_metrics(self) -> Dict[str, float]:
        """í˜„ì¬ ì„±ëŠ¥ ì§€í‘œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        import psutil

        try:
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            memory_percent = memory.percent

            # DuRi íŠ¹í™” ë©”íŠ¸ë¦­ (ì‹œë®¬ë ˆì´ì…˜)
            learning_cycle_time = self._get_learning_cycle_time()
            error_rate = self._get_error_rate()
            memory_growth_rate = self._get_memory_growth_rate()
            system_complexity = self._get_system_complexity()

            return {
                PerformanceMetric.CPU_USAGE.value: cpu_percent,
                PerformanceMetric.MEMORY_USAGE.value: memory_percent,
                PerformanceMetric.LEARNING_CYCLE_TIME.value: learning_cycle_time,
                PerformanceMetric.ERROR_RATE.value: error_rate,
                PerformanceMetric.MEMORY_GROWTH_RATE.value: memory_growth_rate,
                PerformanceMetric.SYSTEM_COMPLEXITY.value: system_complexity,
            }

        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}

    def _get_learning_cycle_time(self) -> float:
        """í•™ìŠµ ì‚¬ì´í´ ì‹œê°„ì„ ì¸¡ì •í•©ë‹ˆë‹¤."""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LearningLoopManagerì—ì„œ ê°€ì ¸ì˜´
        return 2.5  # ì‹œë®¬ë ˆì´ì…˜ ê°’

    def _get_error_rate(self) -> float:
        """ì˜¤ë¥˜ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë¡œê·¸ ë¶„ì„ì„ í†µí•´ ê³„ì‚°
        return 0.02  # 2% ì‹œë®¬ë ˆì´ì…˜

    def _get_memory_growth_rate(self) -> float:
        """ë©”ëª¨ë¦¬ ì„±ì¥ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë³€í™”ìœ¨ ê³„ì‚°
        return 0.05  # 5% ì‹œë®¬ë ˆì´ì…˜

    def _get_system_complexity(self) -> float:
        """ì‹œìŠ¤í…œ ë³µì¡ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ëª¨ë“ˆ ìˆ˜, í•¨ìˆ˜ ìˆ˜ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
        return 0.75  # 75% ì‹œë®¬ë ˆì´ì…˜

    def _save_snapshot(self, snapshot: PerformanceSnapshot):
        """ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ·ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT INTO performance_snapshots
                (timestamp, module_name, operation_type, duration_ms, success, error_message, metrics)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    snapshot.timestamp.isoformat(),
                    snapshot.module_name,
                    snapshot.operation_type,
                    snapshot.duration_ms,
                    1 if snapshot.success else 0,
                    snapshot.error_message,
                    json.dumps(snapshot.metrics),
                ),
            )

            conn.commit()
            conn.close()

        except Exception as e:
            logger.error(f"ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨: {e}")

    def _should_analyze_trends(self) -> bool:
        """ê²½í–¥ ë¶„ì„ì´ í•„ìš”í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        # 24ì‹œê°„ë§ˆë‹¤ ë¶„ì„
        return True  # ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•´ í•­ìƒ True

    def _should_cleanup_old_data(self) -> bool:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ê°€ í•„ìš”í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        # 7ì¼ë§ˆë‹¤ ì •ë¦¬
        return False  # ì‹œë®¬ë ˆì´ì…˜ì„ ìœ„í•´ False

    def _analyze_performance_trends(self):
        """ì„±ëŠ¥ ê²½í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        try:
            # ìµœê·¼ 24ì‹œê°„ ë°ì´í„° ì¡°íšŒ
            end_time = datetime.now()
            start_time = end_time - timedelta(hours=self.trend_analysis_window)

            trends = self._calculate_trends(start_time, end_time)

            # ê²½í–¥ ì €ì¥
            for trend in trends:
                self._save_trend(trend)

            logger.info(f"ì„±ëŠ¥ ê²½í–¥ ë¶„ì„ ì™„ë£Œ: {len(trends)}ê°œ ì§€í‘œ")

        except Exception as e:
            logger.error(f"ê²½í–¥ ë¶„ì„ ì‹¤íŒ¨: {e}")

    def _calculate_trends(
        self, start_time: datetime, end_time: datetime
    ) -> List[PerformanceTrend]:
        """íŠ¹ì • ê¸°ê°„ì˜ ì„±ëŠ¥ ê²½í–¥ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        trends = []

        # ê° ì„±ëŠ¥ ì§€í‘œë³„ë¡œ ê²½í–¥ ê³„ì‚°
        for metric in PerformanceMetric:
            try:
                trend = self._calculate_metric_trend(metric.value, start_time, end_time)
                if trend:
                    trends.append(trend)
            except Exception as e:
                logger.error(f"{metric.value} ê²½í–¥ ê³„ì‚° ì‹¤íŒ¨: {e}")

        return trends

    def _calculate_metric_trend(
        self, metric_name: str, start_time: datetime, end_time: datetime
    ) -> Optional[PerformanceTrend]:
        """íŠ¹ì • ì§€í‘œì˜ ê²½í–¥ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ì‹œì‘ê³¼ ë ê°’ ì¡°íšŒ
            cursor.execute(
                """
                SELECT metrics FROM performance_snapshots
                WHERE timestamp BETWEEN ? AND ?
                ORDER BY timestamp
            """,
                (start_time.isoformat(), end_time.isoformat()),
            )

            rows = cursor.fetchall()
            if len(rows) < 2:
                return None

            # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ê°’ ì¶”ì¶œ
            first_metrics = json.loads(rows[0][0])
            last_metrics = json.loads(rows[-1][0])

            initial_value = first_metrics.get(metric_name, 0.0)
            final_value = last_metrics.get(metric_name, 0.0)

            # ë³€í™”ìœ¨ ê³„ì‚°
            if initial_value != 0:
                change_rate = ((final_value - initial_value) / initial_value) * 100
            else:
                change_rate = 0.0

            # ê²½í–¥ ë°©í–¥ ê²°ì •
            if change_rate > 5:
                trend_direction = "degrading"
            elif change_rate < -5:
                trend_direction = "improving"
            else:
                trend_direction = "stable"

            # ì‹ ë¢°ë„ ê³„ì‚° (ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ ê¸°ë°˜)
            confidence = min(len(rows) / 100.0, 1.0)

            conn.close()

            return PerformanceTrend(
                metric_name=metric_name,
                start_time=start_time,
                end_time=end_time,
                initial_value=initial_value,
                final_value=final_value,
                change_rate=change_rate,
                trend_direction=trend_direction,
                confidence=confidence,
            )

        except Exception as e:
            logger.error(f"{metric_name} ê²½í–¥ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return None

    def _save_trend(self, trend: PerformanceTrend):
        """ì„±ëŠ¥ ê²½í–¥ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT INTO performance_trends
                (metric_name, start_time, end_time, initial_value, final_value,
                 change_rate, trend_direction, confidence)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    trend.metric_name,
                    trend.start_time.isoformat(),
                    trend.end_time.isoformat(),
                    trend.initial_value,
                    trend.final_value,
                    trend.change_rate,
                    trend.trend_direction,
                    trend.confidence,
                ),
            )

            conn.commit()
            conn.close()

        except Exception as e:
            logger.error(f"ê²½í–¥ ì €ì¥ ì‹¤íŒ¨: {e}")

    def get_recent_trends(self, hours: int = 24) -> List[PerformanceTrend]:
        """ìµœê·¼ ê²½í–¥ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            end_time = datetime.now()
            start_time = end_time - timedelta(hours=hours)

            cursor.execute(
                """
                SELECT metric_name, start_time, end_time, initial_value, final_value,
                       change_rate, trend_direction, confidence
                FROM performance_trends
                WHERE end_time >= ?
                ORDER BY end_time DESC
            """,
                (start_time.isoformat(),),
            )

            trends = []
            for row in cursor.fetchall():
                trend = PerformanceTrend(
                    metric_name=row[0],
                    start_time=datetime.fromisoformat(row[1]),
                    end_time=datetime.fromisoformat(row[2]),
                    initial_value=row[3],
                    final_value=row[4],
                    change_rate=row[5],
                    trend_direction=row[6],
                    confidence=row[7],
                )
                trends.append(trend)

            conn.close()
            return trends

        except Exception as e:
            logger.error(f"ìµœê·¼ ê²½í–¥ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            recent_trends = self.get_recent_trends(24)

            # ê²½ê³  ì§€í‘œ ì‹ë³„
            warning_metrics = [
                trend
                for trend in recent_trends
                if trend.trend_direction == "degrading" and trend.confidence > 0.7
            ]

            # ê°œì„  ì§€í‘œ ì‹ë³„
            improving_metrics = [
                trend
                for trend in recent_trends
                if trend.trend_direction == "improving" and trend.confidence > 0.7
            ]

            return {
                "total_trends": len(recent_trends),
                "warning_metrics": len(warning_metrics),
                "improving_metrics": len(improving_metrics),
                "warning_details": [
                    {
                        "metric": trend.metric_name,
                        "change_rate": f"{trend.change_rate:.1f}%",
                        "confidence": f"{trend.confidence:.1f}",
                    }
                    for trend in warning_metrics
                ],
                "improving_details": [
                    {
                        "metric": trend.metric_name,
                        "change_rate": f"{trend.change_rate:.1f}%",
                        "confidence": f"{trend.confidence:.1f}",
                    }
                    for trend in improving_metrics
                ],
            }

        except Exception as e:
            logger.error(f"ì„±ëŠ¥ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_performance_history: Optional[PerformanceHistory] = None


def get_performance_history() -> PerformanceHistory:
    """PerformanceHistory ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    global _performance_history
    if _performance_history is None:
        _performance_history = PerformanceHistory()
    return _performance_history


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    history = get_performance_history()
    history.start_collection()

    print("ğŸ“Š ì„±ëŠ¥ íˆìŠ¤í† ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("â° 30ì´ˆê°„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")

    time.sleep(30)

    summary = history.get_performance_summary()
    print(f"ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½: {summary}")

    history.stop_collection()
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
