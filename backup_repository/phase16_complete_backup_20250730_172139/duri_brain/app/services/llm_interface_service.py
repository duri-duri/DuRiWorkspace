#!/usr/bin/env python3
"""
LLMInterface - Phase 11
LLM ì¸í„°í˜ì´ìŠ¤ ì‹œìŠ¤í…œ

ê¸°ëŠ¥:
- ChatGPT, Claude, Gemini ë“± LLM í†µí•©
- ê°€ì¡± ë§¥ë½ì— ë§ëŠ” ì§ˆë¬¸ ìƒì„± ë° ì‘ë‹µ ì²˜ë¦¬
- í•™ìŠµ ë³´ì¡° ë° ëŒ€í™” ì§€ì›
- ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ë° í•„í„°ë§
"""

import logging
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime
import json
import requests
import time

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMProvider(Enum):
    """LLM ì œê³µì"""
    CHATGPT = "chatgpt"
    CLAUDE = "claude"
    GEMINI = "gemini"
    LOCAL = "local"

class QueryType(Enum):
    """ì§ˆë¬¸ ìœ í˜•"""
    LEARNING_HELP = "learning_help"
    FAMILY_ADVICE = "family_advice"
    EMOTIONAL_SUPPORT = "emotional_support"
    CREATIVE_INSPIRATION = "creative_inspiration"
    KNOWLEDGE_QUESTION = "knowledge_question"
    OTHER = "other"

class ResponseQuality(Enum):
    """ì‘ë‹µ í’ˆì§ˆ"""
    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"

@dataclass
class LLMQuery:
    """LLM ì§ˆë¬¸"""
    id: str
    query_type: QueryType
    question: str
    family_context: Dict[str, Any]
    provider: LLMProvider
    timestamp: datetime
    additional_context: Optional[str] = None

@dataclass
class LLMResponse:
    """LLM ì‘ë‹µ"""
    id: str
    query_id: str
    provider: LLMProvider
    response_text: str
    response_quality: ResponseQuality
    confidence_score: float
    processing_time_seconds: float
    timestamp: datetime
    family_relevance_score: float = 0.0
    notes: Optional[str] = None

@dataclass
class LLMProviderConfig:
    """LLM ì œê³µì ì„¤ì •"""
    provider: LLMProvider
    api_key: Optional[str] = None
    api_url: Optional[str] = None
    model_name: str = ""
    max_tokens: int = 1000
    temperature: float = 0.7
    is_active: bool = True

class LLMInterface:
    """LLM ì¸í„°í˜ì´ìŠ¤ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.provider_configs: Dict[LLMProvider, LLMProviderConfig] = {}
        self.queries: List[LLMQuery] = []
        self.responses: List[LLMResponse] = []
        self.family_context: Dict[str, Any] = {}
        
        # ê¸°ë³¸ ì œê³µì ì„¤ì •
        self._initialize_default_providers()
        
        logger.info("LLMInterface ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_default_providers(self):
        """ê¸°ë³¸ ì œê³µì ì„¤ì • ì´ˆê¸°í™”"""
        # ChatGPT ì„¤ì • (ì‹¤ì œ API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        self.provider_configs[LLMProvider.CHATGPT] = LLMProviderConfig(
            provider=LLMProvider.CHATGPT,
            api_key=None,  # ì‹¤ì œ êµ¬í˜„ì‹œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
            api_url="https://api.openai.com/v1/chat/completions",
            model_name="gpt-4",
            max_tokens=1000,
            temperature=0.7,
            is_active=True
        )
        
        # Claude ì„¤ì •
        self.provider_configs[LLMProvider.CLAUDE] = LLMProviderConfig(
            provider=LLMProvider.CLAUDE,
            api_key=None,  # ì‹¤ì œ êµ¬í˜„ì‹œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
            api_url="https://api.anthropic.com/v1/messages",
            model_name="claude-3-sonnet",
            max_tokens=1000,
            temperature=0.7,
            is_active=True
        )
        
        # Gemini ì„¤ì •
        self.provider_configs[LLMProvider.GEMINI] = LLMProviderConfig(
            provider=LLMProvider.GEMINI,
            api_key=None,  # ì‹¤ì œ êµ¬í˜„ì‹œ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
            api_url="https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent",
            model_name="gemini-pro",
            max_tokens=1000,
            temperature=0.7,
            is_active=True
        )
        
        # ë¡œì»¬ ëª¨ë¸ ì„¤ì • (ì‹œë®¬ë ˆì´ì…˜ìš©)
        self.provider_configs[LLMProvider.LOCAL] = LLMProviderConfig(
            provider=LLMProvider.LOCAL,
            api_key=None,
            api_url="http://localhost:8000/generate",
            model_name="local-model",
            max_tokens=1000,
            temperature=0.7,
            is_active=True
        )
    
    def add_provider_config(self, config: LLMProviderConfig):
        """LLM ì œê³µì ì„¤ì • ì¶”ê°€"""
        try:
            self.provider_configs[config.provider] = config
            logger.info(f"LLM ì œê³µì ì„¤ì • ì¶”ê°€: {config.provider.value}")
        except Exception as e:
            logger.error(f"LLM ì œê³µì ì„¤ì • ì¶”ê°€ ì‹¤íŒ¨: {e}")
            raise
    
    def create_family_context_prompt(self, family_context: Dict[str, Any]) -> str:
        """ê°€ì¡± ë§¥ë½ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        prompt = "ë‹¹ì‹ ì€ ê°€ì¡± ì¤‘ì‹¬ AI DuRiì…ë‹ˆë‹¤. ë‹¤ìŒ ê°€ì¡± ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:\n\n"
        
        if family_context:
            if 'family_type' in family_context:
                prompt += f"ê°€ì¡± ìœ í˜•: {family_context['family_type']}\n"
            if 'children_count' in family_context:
                prompt += f"ìë…€ ìˆ˜: {family_context['children_count']}ëª…\n"
            if 'children_ages' in family_context:
                ages = family_context['children_ages']
                prompt += f"ìë…€ ë‚˜ì´: {', '.join(map(str, ages))}ì„¸\n"
            if 'family_values' in family_context:
                values = family_context['family_values']
                prompt += f"ê°€ì¡± ê°€ì¹˜ê´€: {', '.join(values)}\n"
        
        prompt += "\nê°€ì¡±ì˜ ë³µì§€ì™€ ì¡°í™”ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”."
        return prompt
    
    def ask_llm(self, question: str, query_type: QueryType, family_context: Dict[str, Any] = None, provider: LLMProvider = LLMProvider.CHATGPT) -> LLMResponse:
        """LLMì— ì§ˆë¬¸í•˜ê¸°"""
        try:
            # ì§ˆë¬¸ ìƒì„±
            query_id = f"query_{len(self.queries) + 1}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            llm_query = LLMQuery(
                id=query_id,
                query_type=query_type,
                question=question,
                family_context=family_context or {},
                provider=provider,
                timestamp=datetime.now()
            )
            
            self.queries.append(llm_query)
            logger.info(f"LLM ì§ˆë¬¸ ìƒì„±: {query_id}")
            
            # ì œê³µì ì„¤ì • í™•ì¸
            if provider not in self.provider_configs:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM ì œê³µì: {provider.value}")
            
            config = self.provider_configs[provider]
            if not config.is_active:
                raise ValueError(f"ë¹„í™œì„±í™”ëœ LLM ì œê³µì: {provider.value}")
            
            # ì‘ë‹µ ìƒì„± ì‹œì‘ ì‹œê°„
            start_time = time.time()
            
            # ì‹¤ì œ LLM í˜¸ì¶œ (ì‹œë®¬ë ˆì´ì…˜)
            response_text = self._simulate_llm_response(question, query_type, family_context, provider)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            processing_time = time.time() - start_time
            
            # ì‘ë‹µ í’ˆì§ˆ í‰ê°€
            response_quality = self._evaluate_response_quality(response_text, query_type)
            
            # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°
            confidence_score = self._calculate_confidence_score(response_text, query_type)
            
            # ê°€ì¡± ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°
            family_relevance_score = self._calculate_family_relevance_score(response_text, family_context)
            
            # ì‘ë‹µ ìƒì„±
            response_id = f"response_{len(self.responses) + 1}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            llm_response = LLMResponse(
                id=response_id,
                query_id=query_id,
                provider=provider,
                response_text=response_text,
                response_quality=response_quality,
                confidence_score=confidence_score,
                processing_time_seconds=processing_time,
                timestamp=datetime.now(),
                family_relevance_score=family_relevance_score
            )
            
            self.responses.append(llm_response)
            logger.info(f"LLM ì‘ë‹µ ìƒì„±: {response_id}")
            
            return llm_response
            
        except Exception as e:
            logger.error(f"LLM ì§ˆë¬¸ ì‹¤íŒ¨: {e}")
            raise
    
    def _simulate_llm_response(self, question: str, query_type: QueryType, family_context: Dict[str, Any], provider: LLMProvider) -> str:
        """LLM ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ êµ¬í˜„ì‹œ ì‹¤ì œ API í˜¸ì¶œ)"""
        # ê°€ì¡± ë§¥ë½ í”„ë¡¬í”„íŠ¸ ìƒì„±
        family_prompt = self.create_family_context_prompt(family_context)
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ
        if query_type == QueryType.LEARNING_HELP:
            return f"{family_prompt}\n\ní•™ìŠµ ë„ì›€ë§: {question}ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. ê°€ì¡±ê³¼ í•¨ê»˜ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì œì•ˆí•©ë‹ˆë‹¤."
        elif query_type == QueryType.FAMILY_ADVICE:
            return f"{family_prompt}\n\nê°€ì¡± ì¡°ì–¸: {question}ì— ëŒ€í•´ ê°€ì¡±ì˜ ì¡°í™”ë¥¼ ê³ ë ¤í•œ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤."
        elif query_type == QueryType.EMOTIONAL_SUPPORT:
            return f"{family_prompt}\n\nì •ì„œì  ì§€ì›: {question}ì— ëŒ€í•´ ê³µê°ê³¼ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤."
        elif query_type == QueryType.CREATIVE_INSPIRATION:
            return f"{family_prompt}\n\nì°½ì˜ì  ì˜ê°: {question}ì— ëŒ€í•´ ê°€ì¡±ê³¼ í•¨ê»˜í•  ìˆ˜ ìˆëŠ” ì°½ì˜ì  ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤."
        elif query_type == QueryType.KNOWLEDGE_QUESTION:
            return f"{family_prompt}\n\nì§€ì‹ ì§ˆë¬¸: {question}ì— ëŒ€í•œ ì •í™•í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
        else:
            return f"{family_prompt}\n\nì¼ë°˜ ì‘ë‹µ: {question}ì— ëŒ€í•œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤."
    
    def _evaluate_response_quality(self, response_text: str, query_type: QueryType) -> ResponseQuality:
        """ì‘ë‹µ í’ˆì§ˆ í‰ê°€"""
        # ê°„ë‹¨í•œ í’ˆì§ˆ í‰ê°€ (ì‹¤ì œ êµ¬í˜„ì‹œ ë” ì •êµí•œ í‰ê°€ í•„ìš”)
        word_count = len(response_text.split())
        
        if word_count > 100 and any(word in response_text.lower() for word in ['ê°€ì¡±', 'ì‚¬ë‘', 'ì´í•´', 'ì§€ì§€']):
            return ResponseQuality.EXCELLENT
        elif word_count > 50:
            return ResponseQuality.GOOD
        elif word_count > 20:
            return ResponseQuality.FAIR
        else:
            return ResponseQuality.POOR
    
    def _calculate_confidence_score(self, response_text: str, query_type: QueryType) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 0.6
        
        # ì‘ë‹µ ê¸¸ì´ ì ìˆ˜
        word_count = len(response_text.split())
        length_score = min(0.2, word_count * 0.002)
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ ì ìˆ˜
        type_score = 0.0
        if query_type == QueryType.FAMILY_ADVICE:
            type_score = 0.1
        elif query_type == QueryType.EMOTIONAL_SUPPORT:
            type_score = 0.1
        else:
            type_score = 0.05
        
        return min(1.0, base_score + length_score + type_score)
    
    def _calculate_family_relevance_score(self, response_text: str, family_context: Dict[str, Any]) -> float:
        """ê°€ì¡± ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        family_keywords = ['ê°€ì¡±', 'ë¶€ëª¨', 'ìì‹', 'ì‚¬ë‘', 'ê´€ê³„', 'ì†Œí†µ', 'ì´í•´', 'ì§€ì§€', 'ì„±ì¥']
        
        relevant_words = sum(1 for keyword in family_keywords if keyword in response_text.lower())
        
        return min(1.0, relevant_words * 0.1)
    
    def get_learning_help(self, question: str, family_context: Dict[str, Any] = None) -> LLMResponse:
        """í•™ìŠµ ë„ì›€ ìš”ì²­"""
        return self.ask_llm(question, QueryType.LEARNING_HELP, family_context, LLMProvider.CHATGPT)
    
    def get_family_advice(self, question: str, family_context: Dict[str, Any] = None) -> LLMResponse:
        """ê°€ì¡± ì¡°ì–¸ ìš”ì²­"""
        return self.ask_llm(question, QueryType.FAMILY_ADVICE, family_context, LLMProvider.CLAUDE)
    
    def get_emotional_support(self, question: str, family_context: Dict[str, Any] = None) -> LLMResponse:
        """ì •ì„œì  ì§€ì› ìš”ì²­"""
        return self.ask_llm(question, QueryType.EMOTIONAL_SUPPORT, family_context, LLMProvider.CHATGPT)
    
    def get_creative_inspiration(self, question: str, family_context: Dict[str, Any] = None) -> LLMResponse:
        """ì°½ì˜ì  ì˜ê° ìš”ì²­"""
        return self.ask_llm(question, QueryType.CREATIVE_INSPIRATION, family_context, LLMProvider.GEMINI)
    
    def get_knowledge_answer(self, question: str, family_context: Dict[str, Any] = None) -> LLMResponse:
        """ì§€ì‹ ì§ˆë¬¸ ë‹µë³€"""
        return self.ask_llm(question, QueryType.KNOWLEDGE_QUESTION, family_context, LLMProvider.CHATGPT)
    
    def get_llm_statistics(self) -> Dict[str, Any]:
        """LLM ì‚¬ìš© í†µê³„"""
        try:
            total_queries = len(self.queries)
            total_responses = len(self.responses)
            
            # ì œê³µìë³„ í†µê³„
            provider_stats = {}
            for provider in LLMProvider:
                provider_responses = [r for r in self.responses if r.provider == provider]
                provider_stats[provider.value] = len(provider_responses)
            
            # ì§ˆë¬¸ ìœ í˜•ë³„ í†µê³„
            query_type_stats = {}
            for query_type in QueryType:
                type_queries = [q for q in self.queries if q.query_type == query_type]
                query_type_stats[query_type.value] = len(type_queries)
            
            # ì‘ë‹µ í’ˆì§ˆë³„ í†µê³„
            quality_stats = {}
            for quality in ResponseQuality:
                quality_responses = [r for r in self.responses if r.response_quality == quality]
                quality_stats[quality.value] = len(quality_responses)
            
            # í‰ê·  ì²˜ë¦¬ ì‹œê°„
            avg_processing_time = sum(r.processing_time_seconds for r in self.responses) / len(self.responses) if self.responses else 0
            
            # í‰ê·  ì‹ ë¢°ë„
            avg_confidence = sum(r.confidence_score for r in self.responses) / len(self.responses) if self.responses else 0
            
            # í‰ê·  ê°€ì¡± ê´€ë ¨ì„±
            avg_family_relevance = sum(r.family_relevance_score for r in self.responses) / len(self.responses) if self.responses else 0
            
            statistics = {
                'total_queries': total_queries,
                'total_responses': total_responses,
                'provider_stats': provider_stats,
                'query_type_stats': query_type_stats,
                'quality_stats': quality_stats,
                'average_processing_time': avg_processing_time,
                'average_confidence': avg_confidence,
                'average_family_relevance': avg_family_relevance,
                'last_updated': datetime.now().isoformat()
            }
            
            logger.info("LLM ì‚¬ìš© í†µê³„ ìƒì„± ì™„ë£Œ")
            return statistics
            
        except Exception as e:
            logger.error(f"LLM ì‚¬ìš© í†µê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            return {}
    
    def export_llm_data(self) -> Dict[str, Any]:
        """LLM ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        try:
            export_data = {
                'queries': [asdict(query) for query in self.queries],
                'responses': [asdict(response) for response in self.responses],
                'provider_configs': {provider.value: asdict(config) for provider, config in self.provider_configs.items()},
                'export_date': datetime.now().isoformat()
            }
            
            logger.info("LLM ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ")
            return export_data
            
        except Exception as e:
            logger.error(f"LLM ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return {}
    
    def import_llm_data(self, data: Dict[str, Any]):
        """LLM ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
            for query_data in data.get('queries', []):
                # datetime ê°ì²´ ë³€í™˜
                if 'timestamp' in query_data:
                    query_data['timestamp'] = datetime.fromisoformat(query_data['timestamp'])
                
                llm_query = LLMQuery(**query_data)
                self.queries.append(llm_query)
            
            # ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°
            for response_data in data.get('responses', []):
                # datetime ê°ì²´ ë³€í™˜
                if 'timestamp' in response_data:
                    response_data['timestamp'] = datetime.fromisoformat(response_data['timestamp'])
                
                llm_response = LLMResponse(**response_data)
                self.responses.append(llm_response)
            
            # ì œê³µì ì„¤ì • ê°€ì ¸ì˜¤ê¸°
            for provider_name, config_data in data.get('provider_configs', {}).items():
                provider = LLMProvider(provider_name)
                llm_config = LLMProviderConfig(**config_data)
                self.provider_configs[provider] = llm_config
            
            logger.info("LLM ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"LLM ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            raise

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_llm_interface():
    """LLM ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("ğŸ¤– LLMInterface í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    llm_interface = LLMInterface()
    
    # ê°€ì¡± ë§¥ë½ ì„¤ì •
    family_context = {
        'family_type': 'nuclear',
        'children_count': 2,
        'children_ages': [5, 8],
        'family_values': ['ì‚¬ë‘', 'ì†Œí†µ', 'ì„±ì¥', 'ì°½ì˜ì„±']
    }
    
    # 1. í•™ìŠµ ë„ì›€ ìš”ì²­
    learning_question = "ì•„ì´ë“¤ê³¼ í•¨ê»˜í•  ìˆ˜ ìˆëŠ” ì°½ì˜ì ì¸ ë†€ì´ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."
    learning_response = llm_interface.get_learning_help(learning_question, family_context)
    print(f"âœ… í•™ìŠµ ë„ì›€ ì‘ë‹µ: {learning_response.response_quality.value} í’ˆì§ˆ, {learning_response.confidence_score:.2f} ì‹ ë¢°ë„")
    
    # 2. ê°€ì¡± ì¡°ì–¸ ìš”ì²­
    advice_question = "ì•„ì´ë“¤ì´ ì‹¸ìš¸ ë•Œ ì–´ë–»ê²Œ ëŒ€ì²˜í•´ì•¼ í• ê¹Œìš”?"
    advice_response = llm_interface.get_family_advice(advice_question, family_context)
    print(f"âœ… ê°€ì¡± ì¡°ì–¸ ì‘ë‹µ: {advice_response.response_quality.value} í’ˆì§ˆ, {advice_response.family_relevance_score:.2f} ê°€ì¡± ê´€ë ¨ì„±")
    
    # 3. ì •ì„œì  ì§€ì› ìš”ì²­
    emotional_question = "ì•„ì´ê°€ í•™êµì—ì„œ ì¹œêµ¬ì™€ ë‹¤í‰ˆì„œ ì†ìƒí•´í•´ìš”."
    emotional_response = llm_interface.get_emotional_support(emotional_question, family_context)
    print(f"âœ… ì •ì„œì  ì§€ì› ì‘ë‹µ: {emotional_response.response_quality.value} í’ˆì§ˆ, {emotional_response.processing_time_seconds:.2f}ì´ˆ ì²˜ë¦¬ì‹œê°„")
    
    # 4. ì°½ì˜ì  ì˜ê° ìš”ì²­
    creative_question = "ì£¼ë§ì— ê°€ì¡±ê³¼ í•¨ê»˜í•  ìˆ˜ ìˆëŠ” ì¬ë¯¸ìˆëŠ” í™œë™ì„ ì œì•ˆí•´ì£¼ì„¸ìš”."
    creative_response = llm_interface.get_creative_inspiration(creative_question, family_context)
    print(f"âœ… ì°½ì˜ì  ì˜ê° ì‘ë‹µ: {creative_response.response_quality.value} í’ˆì§ˆ, {creative_response.confidence_score:.2f} ì‹ ë¢°ë„")
    
    # 5. ì§€ì‹ ì§ˆë¬¸
    knowledge_question = "ì•„ì´ì˜ ì°½ì˜ë ¥ì„ í‚¤ìš°ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    knowledge_response = llm_interface.get_knowledge_answer(knowledge_question, family_context)
    print(f"âœ… ì§€ì‹ ì§ˆë¬¸ ì‘ë‹µ: {knowledge_response.response_quality.value} í’ˆì§ˆ, {knowledge_response.family_relevance_score:.2f} ê°€ì¡± ê´€ë ¨ì„±")
    
    # 6. LLM ì‚¬ìš© í†µê³„
    statistics = llm_interface.get_llm_statistics()
    print(f"âœ… LLM ì‚¬ìš© í†µê³„: {statistics['total_queries']}ê°œ ì§ˆë¬¸, {statistics['total_responses']}ê°œ ì‘ë‹µ")
    print(f"   ì œê³µìë³„: {statistics['provider_stats']}")
    print(f"   ì§ˆë¬¸ ìœ í˜•ë³„: {statistics['query_type_stats']}")
    print(f"   ì‘ë‹µ í’ˆì§ˆë³„: {statistics['quality_stats']}")
    
    # 7. ë°ì´í„° ë‚´ë³´ë‚´ê¸°/ê°€ì ¸ì˜¤ê¸°
    export_data = llm_interface.export_llm_data()
    print(f"âœ… LLM ë°ì´í„° ë‚´ë³´ë‚´ê¸°: {len(export_data['queries'])}ê°œ ì§ˆë¬¸, {len(export_data['responses'])}ê°œ ì‘ë‹µ")
    
    print("ğŸ‰ LLMInterface í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    test_llm_interface() 