#!/usr/bin/env python3
"""
Phase 11 í†µí•© í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ

ê¸°ëŠ¥:
- Phase 11ì˜ ëª¨ë“  ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
- ì‹œìŠ¤í…œ ê°„ ìƒí˜¸ì‘ìš© ê²€ì¦
- ë°ì´í„° íë¦„ ë° ì—°ë™ í…ŒìŠ¤íŠ¸
- ì „ì²´ Phase 11 ì„±ëŠ¥ í‰ê°€
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.text_learning_service import TextBasedLearningSystem
from app.services.subtitle_learning_service import SubtitleBasedLearningSystem
from app.services.llm_interface_service import LLMInterface
from app.services.basic_conversation_service import BasicConversationSystem
from app.services.family_conversation_precision_service import FamilyConversationPrecisionSystem
from app.services.developmental_thinking_conversation_service import DevelopmentalThinkingConversationSystem

import json
from datetime import datetime

def test_phase11_integration():
    """Phase 11 í†µí•© í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  Phase 11 í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # ê°€ì¡± ë§¥ë½ ì„¤ì •
    family_context = {
        'family_type': 'nuclear',
        'children_count': 2,
        'children_ages': [5, 8],
        'family_values': ['ì‚¬ë‘', 'ì†Œí†µ', 'ì„±ì¥', 'ì°½ì˜ì„±'],
        'age': 5
    }
    
    # 1. í…ìŠ¤íŠ¸ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\nğŸ“š 1. í…ìŠ¤íŠ¸ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    text_learning = TextBasedLearningSystem()
    
    sample_content = {
        'title': 'ê°€ì¡±ê³¼ í•¨ê»˜í•˜ëŠ” ì°½ì˜ì  í•™ìŠµ ë°©ë²•',
        'content': 'ì°½ì˜ë ¥ì„ í‚¤ìš°ëŠ” ê²ƒì€ ê°€ì¡±ê³¼ì˜ ì†Œí†µì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤. ì•„ì´ë“¤ê³¼ í•¨ê»˜ ê·¸ë¦¼ì„ ê·¸ë¦¬ê±°ë‚˜ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ëŠ” ê²ƒì´ ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤.',
        'text_type': 'article',
        'source_url': 'https://example.com/creative-learning',
        'author': 'ê°€ì¡± êµìœ¡ ì „ë¬¸ê°€'
    }
    
    text_content = text_learning.add_text_content(sample_content)
    extracted_knowledge = text_learning.extract_knowledge_from_text(text_content.id)
    print(f"âœ… í…ìŠ¤íŠ¸ í•™ìŠµ: {len(extracted_knowledge.key_concepts)}ê°œ í‚¤ ì»¨ì…‰ ì¶”ì¶œ")
    
    # 2. ìë§‰ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\nğŸ“¹ 2. ìë§‰ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    subtitle_learning = SubtitleBasedLearningSystem()
    
    sample_video = {
        'title': 'ê°€ì¡±ê³¼ í•¨ê»˜í•˜ëŠ” ì°½ì˜ì  ë†€ì´',
        'description': 'ì•„ì´ë“¤ê³¼ í•¨ê»˜í•  ìˆ˜ ìˆëŠ” ì°½ì˜ì ì¸ ë†€ì´ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.',
        'video_type': 'family_content',
        'duration_seconds': 600,
        'source_url': 'https://youtube.com/watch?v=example',
        'channel_name': 'ê°€ì¡± ë†€ì´ ì±„ë„'
    }
    
    video_content = subtitle_learning.add_video_content(sample_video)
    sample_subtitles = [
        {'start_time': 0.0, 'end_time': 30.0, 'text': 'ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ì€ ê°€ì¡±ê³¼ í•¨ê»˜í•  ìˆ˜ ìˆëŠ” ì°½ì˜ì ì¸ ë†€ì´ë¥¼ ì†Œê°œí•´ë“œë¦´ê²Œìš”.'},
        {'start_time': 30.0, 'end_time': 60.0, 'text': 'ë¨¼ì € ì¤€ë¹„ë¬¼ì„ ë³´ì‹œë©´ ì¢…ì´ì™€ ìƒ‰ì—°í•„ì´ í•„ìš”í•©ë‹ˆë‹¤.'}
    ]
    
    subtitle_segments = subtitle_learning.add_subtitle_segments(video_content.id, sample_subtitles)
    visual_knowledge = subtitle_learning.extract_visual_knowledge_from_video(video_content.id)
    print(f"âœ… ìë§‰ í•™ìŠµ: {len(visual_knowledge.key_concepts)}ê°œ í‚¤ ì»¨ì…‰ ì¶”ì¶œ")
    
    # 3. LLM ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸
    print("\nğŸ¤– 3. LLM ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸")
    llm_interface = LLMInterface()
    
    learning_question = "ì•„ì´ì˜ ì°½ì˜ë ¥ì„ í‚¤ìš°ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”."
    learning_response = llm_interface.get_learning_help(learning_question, family_context)
    print(f"âœ… LLM í•™ìŠµ ë„ì›€: {learning_response.response_quality.value} í’ˆì§ˆ")
    
    # 4. ê¸°ë³¸ ëŒ€í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\nğŸ’¬ 4. ê¸°ë³¸ ëŒ€í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    conversation_system = BasicConversationSystem()
    
    session = conversation_system.start_conversation("member_1", "ì—„ë§ˆ", "mother", family_context)
    conversation_response = conversation_system.process_message(
        session.id, "member_1", "ì—„ë§ˆ", "ì•„ì´ì˜ ì°½ì˜ë ¥ì„ í‚¤ìš°ê³  ì‹¶ì–´ìš”."
    )
    print(f"âœ… ê¸°ë³¸ ëŒ€í™”: {conversation_response.response_style.value} ìŠ¤íƒ€ì¼")
    
    # 5. ê°€ì¡± ì •ë°€ë„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\nğŸ¯ 5. ê°€ì¡± ì •ë°€ë„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    precision_system = FamilyConversationPrecisionSystem()
    
    precision_analysis = precision_system.analyze_conversation_precision(
        "ì•„ì´ì˜ ì°½ì˜ë ¥ì„ í‚¤ìš°ê³  ì‹¶ì–´ìš”.", family_context
    )
    precision_response = precision_system.generate_precision_enhanced_response(
        "ì•„ì´ì˜ ì°½ì˜ë ¥ì„ í‚¤ìš°ê³  ì‹¶ì–´ìš”.", family_context, precision_analysis
    )
    print(f"âœ… ê°€ì¡± ì •ë°€ë„: {precision_response.confidence_score:.2f} ì‹ ë¢°ë„")
    
    # 6. ë°œì „ì  ì‚¬ê³  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    print("\nğŸ§  6. ë°œì „ì  ì‚¬ê³  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    developmental_system = DevelopmentalThinkingConversationSystem()
    
    growth_analysis = developmental_system.analyze_developmental_thinking(
        "ì•„ì´ì˜ ì°½ì˜ë ¥ì„ í‚¤ìš°ê³  ì‹¶ì–´ìš”.", family_context
    )
    developmental_response = developmental_system.generate_developmental_response(
        "ì•„ì´ì˜ ì°½ì˜ë ¥ì„ í‚¤ìš°ê³  ì‹¶ì–´ìš”.", family_context, growth_analysis
    )
    print(f"âœ… ë°œì „ì  ì‚¬ê³ : {developmental_response.confidence_score:.2f} ì‹ ë¢°ë„")
    
    # 7. ì‹œìŠ¤í…œ ê°„ ë°ì´í„° ì—°ë™ í…ŒìŠ¤íŠ¸
    print("\nğŸ”„ 7. ì‹œìŠ¤í…œ ê°„ ë°ì´í„° ì—°ë™ í…ŒìŠ¤íŠ¸")
    
    # í…ìŠ¤íŠ¸ í•™ìŠµ â†’ LLM ì—°ë™
    text_recommendations = text_learning.get_learning_recommendations(family_context)
    if text_recommendations:
        llm_followup = llm_interface.get_knowledge_answer(
            f"'{text_recommendations[0]['text_content']['title']}'ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš”.",
            family_context
        )
        print(f"âœ… í…ìŠ¤íŠ¸â†’LLM ì—°ë™: {llm_followup.response_quality.value} í’ˆì§ˆ")
    
    # ìë§‰ í•™ìŠµ â†’ ëŒ€í™” ì‹œìŠ¤í…œ ì—°ë™
    visual_recommendations = subtitle_learning.get_visual_learning_recommendations(family_context)
    if visual_recommendations:
        conversation_followup = conversation_system.process_message(
            session.id, "member_1", "ì—„ë§ˆ", 
            f"'{visual_recommendations[0]['video_content']['title']}' ì˜ìƒì„ ë³´ì—¬ì£¼ì„¸ìš”."
        )
        print(f"âœ… ìë§‰â†’ëŒ€í™” ì—°ë™: {conversation_followup.response_style.value} ìŠ¤íƒ€ì¼")
    
    # 8. í†µí•© ì„±ëŠ¥ í‰ê°€
    print("\nğŸ“Š 8. í†µí•© ì„±ëŠ¥ í‰ê°€")
    
    # ê° ì‹œìŠ¤í…œì˜ í†µê³„ ìˆ˜ì§‘
    text_stats = text_learning.get_learning_statistics()
    subtitle_stats = subtitle_learning.get_visual_learning_statistics()
    llm_stats = llm_interface.get_llm_statistics()
    conversation_stats = conversation_system.get_conversation_statistics()
    precision_stats = precision_system.get_precision_statistics()
    developmental_stats = developmental_system.get_developmental_statistics()
    
    # ì „ì²´ ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°
    total_systems = 6
    active_systems = sum([
        1 if text_stats.get('total_contents', 0) > 0 else 0,
        1 if subtitle_stats.get('total_videos', 0) > 0 else 0,
        1 if llm_stats.get('total_queries', 0) > 0 else 0,
        1 if conversation_stats.get('total_sessions', 0) > 0 else 0,
        1 if precision_stats.get('total_analyses', 0) > 0 else 0,
        1 if developmental_stats.get('total_analyses', 0) > 0 else 0
    ])
    
    system_activation_rate = active_systems / total_systems
    print(f"âœ… ì‹œìŠ¤í…œ í™œì„±í™”ìœ¨: {system_activation_rate:.2f} ({active_systems}/{total_systems})")
    
    # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
    confidence_scores = [
        text_stats.get('average_confidence', 0),
        subtitle_stats.get('average_confidence', 0),
        llm_stats.get('average_confidence', 0),
        conversation_stats.get('average_confidence', 0),
        precision_stats.get('average_confidence', 0),
        developmental_stats.get('average_confidence', 0)
    ]
    avg_confidence = sum(confidence_scores) / len(confidence_scores)
    print(f"âœ… í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}")
    
    # 9. ë°ì´í„° ë‚´ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸
    print("\nğŸ’¾ 9. ë°ì´í„° ë‚´ë³´ë‚´ê¸° í…ŒìŠ¤íŠ¸")
    
    export_data = {
        'text_learning': text_learning.export_learning_data(),
        'subtitle_learning': subtitle_learning.export_visual_learning_data(),
        'llm_interface': llm_interface.export_llm_data(),
        'conversation': conversation_system.export_conversation_data(),
        'precision': precision_system.export_precision_data(),
        'developmental': developmental_system.export_developmental_data(),
        'integration_test_date': datetime.now().isoformat()
    }
    
    print(f"âœ… í†µí•© ë°ì´í„° ë‚´ë³´ë‚´ê¸°: {len(export_data)}ê°œ ì‹œìŠ¤í…œ")
    
    # 10. Phase 11 ì™„ë£Œ ìš”ì•½
    print("\nğŸ‰ Phase 11 í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ëœ ì‹œìŠ¤í…œ: {total_systems}ê°œ")
    print(f"âœ… í™œì„±í™”ëœ ì‹œìŠ¤í…œ: {active_systems}ê°œ")
    print(f"ğŸ“Š í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.2f}")
    print(f"ğŸ”„ ì‹œìŠ¤í…œ ì—°ë™: í…ìŠ¤íŠ¸â†’LLM, ìë§‰â†’ëŒ€í™”")
    print(f"ğŸ’¾ ë°ì´í„° ë‚´ë³´ë‚´ê¸°: ì™„ë£Œ")
    
    return {
        'total_systems': total_systems,
        'active_systems': active_systems,
        'activation_rate': system_activation_rate,
        'average_confidence': avg_confidence,
        'export_data': export_data
    }

if __name__ == "__main__":
    test_phase11_integration() 