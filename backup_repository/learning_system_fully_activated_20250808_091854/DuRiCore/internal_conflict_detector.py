#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DuRi Phase Z v2.0: ë‚´ë¶€ ëª¨ìˆœ íƒì§€ ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ DuRiì˜ ë‚´ë¶€ ëª¨ìˆœì„ íƒì§€í•˜ê³  í•´ê²°í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ë…¼ë¦¬ì  ì¼ê´€ì„±, ëª©í‘œ ì¶©ëŒ, ë¶ˆì•ˆì •ì„± ë“±ì„ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬
- ëª©í‘œ ì¶©ëŒ ê°ì§€
- ë¶ˆì•ˆì •ì„± íƒì§€
- ëª¨ìˆœ í•´ê²° ë°©ì•ˆ ì œì‹œ
"""

import asyncio
import json
import logging
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple, Union
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ConflictType(Enum):
    """ì¶©ëŒ ìœ í˜• ì—´ê±°í˜•"""
    LOGICAL = "logical"
    ETHICAL = "ethical"
    PRACTICAL = "practical"
    GOAL = "goal"
    INTERNAL = "internal"
    STABILITY = "stability"


class ConflictSeverity(Enum):
    """ì¶©ëŒ ì‹¬ê°ë„ ì—´ê±°í˜•"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class Conflict:
    """ì¶©ëŒ ë°ì´í„° í´ë˜ìŠ¤"""
    conflict_type: ConflictType
    severity: ConflictSeverity
    description: str
    detected_at: datetime
    source: str
    confidence: float
    resolution_suggestions: List[str] = field(default_factory=list)
    resolved: bool = False
    resolution_time: Optional[datetime] = None


@dataclass
class ConflictAnalysisResult:
    """ì¶©ëŒ ë¶„ì„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    conflicts: List[Conflict]
    total_conflicts: int
    severity_distribution: Dict[str, int]
    resolution_priority: List[Conflict]
    analysis_time: float
    success: bool = True


class InternalConflictDetector:
    """ë‚´ë¶€ ëª¨ìˆœ íƒì§€ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.conflicts: List[Conflict] = []
        self.conflict_patterns = self._initialize_conflict_patterns()
        self.logical_rules = self._initialize_logical_rules()
        self.ethical_principles = self._initialize_ethical_principles()
        self.stability_metrics = self._initialize_stability_metrics()
        
    def _initialize_conflict_patterns(self) -> Dict[str, Any]:
        """ì¶©ëŒ íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "logical_contradiction": {
                "pattern": r"(not|never|always|impossible).*(but|however|yet).*(not|never|always|impossible)",
                "weight": 0.8
            },
            "goal_conflict": {
                "pattern": r"(goal|objective|aim).*(conflict|contradict|oppose)",
                "weight": 0.7
            },
            "ethical_dilemma": {
                "pattern": r"(ethical|moral).*(dilemma|conflict|choice)",
                "weight": 0.9
            }
        }
    
    def _initialize_logical_rules(self) -> List[Dict[str, Any]]:
        """ë…¼ë¦¬ì  ê·œì¹™ ì´ˆê¸°í™”"""
        return [
            {
                "name": "non_contradiction",
                "description": "ëª¨ìˆœë˜ëŠ” ì£¼ì¥ì€ ë™ì‹œì— ì°¸ì¼ ìˆ˜ ì—†ìŒ",
                "check_function": self._check_non_contradiction
            },
            {
                "name": "excluded_middle",
                "description": "ì–´ë–¤ ì£¼ì¥ì€ ì°¸ì´ê±°ë‚˜ ê±°ì§“ì´ì–´ì•¼ í•¨",
                "check_function": self._check_excluded_middle
            },
            {
                "name": "identity",
                "description": "ê°™ì€ ê²ƒì€ ê°™ìŒ",
                "check_function": self._check_identity
            }
        ]
    
    def _initialize_ethical_principles(self) -> List[Dict[str, Any]]:
        """ìœ¤ë¦¬ì  ì›ì¹™ ì´ˆê¸°í™”"""
        return [
            {
                "name": "autonomy",
                "description": "ììœ¨ì„± ì¡´ì¤‘",
                "weight": 0.9
            },
            {
                "name": "beneficence",
                "description": "ì´ìµ ì¦ì§„",
                "weight": 0.8
            },
            {
                "name": "non_maleficence",
                "description": "í•´ì•… ë°©ì§€",
                "weight": 0.9
            },
            {
                "name": "justice",
                "description": "ê³µì •ì„±",
                "weight": 0.8
            }
        ]
    
    def _initialize_stability_metrics(self) -> Dict[str, Any]:
        """ì•ˆì •ì„± ì§€í‘œ ì´ˆê¸°í™”"""
        return {
            "consistency_threshold": 0.7,
            "coherence_threshold": 0.6,
            "stability_threshold": 0.8,
            "fluctuation_limit": 0.3
        }
    
    async def detect_conflicts(self, thought_data: Dict[str, Any]) -> ConflictAnalysisResult:
        """ì „ì²´ ì¶©ëŒ íƒì§€"""
        logger.info("ğŸ” ë‚´ë¶€ ëª¨ìˆœ íƒì§€ ì‹œì‘")
        start_time = time.time()
        
        try:
            conflicts = []
            
            # 1. ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬
            logical_conflicts = await self._detect_logical_conflicts(thought_data)
            conflicts.extend(logical_conflicts)
            
            # 2. ëª©í‘œ ì¶©ëŒ ê°ì§€
            goal_conflicts = await self._detect_goal_conflicts(thought_data)
            conflicts.extend(goal_conflicts)
            
            # 3. ìœ¤ë¦¬ì  ì¶©ëŒ ê°ì§€
            ethical_conflicts = await self._detect_ethical_conflicts(thought_data)
            conflicts.extend(ethical_conflicts)
            
            # 4. ë¶ˆì•ˆì •ì„± íƒì§€
            stability_conflicts = await self._detect_stability_conflicts(thought_data)
            conflicts.extend(stability_conflicts)
            
            # 5. ë‚´ì  ëª¨ìˆœ íƒì§€
            internal_conflicts = await self._detect_internal_conflicts(thought_data)
            conflicts.extend(internal_conflicts)
            
            # ì¶©ëŒ ë¶„ì„ ê²°ê³¼ ìƒì„±
            analysis_time = time.time() - start_time
            severity_distribution = self._calculate_severity_distribution(conflicts)
            resolution_priority = self._prioritize_conflicts(conflicts)
            
            result = ConflictAnalysisResult(
                conflicts=conflicts,
                total_conflicts=len(conflicts),
                severity_distribution=severity_distribution,
                resolution_priority=resolution_priority,
                analysis_time=analysis_time,
                success=True
            )
            
            logger.info(f"âœ… ë‚´ë¶€ ëª¨ìˆœ íƒì§€ ì™„ë£Œ - {len(conflicts)}ê°œ ì¶©ëŒ ë°œê²¬")
            return result
            
        except Exception as e:
            logger.error(f"ë‚´ë¶€ ëª¨ìˆœ íƒì§€ ì‹¤íŒ¨: {e}")
            analysis_time = time.time() - start_time
            
            return ConflictAnalysisResult(
                conflicts=[],
                total_conflicts=0,
                severity_distribution={},
                resolution_priority=[],
                analysis_time=analysis_time,
                success=False
            )
    
    async def _detect_logical_conflicts(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ë…¼ë¦¬ì  ì¶©ëŒ íƒì§€"""
        conflicts = []
        
        # ë…¼ë¦¬ì  ê·œì¹™ ê²€ì‚¬
        for rule in self.logical_rules:
            rule_conflicts = await rule["check_function"](thought_data)
            conflicts.extend(rule_conflicts)
        
        # ë…¼ë¦¬ì  íŒ¨í„´ ê²€ì‚¬
        pattern_conflicts = await self._check_logical_patterns(thought_data)
        conflicts.extend(pattern_conflicts)
        
        return conflicts
    
    async def _detect_goal_conflicts(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ëª©í‘œ ì¶©ëŒ íƒì§€"""
        conflicts = []
        
        goals = thought_data.get('goals', [])
        if len(goals) < 2:
            return conflicts
        
        # ëª©í‘œ ê°„ ì¶©ëŒ ê²€ì‚¬
        for i, goal1 in enumerate(goals):
            for j, goal2 in enumerate(goals[i+1:], i+1):
                if await self._check_goal_conflict(goal1, goal2):
                    conflict = Conflict(
                        conflict_type=ConflictType.GOAL,
                        severity=ConflictSeverity.MEDIUM,
                        description=f"ëª©í‘œ ì¶©ëŒ: {goal1} vs {goal2}",
                        detected_at=datetime.now(),
                        source="goal_conflict_detector",
                        confidence=0.8,
                        resolution_suggestions=[
                            "ëª©í‘œ ìš°ì„ ìˆœìœ„ ì¬ì •ë ¬",
                            "ëª©í‘œ í†µí•© ë˜ëŠ” ìˆ˜ì •",
                            "ë‹¨ê³„ì  ëª©í‘œ ì„¤ì •"
                        ]
                    )
                    conflicts.append(conflict)
        
        return conflicts
    
    async def _detect_ethical_conflicts(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ìœ¤ë¦¬ì  ì¶©ëŒ íƒì§€"""
        conflicts = []
        
        # ìœ¤ë¦¬ì  ì›ì¹™ ê°„ ì¶©ëŒ ê²€ì‚¬
        principles = self.ethical_principles
        for i, principle1 in enumerate(principles):
            for j, principle2 in enumerate(principles[i+1:], i+1):
                if await self._check_ethical_conflict(principle1, principle2, thought_data):
                    conflict = Conflict(
                        conflict_type=ConflictType.ETHICAL,
                        severity=ConflictSeverity.HIGH,
                        description=f"ìœ¤ë¦¬ì  ì¶©ëŒ: {principle1['name']} vs {principle2['name']}",
                        detected_at=datetime.now(),
                        source="ethical_conflict_detector",
                        confidence=0.9,
                        resolution_suggestions=[
                            "ìœ¤ë¦¬ì  ì›ì¹™ ìš°ì„ ìˆœìœ„ ì„¤ì •",
                            "ìƒí™©ë³„ ìœ¤ë¦¬ì  íŒë‹¨ ê¸°ì¤€ ìˆ˜ë¦½",
                            "ìœ¤ë¦¬ì  ë”œë ˆë§ˆ í•´ê²° ë°©ì•ˆ ëª¨ìƒ‰"
                        ]
                    )
                    conflicts.append(conflict)
        
        return conflicts
    
    async def _detect_stability_conflicts(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ë¶ˆì•ˆì •ì„± íƒì§€"""
        conflicts = []
        
        # ì¼ê´€ì„± ê²€ì‚¬
        consistency_score = await self._calculate_consistency_score(thought_data)
        if consistency_score < self.stability_metrics["consistency_threshold"]:
            conflict = Conflict(
                conflict_type=ConflictType.STABILITY,
                severity=ConflictSeverity.MEDIUM,
                description=f"ì¼ê´€ì„± ë¶€ì¡±: {consistency_score:.2f}",
                detected_at=datetime.now(),
                source="stability_detector",
                confidence=0.7,
                resolution_suggestions=[
                    "ì‚¬ê³  ê³¼ì •ì˜ ì¼ê´€ì„± ê°•í™”",
                    "ë…¼ë¦¬ì  ì—°ê²°ì„± ê²€í† ",
                    "ì „ì œ ì¡°ê±´ ëª…í™•í™”"
                ]
            )
            conflicts.append(conflict)
        
        # ì‘ì§‘ì„± ê²€ì‚¬
        coherence_score = await self._calculate_coherence_score(thought_data)
        if coherence_score < self.stability_metrics["coherence_threshold"]:
            conflict = Conflict(
                conflict_type=ConflictType.STABILITY,
                severity=ConflictSeverity.MEDIUM,
                description=f"ì‘ì§‘ì„± ë¶€ì¡±: {coherence_score:.2f}",
                detected_at=datetime.now(),
                source="stability_detector",
                confidence=0.7,
                resolution_suggestions=[
                    "ì‚¬ê³  ìš”ì†Œ ê°„ ì—°ê²°ì„± ê°•í™”",
                    "í†µí•©ì  ê´€ì  ë„ì¶œ",
                    "ì¼ê´€ëœ í”„ë ˆì„ì›Œí¬ ì ìš©"
                ]
            )
            conflicts.append(conflict)
        
        return conflicts
    
    async def _detect_internal_conflicts(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ë‚´ì  ëª¨ìˆœ íƒì§€"""
        conflicts = []
        
        # ë‚´ì  ëª¨ìˆœ íŒ¨í„´ ê²€ì‚¬
        internal_patterns = await self._check_internal_patterns(thought_data)
        conflicts.extend(internal_patterns)
        
        # ìê¸° ëª¨ìˆœ ê²€ì‚¬
        self_contradictions = await self._check_self_contradictions(thought_data)
        conflicts.extend(self_contradictions)
        
        return conflicts
    
    # í—¬í¼ ë©”ì„œë“œë“¤
    async def _check_non_contradiction(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ëª¨ìˆœ ê²€ì‚¬"""
        conflicts = []
        # êµ¬í˜„ í•„ìš”
        return conflicts
    
    async def _check_excluded_middle(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ë°°ì¤‘ë¥  ê²€ì‚¬"""
        conflicts = []
        # êµ¬í˜„ í•„ìš”
        return conflicts
    
    async def _check_identity(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ë™ì¼ì„± ê²€ì‚¬"""
        conflicts = []
        # êµ¬í˜„ í•„ìš”
        return conflicts
    
    async def _check_logical_patterns(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ë…¼ë¦¬ì  íŒ¨í„´ ê²€ì‚¬"""
        conflicts = []
        # êµ¬í˜„ í•„ìš”
        return conflicts
    
    async def _check_goal_conflict(self, goal1: str, goal2: str) -> bool:
        """ëª©í‘œ ì¶©ëŒ ê²€ì‚¬"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶©ëŒ ê²€ì‚¬
        conflict_keywords = ["oppose", "contradict", "conflict", "incompatible"]
        goal1_lower = goal1.lower()
        goal2_lower = goal2.lower()
        
        for keyword in conflict_keywords:
            if keyword in goal1_lower or keyword in goal2_lower:
                return True
        
        return False
    
    async def _check_ethical_conflict(self, principle1: Dict[str, Any], 
                                    principle2: Dict[str, Any], 
                                    thought_data: Dict[str, Any]) -> bool:
        """ìœ¤ë¦¬ì  ì¶©ëŒ ê²€ì‚¬"""
        # êµ¬í˜„ í•„ìš”
        return False
    
    async def _calculate_consistency_score(self, thought_data: Dict[str, Any]) -> float:
        """ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        # êµ¬í˜„ í•„ìš”
        return 0.8
    
    async def _calculate_coherence_score(self, thought_data: Dict[str, Any]) -> float:
        """ì‘ì§‘ì„± ì ìˆ˜ ê³„ì‚°"""
        # êµ¬í˜„ í•„ìš”
        return 0.7
    
    async def _check_internal_patterns(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ë‚´ì  íŒ¨í„´ ê²€ì‚¬"""
        conflicts = []
        # êµ¬í˜„ í•„ìš”
        return conflicts
    
    async def _check_self_contradictions(self, thought_data: Dict[str, Any]) -> List[Conflict]:
        """ìê¸° ëª¨ìˆœ ê²€ì‚¬"""
        conflicts = []
        # êµ¬í˜„ í•„ìš”
        return conflicts
    
    def _calculate_severity_distribution(self, conflicts: List[Conflict]) -> Dict[str, int]:
        """ì‹¬ê°ë„ ë¶„í¬ ê³„ì‚°"""
        distribution = {
            "low": 0,
            "medium": 0,
            "high": 0,
            "critical": 0
        }
        
        for conflict in conflicts:
            severity = conflict.severity.value
            if severity in distribution:
                distribution[severity] += 1
        
        return distribution
    
    def _prioritize_conflicts(self, conflicts: List[Conflict]) -> List[Conflict]:
        """ì¶©ëŒ ìš°ì„ ìˆœìœ„ ì„¤ì •"""
        # ì‹¬ê°ë„ì™€ ì‹ ë¢°ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ì„¤ì •
        prioritized = sorted(
            conflicts,
            key=lambda x: (self._get_severity_weight(x.severity), x.confidence),
            reverse=True
        )
        
        return prioritized
    
    def _get_severity_weight(self, severity: ConflictSeverity) -> float:
        """ì‹¬ê°ë„ ê°€ì¤‘ì¹˜ ë°˜í™˜"""
        weights = {
            ConflictSeverity.LOW: 1.0,
            ConflictSeverity.MEDIUM: 2.0,
            ConflictSeverity.HIGH: 3.0,
            ConflictSeverity.CRITICAL: 4.0
        }
        return weights.get(severity, 1.0)


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°
    test_thought_data = {
        'goals': ['íš¨ìœ¨ì„± ê·¹ëŒ€í™”', 'ìœ¤ë¦¬ì  ì›ì¹™ ì¤€ìˆ˜'],
        'principles': ['ììœ¨ì„±', 'ê³µì •ì„±'],
        'arguments': [
            'ëª¨ë“  ê²°ì •ì€ íš¨ìœ¨ì ì´ì–´ì•¼ í•œë‹¤',
            'ë•Œë¡œëŠ” íš¨ìœ¨ì„±ì„ í¬ê¸°í•´ì•¼ í•  ìˆ˜ë„ ìˆë‹¤'
        ]
    }
    
    # ë‚´ë¶€ ëª¨ìˆœ íƒì§€ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    detector = InternalConflictDetector()
    
    # ì¶©ëŒ íƒì§€ ì‹¤í–‰
    result = await detector.detect_conflicts(test_thought_data)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ” ë‚´ë¶€ ëª¨ìˆœ íƒì§€ ê²°ê³¼")
    print("="*80)
    
    print(f"\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
    print(f"  - ì„±ê³µ ì—¬ë¶€: {'âœ… ì„±ê³µ' if result.success else 'âŒ ì‹¤íŒ¨'}")
    print(f"  - ë¶„ì„ ì‹œê°„: {result.analysis_time:.2f}ì´ˆ")
    print(f"  - ì´ ì¶©ëŒ ìˆ˜: {result.total_conflicts}")
    
    print(f"\nğŸ¯ ì‹¬ê°ë„ ë¶„í¬:")
    for severity, count in result.severity_distribution.items():
        print(f"  - {severity}: {count}ê°œ")
    
    print(f"\nğŸš¨ ì£¼ìš” ì¶©ëŒ:")
    for i, conflict in enumerate(result.resolution_priority[:3], 1):
        print(f"  {i}. {conflict.description}")
        print(f"     - ìœ í˜•: {conflict.conflict_type.value}")
        print(f"     - ì‹¬ê°ë„: {conflict.severity.value}")
        print(f"     - ì‹ ë¢°ë„: {conflict.confidence:.2f}")
    
    return result


if __name__ == "__main__":
    asyncio.run(main()) 