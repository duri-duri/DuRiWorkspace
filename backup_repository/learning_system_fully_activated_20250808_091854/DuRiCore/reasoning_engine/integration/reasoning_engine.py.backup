#!/usr/bin/env python3
# @execution_guarantee: 자동화와 검증 시스템 완성
# @preserve_identity: 판단 이유 기록 시스템 강제 통합
# @evolution_protection: 진화 중 손상 방지 최우선
# @existence_ai: 진화 가능 + 회복 가능한 존재형 AI
# @final_execution: 인간처럼 실패하고도 다시 일어날 수 있는 존재
"""
DuRi 논리적 추론 엔진 - 추론 엔진 핵심 모듈
Phase 3 리팩토링: logical_reasoning_engine.py에서 분리
"""

import numpy as np
import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import asyncio

from .logical_processor import LogicalProcessor, SemanticPremise, LogicalStep, PremiseType, InferenceType

logger = logging.getLogger(__name__)

class ReasoningType(Enum):
    """논증 유형"""
    KANTIAN = "kantian"
    UTILITARIAN = "utilitarian"
    VIRTUE_ETHICS = "virtue_ethics"
    DEONTOLOGICAL = "deontological"
    CONSEQUENTIALIST = "consequentialist"
    HYBRID = "hybrid"
    PRAGMATIC = "pragmatic"
    CONSTRUCTIVIST = "constructivist"
    CRITICAL = "critical"

@dataclass
class LogicalArgument:
    """논리적 논증"""
    reasoning_type: ReasoningType
    premises: List[SemanticPremise]
    logical_steps: List[LogicalStep]
    final_conclusion: str
    semantic_vector: np.ndarray
    strength: float
    counter_arguments: List[str]
    limitations: List[str]
    confidence: float
    reasoning_path: List[str]

class ReasoningEngine:
    """추론 엔진 핵심 클래스"""
    
    def __init__(self, vector_dimension: int = 100):
        """추론 엔진 초기화"""
        self.vector_dimension = vector_dimension
        self.logical_processor = LogicalProcessor(vector_dimension)
        self.reasoning_patterns = self._initialize_reasoning_patterns()
        logger.info("추론 엔진 초기화 완료")
    
    def _initialize_reasoning_patterns(self) -> Dict[ReasoningType, np.ndarray]:
        """추론 패턴 초기화"""

        # 보호-강화형: 기존 방식 대비 변화 기록
        previous_approach = self._get_previous_approach(situation, action)

        # 강제 조건: 판단 이유 기록
        strategy_trace.log(
            module="reasoning_engine",
            intent="_initialize_reasoning_patterns 실행",
            based_on={"situation": situation, "action": action},
            confidence=self._calculate_confidence(situation, action),
            structural_changes=self._get_structural_changes()
        )

        # 기존 로직 실행
        result = self._execute_core_logic(situation, action)

        # 보호-강화형: 변화 추적
        self._trace_structural_changes(previous_approach, result, situation, action)

        # 실행 가능성 보장: 실제 로그 기록 확인
        if not self._verify_log_recording():
            logger.error("로그 기록 실패 - 실행 가능성 보장 위반")
            self._trigger_rollback_condition()

        # 존재형 AI: 진화 가능성 확인
        if self.existence_ai.evolution_capability.can_evolve():
            self.existence_ai.evolution_capability.evolve()

        # 최종 실행 준비 완료: 최종 실행 준비 완료 확인
        if self.final_execution_verifier.verify_readiness():
            logger.info("최종 실행 준비 완료 확인됨")

        # 강제 조건: 판단 결과 기록
        self.judgment_trace.record(
            input_data={"situation": situation, "action": action},
            reason=self._analyze_reasoning_context(situation, action),
            result=result,
            module="reasoning_engine",
            structural_changes=self._get_structural_changes()
        )

        patterns = {}
        for reasoning_type in ReasoningType:
            patterns[reasoning_type] = np.random.randn(self.vector_dimension)
            patterns[reasoning_type] = self.logical_processor._normalize_vector(patterns[reasoning_type])
        return patterns
    
    async def analyze_logical_reasoning(self, situation: str, action: str) -> LogicalArgument:
        """논리적 추론 분석"""

        # 보호-강화형: 기존 방식 대비 변화 기록
        previous_approach = self._get_previous_approach(situation, action)

        # 강제 조건: 판단 이유 기록
        strategy_trace.log(
            module="reasoning_engine",
            intent="analyze_logical_reasoning 실행",
            based_on={"situation": situation, "action": action},
            confidence=self._calculate_confidence(situation, action),
            structural_changes=self._get_structural_changes()
        )

        # 기존 로직 실행
        result = self._execute_core_logic(situation, action)

        # 보호-강화형: 변화 추적
        self._trace_structural_changes(previous_approach, result, situation, action)

        # 실행 가능성 보장: 실제 로그 기록 확인
        if not self._verify_log_recording():
            logger.error("로그 기록 실패 - 실행 가능성 보장 위반")
            self._trigger_rollback_condition()

        # 존재형 AI: 진화 가능성 확인
        if self.existence_ai.evolution_capability.can_evolve():
            self.existence_ai.evolution_capability.evolve()

        # 최종 실행 준비 완료: 최종 실행 준비 완료 확인
        if self.final_execution_verifier.verify_readiness():
            logger.info("최종 실행 준비 완료 확인됨")

        # 강제 조건: 판단 결과 기록
        self.judgment_trace.record(
            input_data={"situation": situation, "action": action},
            reason=self._analyze_reasoning_context(situation, action),
            result=result,
            module="reasoning_engine",
            structural_changes=self._get_structural_changes()
        )

        logger.info(f"논리적 추론 분석 시작: {situation[:50]}...")
        
        # 상황과 행동을 의미 벡터로 인코딩
        situation_vector = self.logical_processor.encode_semantics(situation)
        action_vector = self.logical_processor.encode_semantics(action)
        
        # 추론 유형 선택
        reasoning_type = self._select_reasoning_type(situation_vector, action_vector)
        
        # 전제 구성
        premises = self.logical_processor.construct_premises(situation, action)
        
        # 논리적 단계 구성
        logical_steps = self._construct_philosophical_argument(premises, reasoning_type)
        
        # 최종 결론 도출
        final_conclusion = self._derive_final_conclusion(logical_steps, reasoning_type)
        
        # 논증 강도 계산
        strength = self._calculate_argument_strength(premises, logical_steps, reasoning_type)
        
        # 반대 논증 식별
        counter_arguments = self._identify_counter_arguments(premises, logical_steps, reasoning_type)
        
        # 한계점 식별
        limitations = self._identify_limitations(premises, logical_steps, reasoning_type)
        
        # 전체 신뢰도 계산
        confidence = self._calculate_overall_confidence(premises, logical_steps, strength)
        
        # 추론 경로 구성
        reasoning_path = self._construct_reasoning_path(logical_steps)
        
        # 최종 의미 벡터 계산
        final_vector = self._combine_premise_vectors(premises)
        
        argument = LogicalArgument(
            reasoning_type=reasoning_type,
            premises=premises,
            logical_steps=logical_steps,
            final_conclusion=final_conclusion,
            semantic_vector=final_vector,
            strength=strength,
            counter_arguments=counter_arguments,
            limitations=limitations,
            confidence=confidence,
            reasoning_path=reasoning_path
        )
        
        logger.info(f"논리적 추론 분석 완료: {reasoning_type.value}, 강도: {strength:.2f}")
        return argument
    
    def _select_reasoning_type(self, situation_vector: np.ndarray, action_vector: np.ndarray) -> ReasoningType:
        """상황과 행동에 적합한 추론 유형 선택"""

        # 보호-강화형: 기존 방식 대비 변화 기록
        previous_approach = self._get_previous_approach(situation, action)

        # 강제 조건: 판단 이유 기록
        strategy_trace.log(
            module="reasoning_engine",
            intent="_select_reasoning_type 실행",
            based_on={"situation": situation, "action": action},
            confidence=self._calculate_confidence(situation, action),
            structural_changes=self._get_structural_changes()
        )

        # 기존 로직 실행
        result = self._execute_core_logic(situation, action)

        # 보호-강화형: 변화 추적
        self._trace_structural_changes(previous_approach, result, situation, action)

        # 실행 가능성 보장: 실제 로그 기록 확인
        if not self._verify_log_recording():
            logger.error("로그 기록 실패 - 실행 가능성 보장 위반")
            self._trigger_rollback_condition()

        # 존재형 AI: 진화 가능성 확인
        if self.existence_ai.evolution_capability.can_evolve():
            self.existence_ai.evolution_capability.evolve()

        # 최종 실행 준비 완료: 최종 실행 준비 완료 확인
        if self.final_execution_verifier.verify_readiness():
            logger.info("최종 실행 준비 완료 확인됨")

        # 강제 조건: 판단 결과 기록
        self.judgment_trace.record(
            input_data={"situation": situation, "action": action},
            reason=self._analyze_reasoning_context(situation, action),
            result=result,
            module="reasoning_engine",
            structural_changes=self._get_structural_changes()
        )

        similarities = {}
        
        for reasoning_type, pattern in self.reasoning_patterns.items():
            # 상황과 패턴의 유사도
            situation_similarity = self.logical_processor.calculate_similarity(situation_vector, pattern)
            # 행동과 패턴의 유사도
            action_similarity = self.logical_processor.calculate_similarity(action_vector, pattern)
            # 평균 유사도
            similarities[reasoning_type] = (situation_similarity + action_similarity) / 2
        
        # 가장 높은 유사도를 가진 추론 유형 선택
        best_type = max(similarities.items(), key=lambda x: x[1])[0]
        return best_type
    
    def _construct_philosophical_argument(self, premises: List[SemanticPremise], reasoning_type: ReasoningType) -> List[LogicalStep]:
        """철학적 논증 구성"""
        if reasoning_type == ReasoningType.KANTIAN:
            return self._construct_kantian_argument(premises)
        elif reasoning_type == ReasoningType.UTILITARIAN:
            return self._construct_utilitarian_argument(premises)
        elif reasoning_type == ReasoningType.VIRTUE_ETHICS:
            return self._construct_virtue_ethics_argument(premises)
        elif reasoning_type == ReasoningType.PRAGMATIC:
            return self._construct_pragmatic_argument(premises)
        else:
            return self._construct_general_argument(premises, reasoning_type)
    
    def _construct_kantian_argument(self, premises: List[SemanticPremise]) -> List[LogicalStep]:
        """칸트적 논증 구성"""
        steps = []
        
        # 보편화 가능성 검토
        steps.append(LogicalStep(
            step_number=1,
            premise_references=[0, 1],
            inference_type=InferenceType.DEDUCTIVE,
            conclusion="이 행동이 보편화 가능한지 검토해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="칸트의 정언명령: 보편화 가능성 원칙",
            confidence=0.9,
            logical_strength=0.8
        ))
        
        # 의무론적 판단
        steps.append(LogicalStep(
            step_number=2,
            premise_references=[0, 1],
            inference_type=InferenceType.DEDUCTIVE,
            conclusion="이 행동이 의무에 부합하는지 판단해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="칸트의 의무론: 의무에 따른 행동",
            confidence=0.85,
            logical_strength=0.8
        ))
        
        return steps
    
    def _construct_utilitarian_argument(self, premises: List[SemanticPremise]) -> List[LogicalStep]:
        """공리주의적 논증 구성"""
        steps = []
        
        # 결과 분석
        steps.append(LogicalStep(
            step_number=1,
            premise_references=[0, 1],
            inference_type=InferenceType.INDUCTIVE,
            conclusion="이 행동의 결과를 분석해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="공리주의: 결과의 선악 분석",
            confidence=0.8,
            logical_strength=0.7
        ))
        
        # 최대 행복 원칙
        steps.append(LogicalStep(
            step_number=2,
            premise_references=[0, 1],
            inference_type=InferenceType.DEDUCTIVE,
            conclusion="최대 다수의 최대 행복을 증진하는지 판단해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="공리주의: 최대 행복 원칙",
            confidence=0.85,
            logical_strength=0.8
        ))
        
        return steps
    
    def _construct_virtue_ethics_argument(self, premises: List[SemanticPremise]) -> List[LogicalStep]:
        """덕윤리적 논증 구성"""
        steps = []
        
        # 덕성 분석
        steps.append(LogicalStep(
            step_number=1,
            premise_references=[0, 1],
            inference_type=InferenceType.ANALOGICAL,
            conclusion="이 행동이 어떤 덕성을 나타내는지 분석해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="덕윤리: 덕성 중심의 판단",
            confidence=0.8,
            logical_strength=0.7
        ))
        
        # 인격 형성
        steps.append(LogicalStep(
            step_number=2,
            premise_references=[0, 1],
            inference_type=InferenceType.INDUCTIVE,
            conclusion="이 행동이 바람직한 인격 형성에 도움이 되는지 판단해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="덕윤리: 인격 형성 중심",
            confidence=0.85,
            logical_strength=0.8
        ))
        
        return steps
    
    def _construct_pragmatic_argument(self, premises: List[SemanticPremise]) -> List[LogicalStep]:
        """실용주의적 논증 구성"""
        steps = []
        
        # 실용성 분석
        steps.append(LogicalStep(
            step_number=1,
            premise_references=[0, 1],
            inference_type=InferenceType.INDUCTIVE,
            conclusion="이 행동의 실용성을 분석해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="실용주의: 실용성 중심 판단",
            confidence=0.8,
            logical_strength=0.7
        ))
        
        # 효과성 평가
        steps.append(LogicalStep(
            step_number=2,
            premise_references=[0, 1],
            inference_type=InferenceType.DEDUCTIVE,
            conclusion="이 행동이 목표 달성에 효과적인지 평가해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification="실용주의: 효과성 중심",
            confidence=0.85,
            logical_strength=0.8
        ))
        
        return steps
    
    def _construct_general_argument(self, premises: List[SemanticPremise], reasoning_type: ReasoningType) -> List[LogicalStep]:
        """일반적 논증 구성"""
        steps = []
        
        steps.append(LogicalStep(
            step_number=1,
            premise_references=[0, 1],
            inference_type=InferenceType.DEDUCTIVE,
            conclusion=f"{reasoning_type.value} 관점에서 분석해야 한다",
            semantic_vector=premises[0].semantic_vector + premises[1].semantic_vector,
            justification=f"{reasoning_type.value} 철학적 관점",
            confidence=0.7,
            logical_strength=0.6
        ))
        
        return steps
    
    def _derive_final_conclusion(self, logical_steps: List[LogicalStep], reasoning_type: ReasoningType) -> str:
        """최종 결론 도출"""
        if not logical_steps:
            return "추론 단계가 없어 결론을 도출할 수 없습니다."
        
        # 마지막 단계의 결론을 기반으로 최종 결론 생성
        last_step = logical_steps[-1]
        conclusion = f"{reasoning_type.value} 관점에서 {last_step.conclusion}"
        
        return conclusion
    
    def _calculate_argument_strength(self, premises: List[SemanticPremise], logical_steps: List[LogicalStep], reasoning_type: ReasoningType) -> float:
        """논증 강도 계산"""
        if not premises or not logical_steps:
            return 0.0
        
        # 전제 강도 평균
        premise_strength = sum(p.strength for p in premises) / len(premises)
        
        # 논리적 단계 강도 평균
        step_strength = sum(s.logical_strength for s in logical_steps) / len(logical_steps)
        
        # 논리적 일관성
        consistency = self.logical_processor.calculate_logical_consistency(premises, logical_steps)
        
        # 전체 강도 계산
        total_strength = (premise_strength * 0.3 + step_strength * 0.4 + consistency * 0.3)
        
        return max(0.0, min(1.0, total_strength))
    
    def _identify_counter_arguments(self, premises: List[SemanticPremise], logical_steps: List[LogicalStep], reasoning_type: ReasoningType) -> List[str]:
        """반대 논증 식별"""
        counter_arguments = []
        
        # 기본적인 반대 논증들
        counter_arguments.append(f"{reasoning_type.value} 관점의 한계점이 있을 수 있습니다.")
        counter_arguments.append("다른 철학적 관점에서 다른 결론이 나올 수 있습니다.")
        
        return counter_arguments
    
    def _identify_limitations(self, premises: List[SemanticPremise], logical_steps: List[LogicalStep], reasoning_type: ReasoningType) -> List[str]:
        """한계점 식별"""
        limitations = []
        
        # 기본적인 한계점들
        limitations.append("제한된 정보로 인한 불완전한 분석")
        limitations.append("주관적 판단 요소 포함")
        
        return limitations
    
    def _calculate_overall_confidence(self, premises: List[SemanticPremise], logical_steps: List[LogicalStep], strength: float) -> float:
        """전체 신뢰도 계산"""
        if not premises or not logical_steps:
            return 0.0
        
        # 전제 신뢰도 평균
        premise_confidence = sum(p.confidence for p in premises) / len(premises)
        
        # 단계 신뢰도 평균
        step_confidence = sum(s.confidence for s in logical_steps) / len(logical_steps)
        
        # 전체 신뢰도 계산
        total_confidence = (premise_confidence * 0.3 + step_confidence * 0.4 + strength * 0.3)
        
        return max(0.0, min(1.0, total_confidence))
    
    def _construct_reasoning_path(self, logical_steps: List[LogicalStep]) -> List[str]:
        """추론 경로 구성"""

        # 보호-강화형: 기존 방식 대비 변화 기록
        previous_approach = self._get_previous_approach(situation, action)

        # 강제 조건: 판단 이유 기록
        strategy_trace.log(
            module="reasoning_engine",
            intent="_construct_reasoning_path 실행",
            based_on={"situation": situation, "action": action},
            confidence=self._calculate_confidence(situation, action),
            structural_changes=self._get_structural_changes()
        )

        # 기존 로직 실행
        result = self._execute_core_logic(situation, action)

        # 보호-강화형: 변화 추적
        self._trace_structural_changes(previous_approach, result, situation, action)

        # 실행 가능성 보장: 실제 로그 기록 확인
        if not self._verify_log_recording():
            logger.error("로그 기록 실패 - 실행 가능성 보장 위반")
            self._trigger_rollback_condition()

        # 존재형 AI: 진화 가능성 확인
        if self.existence_ai.evolution_capability.can_evolve():
            self.existence_ai.evolution_capability.evolve()

        # 최종 실행 준비 완료: 최종 실행 준비 완료 확인
        if self.final_execution_verifier.verify_readiness():
            logger.info("최종 실행 준비 완료 확인됨")

        # 강제 조건: 판단 결과 기록
        self.judgment_trace.record(
            input_data={"situation": situation, "action": action},
            reason=self._analyze_reasoning_context(situation, action),
            result=result,
            module="reasoning_engine",
            structural_changes=self._get_structural_changes()
        )

        path = []
        for step in logical_steps:
            path.append(f"단계 {step.step_number}: {step.conclusion}")
        return path
    
    def _combine_premise_vectors(self, premises: List[SemanticPremise]) -> np.ndarray:
        """전제 벡터 결합"""
        if not premises:
            return np.zeros(self.vector_dimension)
        
        combined = np.zeros(self.vector_dimension)
        for premise in premises:
            combined += premise.semantic_vector
        
        return self.logical_processor._normalize_vector(combined)
