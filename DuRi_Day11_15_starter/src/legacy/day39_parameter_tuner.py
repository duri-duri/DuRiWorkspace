#!/usr/bin/env python3
"""
Day39: PoU íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì • ì‹œìŠ¤í…œ (ê¸°ì¡´ trace_sweep ê¸°ë°˜)
- Day38 ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì¡°ì •
- ì•ˆ A (ë³´ìˆ˜): safety_first ê°•í™”
- ì•ˆ B (ê³µê²©): quality í”„ë¦¬ì…‹ í…ŒìŠ¤íŠ¸
- ê¸°ì¡´ run_trace_sweep_v2.py íŒ¨í„´ í™œìš©
"""

import argparse
from datetime import datetime
import json
import logging
import pathlib
import subprocess
import sys
import time
from typing import Any, Dict, List, Tuple

try:
    import yaml
except Exception:
    print("[ERR] PyYAML required: pip install pyyaml", file=sys.stderr)
    raise

ROOT = pathlib.Path(__file__).resolve().parents[1]


class Day39ParameterTuner:
    def __init__(self):
        self.logger = self._setup_logging()
        self.experiments_dir = ROOT / "experiments" / "day39"
        self.experiments_dir.mkdir(parents=True, exist_ok=True)

        # ê¸°ì¡´ Day35/Day36 ì„¤ì • ë¡œë“œ
        self.objective_config = ROOT / "configs" / "objective_params.yaml"
        self.evaluator_script = ROOT / "tools" / "evaluate_objective.py"
        self.ingest_script = ROOT / "tools" / "pou_metrics_ingest.py"
        self.ab_test_script = ROOT / "day35_pack" / "tools" / "ab_test_runner.py"

        self.logger.info("Day39 íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì • ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def _setup_logging(self) -> logging.Logger:
        """ë¡œê¹… ì„¤ì •"""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(logging.INFO)
        formatter = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")

        ch = logging.StreamHandler()
        ch.setFormatter(formatter)
        logger.addHandler(ch)

        return logger

    def atomic_write(self, p: pathlib.Path, text: str):
        """ì›ìì  íŒŒì¼ ì“°ê¸°"""
        tmp = p.with_suffix(p.suffix + ".tmp")
        tmp.write_text(text, encoding="utf-8")
        tmp.replace(p)

    def run_cmd(self, cmd: str) -> str:
        """ëª…ë ¹ì–´ ì‹¤í–‰"""
        self.logger.debug(f"ì‹¤í–‰: {cmd}")
        r = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        if r.returncode != 0:
            raise RuntimeError(f"ëª…ë ¹ì–´ ì‹¤íŒ¨: {cmd}\n{r.stderr}")
        return r.stdout.strip()

    def check_sensitivity_snapshot(self) -> Dict[str, float]:
        """ë¯¼ê°ë„ ìŠ¤ëƒ…ìƒ· í™•ì¸"""
        self.logger.info("ğŸ” ë¯¼ê°ë„ ìŠ¤ëƒ…ìƒ· í™•ì¸ ì¤‘...")

        # Day38 ì¼ì¼ ë¦¬í¬íŠ¸ ì‹¤í–‰
        self.run_cmd("python tools/day38_daily_report.py")

        # ë¦¬í¬íŠ¸ íŒŒì¼ ì½ê¸°
        report_file = ROOT / "artifacts" / "day38" / "daily" / "daily_report.md"
        if not report_file.exists():
            self.logger.warning("Day38 ë¦¬í¬íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ ì‚¬ìš©")
            return {"dJ_dfail": 0.1, "dJ_dlat": 0.001}

        # ë¯¼ê°ë„ ê°’ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒŒì‹±)
        content = report_file.read_text(encoding="utf-8")
        sensitivity = {"dJ_dfail": 0.1, "dJ_dlat": 0.001}  # ê¸°ë³¸ê°’

        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”
        self.logger.info(f"ë¯¼ê°ë„ ìŠ¤ëƒ…ìƒ·: {sensitivity}")
        return sensitivity

    def create_plan_a_config(self) -> pathlib.Path:
        """ì•ˆ A (ë³´ìˆ˜) ì„¤ì • ìƒì„±"""
        self.logger.info("ğŸ“‹ ì•ˆ A (ë³´ìˆ˜) ì„¤ì • ìƒì„± ì¤‘...")

        # ê¸°ì¡´ ì„¤ì • ë°±ì—…
        backup_file = self.objective_config.with_suffix(".backup")
        if not backup_file.exists():
            backup_file.write_text(self.objective_config.read_text(encoding="utf-8"))

        # ì„¤ì • ë¡œë“œ ë° ìˆ˜ì •
        config = yaml.safe_load(self.objective_config.read_text(encoding="utf-8"))

        # safety_first ê°€ì¤‘ì¹˜ ê°•í™”
        if "weights" in config and "safety_first" in config["weights"]:
            config["weights"]["safety_first"]["failure"] += 0.05
            config["weights"]["safety_first"]["latency"] -= 0.05

        # ì§€ì—°ì‹œê°„ ì„ê³„ì¹˜ ì™„í™” (1350 â†’ 1450)
        if "transforms" in config and "latency" in config["transforms"]:
            config["transforms"]["latency"]["target_ms"] = 1450

        # ìˆ˜ì •ëœ ì„¤ì • ì €ì¥
        plan_a_config = self.experiments_dir / "plan_a_config.yaml"
        self.atomic_write(plan_a_config, yaml.dump(config, default_flow_style=False))

        self.logger.info(f"ì•ˆ A ì„¤ì • ì €ì¥: {plan_a_config}")
        return plan_a_config

    def run_plan_a_experiment(self, config_file: pathlib.Path) -> pathlib.Path:
        """ì•ˆ A ì‹¤í—˜ ì‹¤í–‰"""
        self.logger.info("ğŸš€ ì•ˆ A (ë³´ìˆ˜) ì‹¤í—˜ ì‹¤í–‰ ì¤‘...")

        out_dir = self.experiments_dir / "A"
        out_dir.mkdir(parents=True, exist_ok=True)

        cmd = [
            "python",
            str(self.ingest_script),
            "--glob",
            "'samples/logs/*_A_*.jsonl'",
            "--mapping",
            "configs/pou_ingest_mapping.yaml",
            "--outdir",
            str(out_dir),
            "--eval_config",
            str(config_file),
            "--weight_preset",
            "safety_first",
            "--evaluate_script",
            str(self.evaluator_script),
        ]

        self.run_cmd(" ".join(cmd))

        self.logger.info(f"ì•ˆ A ì‹¤í—˜ ì™„ë£Œ: {out_dir}")
        return out_dir

    def run_plan_b_experiment(self) -> pathlib.Path:
        """ì•ˆ B (ê³µê²©) ì‹¤í—˜ ì‹¤í–‰"""
        self.logger.info("ğŸš€ ì•ˆ B (ê³µê²©) ì‹¤í—˜ ì‹¤í–‰ ì¤‘...")

        out_dir = self.experiments_dir / "B"
        out_dir.mkdir(parents=True, exist_ok=True)

        cmd = [
            "python",
            str(self.ingest_script),
            "--glob",
            "'samples/logs/*_B_*.jsonl'",
            "--mapping",
            "configs/pou_ingest_mapping.yaml",
            "--outdir",
            str(out_dir),
            "--eval_config",
            str(self.objective_config),
            "--weight_preset",
            "quality",
            "--evaluate_script",
            str(self.evaluator_script),
        ]

        self.run_cmd(" ".join(cmd))

        self.logger.info(f"ì•ˆ B ì‹¤í—˜ ì™„ë£Œ: {out_dir}")
        return out_dir

    def run_ab_comparison(
        self, dir_a: pathlib.Path, dir_b: pathlib.Path
    ) -> Dict[str, Any]:
        """A/B ë¹„êµ ì‹¤í–‰"""
        self.logger.info("ğŸ“Š A/B ë¹„êµ ì‹¤í–‰ ì¤‘...")

        # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        results_dir = ROOT / "artifacts" / "day39"
        results_dir.mkdir(parents=True, exist_ok=True)

        # A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        cmd = [
            "python",
            str(self.ab_test_script),
            "--glob_a",
            f"'{dir_a}/ab_A_*.json'",
            "--glob_b",
            f"'{dir_b}/ab_A_*.json'",
        ]

        output = self.run_cmd(" ".join(cmd))

        # ê²°ê³¼ íŒŒì‹±
        try:
            ab_results = json.loads(output)
        except json.JSONDecodeError:
            # ì¶œë ¥ì´ JSONì´ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ êµ¬ì¡° ìƒì„±
            ab_results = {
                "t_stat": 0.0,
                "p_value": 1.0,
                "mean_a": 0.0,
                "mean_b": 0.0,
                "decision": "INCONCLUSIVE",
            }

        # ê²°ê³¼ ì €ì¥
        results_file = results_dir / "ab_stats.json"
        self.atomic_write(
            results_file, json.dumps(ab_results, ensure_ascii=False, indent=2)
        )

        self.logger.info(f"A/B ë¹„êµ ì™„ë£Œ: {results_file}")
        return ab_results

    def make_decision(
        self, ab_results: Dict[str, Any], sensitivity: Dict[str, float]
    ) -> str:
        """ìµœì¢… íŒì •"""
        self.logger.info("ğŸ¯ ìµœì¢… íŒì • ì¤‘...")

        t_stat = abs(ab_results.get("t_stat", 0))
        mean_a = ab_results.get("mean_a", 0)
        mean_b = ab_results.get("mean_b", 0)

        decision = "MAINTAIN_CURRENT"
        reason = "í†µê³„ì  ìœ ì˜ì„± ë¶€ì¡±"

        if t_stat > 2.0:  # í†µê³„ì  ìœ ì˜ì„±
            if mean_a > mean_b:
                decision = "ADOPT_PLAN_A"
                reason = f"ì•ˆ A ìš°ìˆ˜ (t={t_stat:.2f}, Î”J={mean_a-mean_b:.6f})"
            else:
                decision = "ADOPT_PLAN_B"
                reason = f"ì•ˆ B ìš°ìˆ˜ (t={t_stat:.2f}, Î”J={mean_b-mean_a:.6f})"

        # ë¯¼ê°ë„ ê¸°ë°˜ ì¶”ê°€ íŒì •
        if sensitivity["dJ_dfail"] > 0.2:
            if decision == "MAINTAIN_CURRENT":
                decision = "ADOPT_PLAN_A"
                reason += " + ì‹¤íŒ¨ìœ¨ ë¯¼ê°ë„ ë†’ìŒ"

        self.logger.info(f"íŒì •: {decision} - {reason}")
        return decision

    def setup_canary_rules(self) -> Dict[str, Any]:
        """ì¹´ë‚˜ë¦¬ ê·œì¹™ ì„¤ì •"""
        self.logger.info("ğŸ›¡ï¸ ì¹´ë‚˜ë¦¬ ê·œì¹™ ì„¤ì • ì¤‘...")

        canary_rules = {
            "failure_rate_threshold": 0.008,  # 0.8%
            "failure_persist_minutes": 30,
            "latency_threshold_ms": 1800,
            "latency_persist_minutes": 30,
            "rollback_action": "REVERT_TO_PREVIOUS",
            "monitoring_integration": True,
        }

        # ì¹´ë‚˜ë¦¬ ì„¤ì • ì €ì¥
        canary_file = ROOT / "artifacts" / "day39" / "canary_rules.json"
        canary_file.parent.mkdir(parents=True, exist_ok=True)
        self.atomic_write(
            canary_file, json.dumps(canary_rules, ensure_ascii=False, indent=2)
        )

        self.logger.info(f"ì¹´ë‚˜ë¦¬ ê·œì¹™ ì €ì¥: {canary_file}")
        return canary_rules

    def generate_report(
        self,
        sensitivity: Dict[str, float],
        ab_results: Dict[str, Any],
        decision: str,
        canary_rules: Dict[str, Any],
    ) -> str:
        """ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        report = f"""# Day39 PoU íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì • ë¦¬í¬íŠ¸

## ğŸ“Š ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼
- **âˆ‚J/âˆ‚failure**: {sensitivity['dJ_dfail']:.6f}
- **âˆ‚J/âˆ‚latency**: {sensitivity['dJ_dlat']:.9f}

## ğŸ§ª A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼
- **t-statistic**: {ab_results.get('t_stat', 0):.3f}
- **p-value**: {ab_results.get('p_value', 1.0):.6f}
- **Mean A**: {ab_results.get('mean_a', 0):.6f}
- **Mean B**: {ab_results.get('mean_b', 0):.6f}

## ğŸ¯ ìµœì¢… íŒì •
- **ê²°ì •**: {decision}
- **ê·¼ê±°**: í†µê³„ì  ìœ ì˜ì„± ë° ë¯¼ê°ë„ ë¶„ì„ ê¸°ë°˜

## ğŸ›¡ï¸ ì¹´ë‚˜ë¦¬ ê·œì¹™
- **ì‹¤íŒ¨ìœ¨ ì„ê³„ì¹˜**: {canary_rules['failure_rate_threshold']:.1%}
- **ì§€ì—°ì‹œê°„ ì„ê³„ì¹˜**: {canary_rules['latency_threshold_ms']}ms
- **ì§€ì† ì‹œê°„**: {canary_rules['failure_persist_minutes']}ë¶„
- **ë¡¤ë°± ì •ì±…**: {canary_rules['rollback_action']}

## ğŸ“ˆ ê¶Œì¥ì‚¬í•­
1. **ëª¨ë‹ˆí„°ë§ ê°•í™”**: Day38 ì‹œìŠ¤í…œê³¼ ì—°ë™í•˜ì—¬ ì‹¤ì‹œê°„ ì¶”ì 
2. **ì ì§„ì  ë°°í¬**: ì¹´ë‚˜ë¦¬ ê·œì¹™ì— ë”°ë¼ ë‹¨ê³„ì  ì ìš©
3. **ì„±ëŠ¥ ì¶”ì **: ëª©ì í•¨ìˆ˜ J ê°’ì˜ ì§€ì†ì  ëª¨ë‹ˆí„°ë§
4. **ì¬í‰ê°€**: 1ì£¼ì¼ í›„ ë™ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ì¬ê²€í† 

---
*ìƒì„± ì‹œê°„: {timestamp}*
"""

        # ë¦¬í¬íŠ¸ ì €ì¥
        report_file = ROOT / "artifacts" / "day39" / f"day39_report_{timestamp}.md"
        self.atomic_write(report_file, report)

        return report

    def run_full_tuning(self) -> Dict[str, Any]:
        """ì „ì²´ íŠœë‹ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        self.logger.info("ğŸš€ Day39 ì „ì²´ íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì • ì‹œì‘")

        try:
            # 1. ë¯¼ê°ë„ ìŠ¤ëƒ…ìƒ· í™•ì¸
            sensitivity = self.check_sensitivity_snapshot()

            # 2. ì•ˆ A ì„¤ì • ìƒì„± ë° ì‹¤í—˜
            plan_a_config = self.create_plan_a_config()
            dir_a = self.run_plan_a_experiment(plan_a_config)

            # 3. ì•ˆ B ì‹¤í—˜
            dir_b = self.run_plan_b_experiment()

            # 4. A/B ë¹„êµ
            ab_results = self.run_ab_comparison(dir_a, dir_b)

            # 5. ìµœì¢… íŒì •
            decision = self.make_decision(ab_results, sensitivity)

            # 6. ì¹´ë‚˜ë¦¬ ê·œì¹™ ì„¤ì •
            canary_rules = self.setup_canary_rules()

            # 7. ë¦¬í¬íŠ¸ ìƒì„±
            report = self.generate_report(
                sensitivity, ab_results, decision, canary_rules
            )

            result = {
                "status": "SUCCESS",
                "sensitivity": sensitivity,
                "ab_results": ab_results,
                "decision": decision,
                "canary_rules": canary_rules,
                "report": report,
            }

            self.logger.info("âœ… Day39 íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì • ì™„ë£Œ")
            return result

        except Exception as e:
            self.logger.error(f"âŒ Day39 íŠœë‹ ì‹¤íŒ¨: {e}")
            return {"status": "FAILED", "error": str(e)}


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Day39 PoU íŒŒë¼ë¯¸í„° ë¯¸ì„¸ì¡°ì •")
    parser.add_argument(
        "--plan",
        choices=["A", "B", "both"],
        default="both",
        help="ì‹¤í–‰í•  ê³„íš (A: ë³´ìˆ˜, B: ê³µê²©, both: ë‘˜ ë‹¤)",
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ë¡œê·¸")

    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    tuner = Day39ParameterTuner()

    if args.plan == "both":
        result = tuner.run_full_tuning()
        print(json.dumps(result, ensure_ascii=False, indent=2))
    elif args.plan == "A":
        sensitivity = tuner.check_sensitivity_snapshot()
        config = tuner.create_plan_a_config()
        tuner.run_plan_a_experiment(config)
    elif args.plan == "B":
        tuner.run_plan_b_experiment()


if __name__ == "__main__":
    main()
