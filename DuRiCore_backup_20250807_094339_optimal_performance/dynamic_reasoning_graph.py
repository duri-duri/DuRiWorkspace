#!/usr/bin/env python3
"""
DuRi ë™ì  ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ - Phase 1-3 Week 3 Day 1
ê¸°ì¡´ reasoning_graph_system.pyë¥¼ ë™ì  ì‹œìŠ¤í…œìœ¼ë¡œ ì „í™˜

ê¸°ëŠ¥:
1. ë™ì  ë…¸ë“œ ìƒì„± ì‹œìŠ¤í…œ
2. ì¶”ë¡  ê²½ë¡œ ê²€ì¦ ì‹œìŠ¤í…œ
3. ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²° ì‹œìŠ¤í…œ
4. ì‹¤ì‹œê°„ ê·¸ë˜í”„ ì§„í™”
5. ì˜ë¯¸ ê¸°ë°˜ ë…¸ë“œ ì—°ê²°
"""

import asyncio
import json
import logging
import re
from collections import defaultdict
from dataclasses import asdict, dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Set, Tuple

import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NodeType(Enum):
    """ë…¸ë“œ ìœ í˜• - í™•ì¥ëœ ë²„ì „"""

    PREMISE = "premise"
    INFERENCE = "inference"
    CONCLUSION = "conclusion"
    COUNTER_ARGUMENT = "counter_argument"
    EVIDENCE = "evidence"
    ASSUMPTION = "assumption"
    HYPOTHESIS = "hypothesis"
    CONSTRAINT = "constraint"
    ALTERNATIVE = "alternative"
    INTEGRATION = "integration"


class EdgeType(Enum):
    """ì—£ì§€ ìœ í˜• - í™•ì¥ëœ ë²„ì „"""

    SUPPORTS = "supports"
    CONTRADICTS = "contradicts"
    INFERS = "infers"
    ASSUMES = "assumes"
    EVIDENCES = "evidences"
    CONSTRAINS = "constrains"
    ALTERNATES = "alternates"
    INTEGRATES = "integrates"
    CHALLENGES = "challenges"
    REFINES = "refines"


@dataclass
class DynamicReasoningNode:
    """ë™ì  ì¶”ë¡  ë…¸ë“œ"""

    node_id: str
    node_type: NodeType
    content: str
    confidence: float  # 0.0-1.0
    source: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    semantic_vector: Optional[np.ndarray] = None
    activation_level: float = 1.0
    importance_score: float = 0.5


@dataclass
class DynamicReasoningEdge:
    """ë™ì  ì¶”ë¡  ì—£ì§€"""

    edge_id: str
    source_node: str
    target_node: str
    edge_type: EdgeType
    strength: float  # 0.0-1.0
    reasoning: str
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    semantic_similarity: float = 0.0
    logical_validity: float = 0.0


@dataclass
class DynamicReasoningGraph:
    """ë™ì  ì¶”ë¡  ê·¸ë˜í”„"""

    graph_id: str
    nodes: Dict[str, DynamicReasoningNode] = field(default_factory=dict)
    edges: Dict[str, DynamicReasoningEdge] = field(default_factory=dict)
    root_nodes: List[str] = field(default_factory=list)
    leaf_nodes: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    complexity_score: float = 0.0
    coherence_score: float = 0.0
    evolution_history: List[Dict[str, Any]] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)


class SemanticVectorEngine:
    """ì˜ë¯¸ ë²¡í„° ì—”ì§„ - ë…¸ë“œ ê°„ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""

    def __init__(self):
        self.vector_cache = {}
        self.similarity_cache = {}
        self.max_cache_size = 1000

        # ì˜ë¯¸ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜
        self.semantic_keywords = {
            "ìœ¤ë¦¬": 0.9,
            "ë„ë•": 0.9,
            "ì •ì˜": 0.8,
            "ê³µì •": 0.8,
            "íš¨ìœ¨": 0.9,
            "ì‹¤ìš©": 0.8,
            "íš¨ê³¼": 0.7,
            "ê²°ê³¼": 0.7,
            "ë…¼ë¦¬": 0.8,
            "ì¶”ë¡ ": 0.8,
            "ë¶„ì„": 0.7,
            "í‰ê°€": 0.7,
            "ê°€ì¹˜": 0.8,
            "ì›ì¹™": 0.8,
            "ê¸°ì¤€": 0.7,
            "ëª©í‘œ": 0.7,
        }

    def encode_semantics(self, text: str) -> np.ndarray:
        """í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ë²¡í„°ë¡œ ì¸ì½”ë”©"""
        if text in self.vector_cache:
            return self.vector_cache[text]

        # ê°„ë‹¨í•œ ì˜ë¯¸ ë²¡í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì„ë² ë”© ì‚¬ìš©)
        vector = np.zeros(len(self.semantic_keywords))
        text_lower = text.lower()

        for i, (keyword, weight) in enumerate(self.semantic_keywords.items()):
            if keyword in text_lower:
                vector[i] = weight

        # ì •ê·œí™”
        if np.linalg.norm(vector) > 0:
            vector = vector / np.linalg.norm(vector)

        # ìºì‹œì— ì €ì¥
        if len(self.vector_cache) < self.max_cache_size:
            self.vector_cache[text] = vector

        return vector

    def calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
        cache_key = f"{text1}|||{text2}"
        if cache_key in self.similarity_cache:
            return self.similarity_cache[cache_key]

        vector1 = self.encode_semantics(text1)
        vector2 = self.encode_semantics(text2)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = np.dot(vector1, vector2) / (
            np.linalg.norm(vector1) * np.linalg.norm(vector2) + 1e-8
        )

        # ìºì‹œì— ì €ì¥
        if len(self.similarity_cache) < self.max_cache_size:
            self.similarity_cache[cache_key] = similarity

        return similarity


class DynamicNodeGenerator:
    """ë™ì  ë…¸ë“œ ìƒì„± ì‹œìŠ¤í…œ"""

    def __init__(self, semantic_engine: SemanticVectorEngine):
        self.semantic_engine = semantic_engine
        self.node_counter = 0
        self.node_templates = self._initialize_node_templates()

    def _initialize_node_templates(self) -> Dict[str, Dict[str, Any]]:
        """ë…¸ë“œ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        return {
            "premise": {
                "confidence_range": (0.6, 0.9),
                "importance_range": (0.5, 0.8),
                "activation_range": (0.8, 1.0),
            },
            "inference": {
                "confidence_range": (0.5, 0.8),
                "importance_range": (0.6, 0.9),
                "activation_range": (0.7, 1.0),
            },
            "conclusion": {
                "confidence_range": (0.7, 0.95),
                "importance_range": (0.8, 1.0),
                "activation_range": (0.9, 1.0),
            },
            "counter_argument": {
                "confidence_range": (0.4, 0.7),
                "importance_range": (0.6, 0.8),
                "activation_range": (0.6, 0.9),
            },
        }

    def generate_dynamic_node(
        self, content: str, node_type: NodeType, context: Dict[str, Any] = None
    ) -> DynamicReasoningNode:
        """ë™ì  ë…¸ë“œ ìƒì„±"""
        node_id = f"dynamic_node_{self.node_counter}_{int(datetime.now().timestamp())}"
        self.node_counter += 1

        # í…œí”Œë¦¿ì—ì„œ ê¸°ë³¸ê°’ ê°€ì ¸ì˜¤ê¸°
        template = self.node_templates.get(node_type.value, {})
        confidence_range = template.get("confidence_range", (0.5, 0.8))
        importance_range = template.get("importance_range", (0.5, 0.8))
        activation_range = template.get("activation_range", (0.7, 1.0))

        # ë™ì  ê°’ ê³„ì‚°
        confidence = np.random.uniform(*confidence_range)
        importance = np.random.uniform(*importance_range)
        activation = np.random.uniform(*activation_range)

        # ì˜ë¯¸ ë²¡í„° ìƒì„±
        semantic_vector = self.semantic_engine.encode_semantics(content)

        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "generation_method": "dynamic",
            "context": context or {},
            "semantic_vector_shape": semantic_vector.shape,
        }

        node = DynamicReasoningNode(
            node_id=node_id,
            node_type=node_type,
            content=content,
            confidence=confidence,
            source="DynamicGenerator",
            metadata=metadata,
            semantic_vector=semantic_vector,
            activation_level=activation,
            importance_score=importance,
        )

        return node


class DynamicEdgeGenerator:
    """ë™ì  ì—£ì§€ ìƒì„± ì‹œìŠ¤í…œ"""

    def __init__(self, semantic_engine: SemanticVectorEngine):
        self.semantic_engine = semantic_engine
        self.edge_counter = 0
        self.edge_templates = self._initialize_edge_templates()

    def _initialize_edge_templates(self) -> Dict[str, Dict[str, Any]]:
        """ì—£ì§€ í…œí”Œë¦¿ ì´ˆê¸°í™”"""
        return {
            "supports": {"strength_range": (0.6, 0.9), "validity_range": (0.7, 0.95)},
            "contradicts": {"strength_range": (0.4, 0.7), "validity_range": (0.6, 0.8)},
            "infers": {"strength_range": (0.5, 0.8), "validity_range": (0.6, 0.9)},
            "evidences": {"strength_range": (0.7, 0.9), "validity_range": (0.8, 0.95)},
        }

    def generate_dynamic_edge(
        self,
        source_node: DynamicReasoningNode,
        target_node: DynamicReasoningNode,
        edge_type: EdgeType,
    ) -> DynamicReasoningEdge:
        """ë™ì  ì—£ì§€ ìƒì„±"""
        edge_id = f"dynamic_edge_{self.edge_counter}_{int(datetime.now().timestamp())}"
        self.edge_counter += 1

        # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°
        semantic_similarity = self.semantic_engine.calculate_semantic_similarity(
            source_node.content, target_node.content
        )

        # í…œí”Œë¦¿ì—ì„œ ê¸°ë³¸ê°’ ê°€ì ¸ì˜¤ê¸°
        template = self.edge_templates.get(edge_type.value, {})
        strength_range = template.get("strength_range", (0.5, 0.8))
        validity_range = template.get("validity_range", (0.6, 0.9))

        # ë™ì  ê°’ ê³„ì‚°
        strength = np.random.uniform(*strength_range) * semantic_similarity
        logical_validity = np.random.uniform(*validity_range)

        # ì¶”ë¡  ì„¤ëª… ìƒì„±
        reasoning = self._generate_edge_reasoning(source_node, target_node, edge_type)

        edge = DynamicReasoningEdge(
            edge_id=edge_id,
            source_node=source_node.node_id,
            target_node=target_node.node_id,
            edge_type=edge_type,
            strength=strength,
            reasoning=reasoning,
            semantic_similarity=semantic_similarity,
            logical_validity=logical_validity,
        )

        return edge

    def _generate_edge_reasoning(
        self,
        source_node: DynamicReasoningNode,
        target_node: DynamicReasoningNode,
        edge_type: EdgeType,
    ) -> str:
        """ì—£ì§€ ì¶”ë¡  ì„¤ëª… ìƒì„±"""
        reasoning_templates = {
            EdgeType.SUPPORTS: f"{source_node.content}ì´ {target_node.content}ë¥¼ ì§€ì›í•¨",
            EdgeType.CONTRADICTS: f"{source_node.content}ì´ {target_node.content}ì™€ ëª¨ìˆœë¨",
            EdgeType.INFERS: f"{source_node.content}ì—ì„œ {target_node.content}ë¥¼ ì¶”ë¡ í•¨",
            EdgeType.EVIDENCES: f"{source_node.content}ì´ {target_node.content}ì˜ ì¦ê±°ê°€ ë¨",
        }

        return reasoning_templates.get(
            edge_type, f"{source_node.content}ê³¼ {target_node.content} ê°„ì˜ ê´€ê³„"
        )


class DynamicReasoningGraphBuilder:
    """ë™ì  ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶• ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.semantic_engine = SemanticVectorEngine()
        self.node_generator = DynamicNodeGenerator(self.semantic_engine)
        self.edge_generator = DynamicEdgeGenerator(self.semantic_engine)
        self.graph_counter = 0

    async def build_dynamic_reasoning_graph(
        self,
        situation: str,
        semantic_context: Dict[str, Any],
        philosophical_arguments: Dict[str, Any],
    ) -> DynamicReasoningGraph:
        """ë™ì  ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶•"""
        logger.info(f"ë™ì  ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶• ì‹œì‘: {situation}")

        # ê·¸ë˜í”„ ì´ˆê¸°í™”
        graph_id = f"dynamic_reasoning_graph_{self.graph_counter}_{int(datetime.now().timestamp())}"
        self.graph_counter += 1

        graph = DynamicReasoningGraph(graph_id=graph_id)

        # 1. ë™ì  ìƒí™© ë…¸ë“œ ìƒì„±
        situation_nodes = await self._create_dynamic_situation_nodes(
            situation, semantic_context
        )
        graph.nodes.update(situation_nodes)
        graph.root_nodes.extend(situation_nodes.keys())

        # 2. ë™ì  ì² í•™ì  ë…¸ë“œ ìƒì„±
        philosophical_nodes = await self._create_dynamic_philosophical_nodes(
            philosophical_arguments
        )
        graph.nodes.update(philosophical_nodes)

        # 3. ë™ì  ì¶”ë¡  ì—£ì§€ ìƒì„±
        reasoning_edges = await self._create_dynamic_reasoning_edges(
            graph.nodes, situation, philosophical_arguments
        )
        graph.edges.update(reasoning_edges)

        # 4. ë™ì  ê²°ë¡  ë…¸ë“œ ìƒì„±
        conclusion_nodes = await self._create_dynamic_conclusion_nodes(
            graph.nodes, graph.edges
        )
        graph.nodes.update(conclusion_nodes)
        graph.leaf_nodes.extend(conclusion_nodes.keys())

        # 5. ê·¸ë˜í”„ ë©”íŠ¸ë¦­ ê³„ì‚°
        graph.confidence_score = self._calculate_dynamic_graph_confidence(
            graph.nodes, graph.edges
        )
        graph.complexity_score = self._calculate_dynamic_graph_complexity(
            graph.nodes, graph.edges
        )
        graph.coherence_score = self._calculate_dynamic_graph_coherence(
            graph.nodes, graph.edges
        )

        # 6. ì§„í™” íˆìŠ¤í† ë¦¬ ê¸°ë¡
        graph.evolution_history.append(
            {
                "timestamp": datetime.now().isoformat(),
                "action": "graph_creation",
                "node_count": len(graph.nodes),
                "edge_count": len(graph.edges),
            }
        )

        logger.info(
            f"ë™ì  ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ: {len(graph.nodes)} ë…¸ë“œ, {len(graph.edges)} ì—£ì§€"
        )
        return graph

    async def _create_dynamic_situation_nodes(
        self, situation: str, semantic_context: Dict[str, Any]
    ) -> Dict[str, DynamicReasoningNode]:
        """ë™ì  ìƒí™© ë…¸ë“œ ìƒì„±"""
        nodes = {}

        # ìƒí™© ìœ í˜• ë…¸ë“œ
        situation_type = semantic_context.get("situation_type", "unknown")
        situation_type_content = f"ìƒí™© ìœ í˜•: {situation_type}"
        situation_type_node = self.node_generator.generate_dynamic_node(
            situation_type_content, NodeType.PREMISE, {"situation_type": situation_type}
        )
        nodes[situation_type_node.node_id] = situation_type_node

        # ì˜ë„ ë…¸ë“œ
        intent = semantic_context.get("intent", "unknown")
        intent_content = f"ì˜ë„: {intent}"
        intent_node = self.node_generator.generate_dynamic_node(
            intent_content, NodeType.PREMISE, {"intent": intent}
        )
        nodes[intent_node.node_id] = intent_node

        # ê°€ì¹˜ ì¶©ëŒ ë…¸ë“œë“¤
        value_conflicts = semantic_context.get("value_conflicts", [])
        for i, conflict in enumerate(value_conflicts):
            conflict_content = f"ê°€ì¹˜ ì¶©ëŒ {i+1}: {conflict}"
            conflict_node = self.node_generator.generate_dynamic_node(
                conflict_content, NodeType.CONSTRAINT, {"conflict_type": conflict}
            )
            nodes[conflict_node.node_id] = conflict_node

        return nodes

    async def _create_dynamic_philosophical_nodes(
        self, philosophical_arguments: Dict[str, Any]
    ) -> Dict[str, DynamicReasoningNode]:
        """ë™ì  ì² í•™ì  ë…¸ë“œ ìƒì„±"""
        nodes = {}

        # ì¹¸íŠ¸ì  ë¶„ì„ ë…¸ë“œ
        if "kantian" in philosophical_arguments:
            kantian = philosophical_arguments["kantian"]
            kantian_content = (
                f"ì¹¸íŠ¸ì  ë¶„ì„: {kantian.get('final_conclusion', 'ë¶„ì„ ì—†ìŒ')}"
            )
            kantian_node = self.node_generator.generate_dynamic_node(
                kantian_content, NodeType.INFERENCE, {"reasoning_type": "kantian"}
            )
            nodes[kantian_node.node_id] = kantian_node

        # ê³µë¦¬ì£¼ì˜ ë¶„ì„ ë…¸ë“œ
        if "utilitarian" in philosophical_arguments:
            utilitarian = philosophical_arguments["utilitarian"]
            utilitarian_content = (
                f"ê³µë¦¬ì£¼ì˜ ë¶„ì„: {utilitarian.get('final_conclusion', 'ë¶„ì„ ì—†ìŒ')}"
            )
            utilitarian_node = self.node_generator.generate_dynamic_node(
                utilitarian_content,
                NodeType.INFERENCE,
                {"reasoning_type": "utilitarian"},
            )
            nodes[utilitarian_node.node_id] = utilitarian_node

        # í†µí•© ë¶„ì„ ë…¸ë“œ
        if "integrated" in philosophical_arguments:
            integrated = philosophical_arguments["integrated"]
            integrated_content = (
                f"í†µí•© ë¶„ì„: {integrated.get('recommendation', 'ë¶„ì„ ì—†ìŒ')}"
            )
            integrated_node = self.node_generator.generate_dynamic_node(
                integrated_content,
                NodeType.INTEGRATION,
                {"reasoning_type": "integrated"},
            )
            nodes[integrated_node.node_id] = integrated_node

        return nodes

    async def _create_dynamic_reasoning_edges(
        self,
        nodes: Dict[str, DynamicReasoningNode],
        situation: str,
        philosophical_arguments: Dict[str, Any],
    ) -> Dict[str, DynamicReasoningEdge]:
        """ë™ì  ì¶”ë¡  ì—£ì§€ ìƒì„±"""
        edges = {}

        # ìƒí™© ë¶„ì„ â†’ ì² í•™ì  ë¶„ì„ ì—°ê²°
        situation_nodes = [n for n in nodes.values() if n.node_type == NodeType.PREMISE]
        philosophical_nodes = [
            n
            for n in nodes.values()
            if n.node_type in [NodeType.INFERENCE, NodeType.INTEGRATION]
        ]

        for situation_node in situation_nodes:
            for philosophical_node in philosophical_nodes:
                # ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜ ì—£ì§€ ìƒì„±
                similarity = self.semantic_engine.calculate_semantic_similarity(
                    situation_node.content, philosophical_node.content
                )

                if similarity > 0.3:  # ì„ê³„ê°’ ì´ìƒì¼ ë•Œë§Œ ì—£ì§€ ìƒì„±
                    edge = self.edge_generator.generate_dynamic_edge(
                        situation_node, philosophical_node, EdgeType.SUPPORTS
                    )
                    edges[edge.edge_id] = edge

        # ì² í•™ì  ë¶„ì„ ê°„ ì—°ê²°
        if len(philosophical_nodes) > 1:
            for i, node1 in enumerate(philosophical_nodes):
                for node2 in philosophical_nodes[i + 1 :]:
                    similarity = self.semantic_engine.calculate_semantic_similarity(
                        node1.content, node2.content
                    )

                    if similarity > 0.2:
                        edge_type = (
                            EdgeType.INFERS if similarity > 0.5 else EdgeType.INTEGRATES
                        )
                        edge = self.edge_generator.generate_dynamic_edge(
                            node1, node2, edge_type
                        )
                        edges[edge.edge_id] = edge

        return edges

    async def _create_dynamic_conclusion_nodes(
        self,
        nodes: Dict[str, DynamicReasoningNode],
        edges: Dict[str, DynamicReasoningEdge],
    ) -> Dict[str, DynamicReasoningNode]:
        """ë™ì  ê²°ë¡  ë…¸ë“œ ìƒì„±"""
        conclusion_nodes = {}

        # ìµœì¢… ê²°ë¡  ë…¸ë“œ
        final_conclusion_content = "ìµœì¢… ë„ë•ì  íŒë‹¨"
        final_conclusion_node = self.node_generator.generate_dynamic_node(
            final_conclusion_content,
            NodeType.CONCLUSION,
            {"conclusion_type": "final_judgment"},
        )
        conclusion_nodes[final_conclusion_node.node_id] = final_conclusion_node

        # ë°˜ë¡  ë…¸ë“œ
        counter_argument_content = "ëŒ€ì•ˆì  ê´€ì  ë° ë°˜ë¡ "
        counter_argument_node = self.node_generator.generate_dynamic_node(
            counter_argument_content,
            NodeType.COUNTER_ARGUMENT,
            {"counter_type": "alternative_perspectives"},
        )
        conclusion_nodes[counter_argument_node.node_id] = counter_argument_node

        return conclusion_nodes

    def _calculate_dynamic_graph_confidence(
        self,
        nodes: Dict[str, DynamicReasoningNode],
        edges: Dict[str, DynamicReasoningEdge],
    ) -> float:
        """ë™ì  ê·¸ë˜í”„ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not nodes:
            return 0.0

        # ë…¸ë“œ ì‹ ë¢°ë„ì˜ ê°€ì¤‘ í‰ê·  (ì¤‘ìš”ë„ ê¸°ë°˜)
        total_weight = 0.0
        weighted_confidence = 0.0

        for node in nodes.values():
            weight = node.importance_score
            weighted_confidence += node.confidence * weight
            total_weight += weight

        avg_node_confidence = (
            weighted_confidence / total_weight if total_weight > 0 else 0.0
        )

        # ì—£ì§€ ê°•ë„ì˜ í‰ê· 
        if edges:
            edge_strengths = [edge.strength for edge in edges.values()]
            avg_edge_strength = sum(edge_strengths) / len(edge_strengths)
        else:
            avg_edge_strength = 0.5

        # ì¢…í•© ì‹ ë¢°ë„ (ë…¸ë“œ 60%, ì—£ì§€ 40%)
        overall_confidence = avg_node_confidence * 0.6 + avg_edge_strength * 0.4
        return min(max(overall_confidence, 0.0), 1.0)

    def _calculate_dynamic_graph_complexity(
        self,
        nodes: Dict[str, DynamicReasoningNode],
        edges: Dict[str, DynamicReasoningEdge],
    ) -> float:
        """ë™ì  ê·¸ë˜í”„ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 0.0

        # ë…¸ë“œ ìˆ˜ì— ë”°ë¥¸ ë³µì¡ë„
        node_complexity = min(len(nodes) / 15.0, 1.0)
        complexity += node_complexity * 0.25

        # ì—£ì§€ ìˆ˜ì— ë”°ë¥¸ ë³µì¡ë„
        edge_complexity = min(len(edges) / 20.0, 1.0)
        complexity += edge_complexity * 0.25

        # ë…¸ë“œ ìœ í˜• ë‹¤ì–‘ì„±ì— ë”°ë¥¸ ë³µì¡ë„
        node_types = set(node.node_type for node in nodes.values())
        type_diversity = len(node_types) / 10.0  # ìµœëŒ€ 10ê°œ ìœ í˜•
        complexity += type_diversity * 0.2

        # ì—£ì§€ ìœ í˜• ë‹¤ì–‘ì„±ì— ë”°ë¥¸ ë³µì¡ë„
        edge_types = set(edge.edge_type for edge in edges.values())
        edge_diversity = len(edge_types) / 10.0  # ìµœëŒ€ 10ê°œ ìœ í˜•
        complexity += edge_diversity * 0.2

        # ì˜ë¯¸ì  ë³µì¡ë„ (ë…¸ë“œ ê°„ í‰ê·  ì˜ë¯¸ì  ê±°ë¦¬)
        if len(nodes) > 1:
            semantic_distances = []
            node_list = list(nodes.values())
            for i, node1 in enumerate(node_list):
                for node2 in node_list[i + 1 :]:
                    distance = 1.0 - self.semantic_engine.calculate_semantic_similarity(
                        node1.content, node2.content
                    )
                    semantic_distances.append(distance)

            if semantic_distances:
                avg_semantic_distance = sum(semantic_distances) / len(
                    semantic_distances
                )
                complexity += avg_semantic_distance * 0.1

        return min(complexity, 1.0)

    def _calculate_dynamic_graph_coherence(
        self,
        nodes: Dict[str, DynamicReasoningNode],
        edges: Dict[str, DynamicReasoningEdge],
    ) -> float:
        """ë™ì  ê·¸ë˜í”„ ì¼ê´€ì„± ê³„ì‚°"""
        if not nodes or not edges:
            return 0.0

        # ì—£ì§€ì˜ ë…¼ë¦¬ì  ìœ íš¨ì„± í‰ê· 
        edge_validities = [edge.logical_validity for edge in edges.values()]
        avg_edge_validity = sum(edge_validities) / len(edge_validities)

        # ë…¸ë“œ ê°„ ì˜ë¯¸ì  ì¼ê´€ì„±
        semantic_coherences = []
        for edge in edges.values():
            source_node = nodes.get(edge.source_node)
            target_node = nodes.get(edge.target_node)

            if source_node and target_node:
                semantic_similarity = (
                    self.semantic_engine.calculate_semantic_similarity(
                        source_node.content, target_node.content
                    )
                )
                semantic_coherences.append(semantic_similarity)

        avg_semantic_coherence = (
            sum(semantic_coherences) / len(semantic_coherences)
            if semantic_coherences
            else 0.0
        )

        # ì¢…í•© ì¼ê´€ì„± (ì—£ì§€ ìœ íš¨ì„± 60%, ì˜ë¯¸ì  ì¼ê´€ì„± 40%)
        overall_coherence = avg_edge_validity * 0.6 + avg_semantic_coherence * 0.4
        return min(max(overall_coherence, 0.0), 1.0)


class DynamicReasoningGraphAnalyzer:
    """ë™ì  ì¶”ë¡  ê·¸ë˜í”„ ë¶„ì„ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.graph_builder = DynamicReasoningGraphBuilder()
        self.semantic_engine = SemanticVectorEngine()

    async def analyze_dynamic_reasoning_process(
        self,
        situation: str,
        semantic_context: Dict[str, Any],
        philosophical_arguments: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ë™ì  ì¶”ë¡  ê³¼ì • ë¶„ì„"""
        logger.info(f"ë™ì  ì¶”ë¡  ê³¼ì • ë¶„ì„ ì‹œì‘: {situation}")

        # 1. ë™ì  ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶•
        reasoning_graph = await self.graph_builder.build_dynamic_reasoning_graph(
            situation, semantic_context, philosophical_arguments
        )

        # 2. ê·¸ë˜í”„ êµ¬ì¡° ë¶„ì„
        graph_analysis = self._analyze_dynamic_graph_structure(reasoning_graph)

        # 3. ì¶”ë¡  í’ˆì§ˆ í‰ê°€
        quality_assessment = self._assess_dynamic_reasoning_quality(reasoning_graph)

        # 4. ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²°
        inconsistency_analysis = self._detect_and_resolve_inconsistencies(
            reasoning_graph
        )

        return {
            "reasoning_graph": reasoning_graph,
            "graph_analysis": graph_analysis,
            "quality_assessment": quality_assessment,
            "inconsistency_analysis": inconsistency_analysis,
        }

    def _analyze_dynamic_graph_structure(
        self, graph: DynamicReasoningGraph
    ) -> Dict[str, Any]:
        """ë™ì  ê·¸ë˜í”„ êµ¬ì¡° ë¶„ì„"""
        analysis = {
            "node_count": len(graph.nodes),
            "edge_count": len(graph.edges),
            "node_types": {},
            "edge_types": {},
            "connectivity": 0.0,
            "depth": 0,
            "semantic_coherence": 0.0,
            "evolution_steps": len(graph.evolution_history),
        }

        # ë…¸ë“œ ìœ í˜• ë¶„í¬
        for node in graph.nodes.values():
            node_type = node.node_type.value
            analysis["node_types"][node_type] = (
                analysis["node_types"].get(node_type, 0) + 1
            )

        # ì—£ì§€ ìœ í˜• ë¶„í¬
        for edge in graph.edges.values():
            edge_type = edge.edge_type.value
            analysis["edge_types"][edge_type] = (
                analysis["edge_types"].get(edge_type, 0) + 1
            )

        # ì—°ê²°ì„± ê³„ì‚°
        if len(graph.nodes) > 1:
            analysis["connectivity"] = len(graph.edges) / (
                len(graph.nodes) * (len(graph.nodes) - 1)
            )

        # ê¹Šì´ ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
        analysis["depth"] = min(len(graph.nodes) // 3, 5)

        # ì˜ë¯¸ì  ì¼ê´€ì„± ê³„ì‚°
        if graph.edges:
            semantic_similarities = [
                edge.semantic_similarity for edge in graph.edges.values()
            ]
            analysis["semantic_coherence"] = sum(semantic_similarities) / len(
                semantic_similarities
            )

        return analysis

    def _assess_dynamic_reasoning_quality(
        self, graph: DynamicReasoningGraph
    ) -> Dict[str, Any]:
        """ë™ì  ì¶”ë¡  í’ˆì§ˆ í‰ê°€"""
        quality = {
            "overall_quality": 0.0,
            "logical_consistency": 0.0,
            "completeness": 0.0,
            "clarity": 0.0,
            "strength": 0.0,
            "coherence": 0.0,
            "dynamism": 0.0,
        }

        # ë…¼ë¦¬ì  ì¼ê´€ì„± (ì—£ì§€ì˜ ë…¼ë¦¬ì  ìœ íš¨ì„±)
        if graph.edges:
            edge_validities = [edge.logical_validity for edge in graph.edges.values()]
            quality["logical_consistency"] = sum(edge_validities) / len(edge_validities)

        # ì™„ì „ì„± (ëª¨ë“  ë…¸ë“œ ìœ í˜•ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€)
        node_types = set(node.node_type for node in graph.nodes.values())
        quality["completeness"] = len(node_types) / 10.0  # ìµœëŒ€ 10ê°œ ìœ í˜•

        # ëª…í™•ì„± (ë…¸ë“œì˜ í‰ê·  ì‹ ë¢°ë„)
        if graph.nodes:
            node_confidences = [node.confidence for node in graph.nodes.values()]
            quality["clarity"] = sum(node_confidences) / len(node_confidences)

        # ê°•ë„ (ì—£ì§€ì˜ í‰ê·  ê°•ë„)
        if graph.edges:
            edge_strengths = [edge.strength for edge in graph.edges.values()]
            quality["strength"] = sum(edge_strengths) / len(edge_strengths)

        # ì¼ê´€ì„± (ê·¸ë˜í”„ì˜ ì¼ê´€ì„± ì ìˆ˜)
        quality["coherence"] = graph.coherence_score

        # ë™ì ì„± (ì§„í™” íˆìŠ¤í† ë¦¬ ê¸°ë°˜)
        quality["dynamism"] = min(len(graph.evolution_history) / 5.0, 1.0)

        # ì¢…í•© í’ˆì§ˆ
        quality["overall_quality"] = (
            quality["logical_consistency"] * 0.25
            + quality["completeness"] * 0.15
            + quality["clarity"] * 0.2
            + quality["strength"] * 0.2
            + quality["coherence"] * 0.15
            + quality["dynamism"] * 0.05
        )

        return quality

    def _detect_and_resolve_inconsistencies(
        self, graph: DynamicReasoningGraph
    ) -> Dict[str, Any]:
        """ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²°"""
        inconsistencies = {
            "detected_inconsistencies": [],
            "resolved_inconsistencies": [],
            "inconsistency_score": 0.0,
        }

        # ëª¨ìˆœë˜ëŠ” ì—£ì§€ íƒì§€
        contradiction_edges = []
        for edge in graph.edges.values():
            if edge.edge_type == EdgeType.CONTRADICTS:
                contradiction_edges.append(edge)

        # ëª¨ìˆœë˜ëŠ” ë…¸ë“œ ìŒ íƒì§€
        contradictory_nodes = []
        for i, node1 in enumerate(list(graph.nodes.values())):
            for node2 in list(graph.nodes.values())[i + 1 :]:
                similarity = self.semantic_engine.calculate_semantic_similarity(
                    node1.content, node2.content
                )
                if (
                    similarity > 0.8
                    and node1.confidence > 0.7
                    and node2.confidence > 0.7
                ):
                    # ë†’ì€ ìœ ì‚¬ë„ì™€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ë…¸ë“œë“¤ì´ ëª¨ìˆœë  ê°€ëŠ¥ì„±
                    contradictory_nodes.append((node1, node2))

        # ë¶ˆì¼ì¹˜ ì ìˆ˜ ê³„ì‚°
        total_inconsistencies = len(contradiction_edges) + len(contradictory_nodes)
        inconsistency_score = min(total_inconsistencies / max(len(graph.nodes), 1), 1.0)

        inconsistencies.update(
            {
                "detected_inconsistencies": [
                    {"type": "contradiction_edge", "edge_id": edge.edge_id}
                    for edge in contradiction_edges
                ]
                + [
                    {
                        "type": "contradictory_nodes",
                        "node1_id": n1.node_id,
                        "node2_id": n2.node_id,
                    }
                    for n1, n2 in contradictory_nodes
                ],
                "inconsistency_score": inconsistency_score,
            }
        )

        return inconsistencies


async def test_dynamic_reasoning_graph_system():
    """ë™ì  ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=== ë™ì  ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Phase 1-3 Week 3 Day 1) ===")

    analyzer = DynamicReasoningGraphAnalyzer()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_situation = "ê±°ì§“ë§ì„ í•´ì•¼ í•˜ëŠ” ìƒí™©"
    test_semantic_context = {
        "situation_type": "ethical_dilemma",
        "intent": "deception",
        "value_conflicts": ["honesty_vs_harm_prevention"],
        "confidence_score": 0.9,
    }
    test_philosophical_arguments = {
        "kantian": {
            "final_conclusion": "ê±°ì§“ë§ì€ ë„ë•ì ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠëŠ”ë‹¤",
            "strength": 0.8,
        },
        "utilitarian": {
            "final_conclusion": "ê±°ì§“ë§ì€ ë„ë•ì ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠëŠ”ë‹¤",
            "strength": 0.7,
        },
        "integrated": {
            "recommendation": "ë‘ ê´€ì  ëª¨ë‘ ê±°ì§“ë§ì„ ê¸ˆì§€í•œë‹¤",
            "strength": 0.75,
        },
    }

    # ë™ì  ì¶”ë¡  ê³¼ì • ë¶„ì„
    analysis_result = await analyzer.analyze_dynamic_reasoning_process(
        test_situation, test_semantic_context, test_philosophical_arguments
    )

    # ê²°ê³¼ ì¶œë ¥
    reasoning_graph = analysis_result["reasoning_graph"]
    graph_analysis = analysis_result["graph_analysis"]
    quality_assessment = analysis_result["quality_assessment"]
    inconsistency_analysis = analysis_result["inconsistency_analysis"]

    print(f"\nğŸ“Š ë™ì  ì¶”ë¡  ê·¸ë˜í”„ ë¶„ì„:")
    print(f"  â€¢ ë…¸ë“œ ìˆ˜: {graph_analysis['node_count']}")
    print(f"  â€¢ ì—£ì§€ ìˆ˜: {graph_analysis['edge_count']}")
    print(f"  â€¢ ë…¸ë“œ ìœ í˜•: {graph_analysis['node_types']}")
    print(f"  â€¢ ì—£ì§€ ìœ í˜•: {graph_analysis['edge_types']}")
    print(f"  â€¢ ì—°ê²°ì„±: {graph_analysis['connectivity']:.2f}")
    print(f"  â€¢ ê¹Šì´: {graph_analysis['depth']}")
    print(f"  â€¢ ì˜ë¯¸ì  ì¼ê´€ì„±: {graph_analysis['semantic_coherence']:.2f}")
    print(f"  â€¢ ì§„í™” ë‹¨ê³„: {graph_analysis['evolution_steps']}")

    print(f"\nğŸ¯ ë™ì  ì¶”ë¡  í’ˆì§ˆ í‰ê°€:")
    print(f"  â€¢ ì¢…í•© í’ˆì§ˆ: {quality_assessment['overall_quality']:.2f}")
    print(f"  â€¢ ë…¼ë¦¬ì  ì¼ê´€ì„±: {quality_assessment['logical_consistency']:.2f}")
    print(f"  â€¢ ì™„ì „ì„±: {quality_assessment['completeness']:.2f}")
    print(f"  â€¢ ëª…í™•ì„±: {quality_assessment['clarity']:.2f}")
    print(f"  â€¢ ê°•ë„: {quality_assessment['strength']:.2f}")
    print(f"  â€¢ ì¼ê´€ì„±: {quality_assessment['coherence']:.2f}")
    print(f"  â€¢ ë™ì ì„±: {quality_assessment['dynamism']:.2f}")

    print(f"\nğŸ” ë¶ˆì¼ì¹˜ ë¶„ì„:")
    print(f"  â€¢ ë¶ˆì¼ì¹˜ ì ìˆ˜: {inconsistency_analysis['inconsistency_score']:.2f}")
    print(
        f"  â€¢ íƒì§€ëœ ë¶ˆì¼ì¹˜: {len(inconsistency_analysis['detected_inconsistencies'])}"
    )

    print(f"\nğŸ” ë™ì  ì¶”ë¡  ë…¸ë“œ ìƒì„¸:")
    for node_id, node in reasoning_graph.nodes.items():
        print(
            f"  â€¢ {node_id}: {node.content} (ì‹ ë¢°ë„: {node.confidence:.2f}, ì¤‘ìš”ë„: {node.importance_score:.2f})"
        )

    print(f"\nğŸ”— ë™ì  ì¶”ë¡  ì—£ì§€ ìƒì„¸:")
    for edge_id, edge in reasoning_graph.edges.items():
        print(
            f"  â€¢ {edge_id}: {edge.source_node} â†’ {edge.target_node} (ê°•ë„: {edge.strength:.2f}, ìœ ì‚¬ë„: {edge.semantic_similarity:.2f})"
        )

    print(f"\n{'='*70}")
    print("=== ë™ì  ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Phase 1-3 Week 3 Day 1) ===")
    print("âœ… Day 1 ëª©í‘œ ë‹¬ì„±: ë™ì  ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ë™ì  ë…¸ë“œ ìƒì„± ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ë™ì  ì—£ì§€ ìƒì„± ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ì˜ë¯¸ ê¸°ë°˜ ë…¸ë“œ ì—°ê²° ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²° ì‹œìŠ¤í…œ êµ¬í˜„")


if __name__ == "__main__":
    asyncio.run(test_dynamic_reasoning_graph_system())
