#!/usr/bin/env python3
"""
DuRi ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ - Phase 1-3 Week 3 Day 6
ë™ì  ì¶”ë¡  ê·¸ë˜í”„ì˜ ì‹¤ì‹œê°„ í•™ìŠµì„ ê´€ë¦¬í•˜ëŠ” ì‹œìŠ¤í…œ

ê¸°ëŠ¥:
1. í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ
2. ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ
3. í•™ìŠµ ì„±ê³¼ í‰ê°€ ì‹œìŠ¤í…œ
4. í•™ìŠµ ê²€ì¦ ì‹œìŠ¤í…œ
"""

import asyncio
import heapq
import json
import logging
import os
import pickle
import random
import re
from collections import defaultdict, deque
from dataclasses import asdict, dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# í…ŒìŠ¤íŠ¸ìš© í´ë˜ìŠ¤ë“¤ (ë¨¼ì € ì •ì˜)
class NodeType(Enum):
    """ë…¸ë“œ ìœ í˜• - í™•ì¥ëœ ë²„ì „"""

    PREMISE = "premise"
    INFERENCE = "inference"
    CONCLUSION = "conclusion"
    COUNTER_ARGUMENT = "counter_argument"
    EVIDENCE = "evidence"
    ASSUMPTION = "assumption"
    HYPOTHESIS = "hypothesis"
    CONSTRAINT = "constraint"
    ALTERNATIVE = "alternative"
    INTEGRATION = "integration"


class EdgeType(Enum):
    """ì—£ì§€ ìœ í˜• - í™•ì¥ëœ ë²„ì „"""

    SUPPORTS = "supports"
    CONTRADICTS = "contradicts"
    INFERS = "infers"
    ASSUMES = "assumes"
    EVIDENCES = "evidences"
    CONSTRAINS = "constrains"
    ALTERNATES = "alternates"
    INTEGRATES = "integrates"
    CHALLENGES = "challenges"
    REFINES = "refines"


@dataclass
class DynamicReasoningNode:
    """ë™ì  ì¶”ë¡  ë…¸ë“œ (í…ŒìŠ¤íŠ¸ìš©)"""

    node_id: str
    node_type: NodeType
    content: str
    confidence: float
    source: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    semantic_vector: Optional[np.ndarray] = None
    activation_level: float = 1.0
    importance_score: float = 0.5


@dataclass
class DynamicReasoningEdge:
    """ë™ì  ì¶”ë¡  ì—£ì§€ (í…ŒìŠ¤íŠ¸ìš©)"""

    edge_id: str
    source_node: str
    target_node: str
    edge_type: EdgeType
    strength: float
    reasoning: str
    semantic_similarity: float = 0.0
    logical_validity: float = 0.0


@dataclass
class DynamicReasoningGraph:
    """ë™ì  ì¶”ë¡  ê·¸ë˜í”„ (í…ŒìŠ¤íŠ¸ìš©)"""

    graph_id: str
    nodes: Dict[str, DynamicReasoningNode] = field(default_factory=dict)
    edges: Dict[str, DynamicReasoningEdge] = field(default_factory=dict)


class LearningDataType(Enum):
    """í•™ìŠµ ë°ì´í„° ìœ í˜•"""

    USER_INTERACTION = "user_interaction"
    SYSTEM_FEEDBACK = "system_feedback"
    PERFORMANCE_METRIC = "performance_metric"
    ERROR_CORRECTION = "error_correction"
    ADAPTATION_DATA = "adaptation_data"


class LearningTrigger(Enum):
    """í•™ìŠµ íŠ¸ë¦¬ê±° ìœ í˜•"""

    PERFORMANCE_DEGRADATION = "performance_degradation"
    USER_FEEDBACK = "user_feedback"
    ERROR_DETECTION = "error_detection"
    AUTOMATIC_SCHEDULE = "automatic_schedule"
    ADAPTATION_NEEDED = "adaptation_needed"


@dataclass
class LearningData:
    """í•™ìŠµ ë°ì´í„°"""

    data_id: str
    data_type: LearningDataType
    timestamp: datetime
    content: Dict[str, Any]
    source: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    processed: bool = False


@dataclass
class LearningResult:
    """í•™ìŠµ ê²°ê³¼"""

    learning_id: str
    trigger: LearningTrigger
    success: bool
    confidence: float
    description: str
    improvements: List[str] = field(default_factory=list)
    metrics: Dict[str, float] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)


class LearningDataCollector:
    """í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_storage = {}
        self.collection_rules = self._initialize_collection_rules()
        self.data_queue = deque(maxlen=1000)
        self.collection_stats = defaultdict(int)

    def _initialize_collection_rules(self) -> Dict[str, Dict[str, Any]]:
        """ìˆ˜ì§‘ ê·œì¹™ ì´ˆê¸°í™”"""
        return {
            "user_interaction": {
                "enabled": True,
                "priority": "high",
                "max_storage": 1000,
                "retention_days": 30,
            },
            "system_feedback": {
                "enabled": True,
                "priority": "medium",
                "max_storage": 500,
                "retention_days": 60,
            },
            "performance_metric": {
                "enabled": True,
                "priority": "high",
                "max_storage": 2000,
                "retention_days": 90,
            },
            "error_correction": {
                "enabled": True,
                "priority": "high",
                "max_storage": 500,
                "retention_days": 120,
            },
            "adaptation_data": {
                "enabled": True,
                "priority": "medium",
                "max_storage": 300,
                "retention_days": 45,
            },
        }

    async def collect_learning_data(
        self,
        data_type: LearningDataType,
        content: Dict[str, Any],
        source: str = "system",
    ) -> str:
        """í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘"""
        logger.info(f"í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {data_type.value}")

        # ë°ì´í„° ID ìƒì„±
        data_id = f"{data_type.value}_{int(datetime.now().timestamp())}_{random.randint(1000, 9999)}"

        # í•™ìŠµ ë°ì´í„° ìƒì„±
        learning_data = LearningData(
            data_id=data_id,
            data_type=data_type,
            timestamp=datetime.now(),
            content=content,
            source=source,
            metadata={
                "collection_timestamp": datetime.now().isoformat(),
                "data_size": len(str(content)),
                "priority": self.collection_rules.get(data_type.value, {}).get(
                    "priority", "medium"
                ),
            },
        )

        # ë°ì´í„° ì €ì¥
        self.data_storage[data_id] = learning_data
        self.data_queue.append(learning_data)

        # í†µê³„ ì—…ë°ì´íŠ¸
        self.collection_stats[data_type.value] += 1

        logger.info(f"í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {data_id}")
        return data_id

    async def collect_user_interaction(
        self, user_id: str, interaction_type: str, interaction_data: Dict[str, Any]
    ) -> str:
        """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„° ìˆ˜ì§‘"""
        content = {
            "user_id": user_id,
            "interaction_type": interaction_type,
            "interaction_data": interaction_data,
            "timestamp": datetime.now().isoformat(),
        }

        return await self.collect_learning_data(
            LearningDataType.USER_INTERACTION, content, f"user_{user_id}"
        )

    async def collect_system_feedback(
        self, feedback_type: str, feedback_data: Dict[str, Any]
    ) -> str:
        """ì‹œìŠ¤í…œ í”¼ë“œë°± ë°ì´í„° ìˆ˜ì§‘"""
        content = {
            "feedback_type": feedback_type,
            "feedback_data": feedback_data,
            "timestamp": datetime.now().isoformat(),
        }

        return await self.collect_learning_data(
            LearningDataType.SYSTEM_FEEDBACK, content, "system"
        )

    async def collect_performance_metric(
        self, metric_name: str, metric_value: float, context: Dict[str, Any] = None
    ) -> str:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘"""
        content = {
            "metric_name": metric_name,
            "metric_value": metric_value,
            "context": context or {},
            "timestamp": datetime.now().isoformat(),
        }

        return await self.collect_learning_data(
            LearningDataType.PERFORMANCE_METRIC, content, "system"
        )

    async def collect_error_correction(
        self,
        error_type: str,
        error_data: Dict[str, Any],
        correction_data: Dict[str, Any],
    ) -> str:
        """ì˜¤ë¥˜ ìˆ˜ì • ë°ì´í„° ìˆ˜ì§‘"""
        content = {
            "error_type": error_type,
            "error_data": error_data,
            "correction_data": correction_data,
            "timestamp": datetime.now().isoformat(),
        }

        return await self.collect_learning_data(
            LearningDataType.ERROR_CORRECTION, content, "system"
        )

    async def get_learning_data(
        self, data_type: Optional[LearningDataType] = None, limit: int = 100
    ) -> List[LearningData]:
        """í•™ìŠµ ë°ì´í„° ì¡°íšŒ"""
        if data_type:
            filtered_data = [
                data
                for data in self.data_storage.values()
                if data.data_type == data_type
            ]
        else:
            filtered_data = list(self.data_storage.values())

        # ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
        filtered_data.sort(key=lambda x: x.timestamp, reverse=True)

        return filtered_data[:limit]

    async def cleanup_old_data(self) -> int:
        """ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬"""
        current_time = datetime.now()
        cleaned_count = 0

        for data_id, data in list(self.data_storage.items()):
            rule = self.collection_rules.get(data.data_type.value, {})
            retention_days = rule.get("retention_days", 30)

            if (current_time - data.timestamp).days > retention_days:
                del self.data_storage[data_id]
                cleaned_count += 1

        logger.info(f"ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ: {cleaned_count}ê°œ ì‚­ì œ")
        return cleaned_count


class RealtimeModelUpdater:
    """ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.model_versions = {}
        self.update_strategies = self._initialize_update_strategies()
        self.update_history = []
        self.model_performance = defaultdict(list)

    def _initialize_update_strategies(self) -> Dict[str, Dict[str, Any]]:
        """ì—…ë°ì´íŠ¸ ì „ëµ ì´ˆê¸°í™”"""
        return {
            "incremental": {
                "description": "ì ì§„ì  ì—…ë°ì´íŠ¸",
                "update_frequency": "daily",
                "batch_size": 100,
                "learning_rate": 0.01,
            },
            "adaptive": {
                "description": "ì ì‘ì  ì—…ë°ì´íŠ¸",
                "update_frequency": "on_demand",
                "batch_size": 50,
                "learning_rate": 0.02,
            },
            "comprehensive": {
                "description": "í¬ê´„ì  ì—…ë°ì´íŠ¸",
                "update_frequency": "weekly",
                "batch_size": 500,
                "learning_rate": 0.005,
            },
        }

    async def update_model(
        self,
        graph: "DynamicReasoningGraph",
        learning_data: List[LearningData],
        strategy: str = "adaptive",
    ) -> LearningResult:
        """ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        logger.info(f"ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œì‘: {strategy}")

        learning_id = f"learning_{int(datetime.now().timestamp())}"
        strategy_config = self.update_strategies.get(
            strategy, self.update_strategies["adaptive"]
        )

        improvements = []
        metrics = {}

        try:
            # 1. ë…¸ë“œ ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸
            node_improvements = await self._update_node_confidence(graph, learning_data)
            improvements.extend(node_improvements)

            # 2. ì—£ì§€ ê°•ë„ ì—…ë°ì´íŠ¸
            edge_improvements = await self._update_edge_strength(graph, learning_data)
            improvements.extend(edge_improvements)

            # 3. ì—°ê²°ì„± ìµœì í™”
            connectivity_improvements = await self._optimize_connectivity(
                graph, learning_data
            )
            improvements.extend(connectivity_improvements)

            # 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics = await self._calculate_learning_metrics(graph, learning_data)

            # 5. ëª¨ë¸ ë²„ì „ ê´€ë¦¬
            version_info = await self._create_model_version(graph, strategy, metrics)

            learning_result = LearningResult(
                learning_id=learning_id,
                trigger=LearningTrigger.ADAPTATION_NEEDED,
                success=True,
                confidence=metrics.get("overall_confidence", 0.7),
                description=f"ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(improvements)}ê°œ ê°œì„ ì‚¬í•­",
                improvements=improvements,
                metrics=metrics,
            )

            # ì—…ë°ì´íŠ¸ ì´ë ¥ì— ì¶”ê°€
            self.update_history.append(
                {
                    "learning_result": learning_result,
                    "version_info": version_info,
                    "timestamp": datetime.now(),
                }
            )

            logger.info(f"ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(improvements)}ê°œ ê°œì„ ì‚¬í•­")
            return learning_result

        except Exception as e:
            logger.error(f"ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return LearningResult(
                learning_id=learning_id,
                trigger=LearningTrigger.ADAPTATION_NEEDED,
                success=False,
                confidence=0.0,
                description=f"ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}",
            )

    async def _update_node_confidence(
        self, graph: "DynamicReasoningGraph", learning_data: List[LearningData]
    ) -> List[str]:
        """ë…¸ë“œ ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸"""
        improvements = []

        for node_id, node in graph.nodes.items():
            # í•™ìŠµ ë°ì´í„°ì—ì„œ í•´ë‹¹ ë…¸ë“œì™€ ê´€ë ¨ëœ í”¼ë“œë°± ì°¾ê¸°
            relevant_feedback = []
            for data in learning_data:
                if data.data_type == LearningDataType.USER_INTERACTION:
                    if node_id in str(data.content):
                        relevant_feedback.append(data)
                elif data.data_type == LearningDataType.SYSTEM_FEEDBACK:
                    if node_id in str(data.content):
                        relevant_feedback.append(data)

            if relevant_feedback:
                # í”¼ë“œë°± ê¸°ë°˜ ì‹ ë¢°ë„ ì¡°ì •
                feedback_score = self._calculate_feedback_score(relevant_feedback)
                old_confidence = node.confidence
                node.confidence = min(
                    1.0, max(0.0, old_confidence + feedback_score * 0.1)
                )

                if abs(node.confidence - old_confidence) > 0.01:
                    improvements.append(
                        f"ë…¸ë“œ {node_id} ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸: {old_confidence:.3f} â†’ {node.confidence:.3f}"
                    )

        return improvements

    async def _update_edge_strength(
        self, graph: "DynamicReasoningGraph", learning_data: List[LearningData]
    ) -> List[str]:
        """ì—£ì§€ ê°•ë„ ì—…ë°ì´íŠ¸"""
        improvements = []

        for edge_id, edge in graph.edges.items():
            # í•™ìŠµ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì—£ì§€ì™€ ê´€ë ¨ëœ í”¼ë“œë°± ì°¾ê¸°
            relevant_feedback = []
            for data in learning_data:
                if data.data_type == LearningDataType.USER_INTERACTION:
                    if (
                        edge_id in str(data.content)
                        or edge.source_node in str(data.content)
                        or edge.target_node in str(data.content)
                    ):
                        relevant_feedback.append(data)

            if relevant_feedback:
                # í”¼ë“œë°± ê¸°ë°˜ ê°•ë„ ì¡°ì •
                feedback_score = self._calculate_feedback_score(relevant_feedback)
                old_strength = edge.strength
                edge.strength = min(1.0, max(0.0, old_strength + feedback_score * 0.1))

                if abs(edge.strength - old_strength) > 0.01:
                    improvements.append(
                        f"ì—£ì§€ {edge_id} ê°•ë„ ì—…ë°ì´íŠ¸: {old_strength:.3f} â†’ {edge.strength:.3f}"
                    )

        return improvements

    async def _optimize_connectivity(
        self, graph: "DynamicReasoningGraph", learning_data: List[LearningData]
    ) -> List[str]:
        """ì—°ê²°ì„± ìµœì í™”"""
        improvements = []

        # ê³ ë¦½ëœ ë…¸ë“œ ì°¾ê¸°
        isolated_nodes = []
        for node_id in graph.nodes:
            has_connection = False
            for edge in graph.edges.values():
                if edge.source_node == node_id or edge.target_node == node_id:
                    has_connection = True
                    break

            if not has_connection:
                isolated_nodes.append(node_id)

        # ê³ ë¦½ëœ ë…¸ë“œë“¤ì„ ë‹¤ë¥¸ ë…¸ë“œì™€ ì—°ê²°
        for node_id in isolated_nodes:
            node = graph.nodes.get(node_id)
            if node:
                # ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë“œ ì°¾ê¸°
                best_similarity = 0.0
                best_target = None

                for target_id, target_node in graph.nodes.items():
                    if target_id != node_id:
                        # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚°
                        similarity = await self._calculate_simple_similarity(
                            node.content, target_node.content
                        )
                        if similarity > best_similarity:
                            best_similarity = similarity
                            best_target = target_id

                # ìƒˆë¡œìš´ ì—£ì§€ ìƒì„±
                if best_target and best_similarity > 0.2:
                    new_edge_id = f"learning_edge_{node_id}_{best_target}"
                    new_edge = DynamicReasoningEdge(
                        edge_id=new_edge_id,
                        source_node=node_id,
                        target_node=best_target,
                        edge_type=EdgeType.SUPPORTS,
                        strength=best_similarity,
                        reasoning=f"í•™ìŠµ ê¸°ë°˜ ì—°ê²°ì„± ìµœì í™” (ìœ ì‚¬ë„: {best_similarity:.2f})",
                        semantic_similarity=best_similarity,
                    )
                    graph.edges[new_edge_id] = new_edge
                    improvements.append(
                        f"ê³ ë¦½ëœ ë…¸ë“œ {node_id} ì—°ê²° ìƒì„±: {best_target} (ìœ ì‚¬ë„: {best_similarity:.2f})"
                    )

        return improvements

    async def _calculate_learning_metrics(
        self, graph: "DynamicReasoningGraph", learning_data: List[LearningData]
    ) -> Dict[str, float]:
        """í•™ìŠµ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {}

        # í‰ê·  ë…¸ë“œ ì‹ ë¢°ë„
        node_confidences = [node.confidence for node in graph.nodes.values()]
        metrics["avg_node_confidence"] = (
            sum(node_confidences) / len(node_confidences) if node_confidences else 0.0
        )

        # í‰ê·  ì—£ì§€ ê°•ë„
        edge_strengths = [edge.strength for edge in graph.edges.values()]
        metrics["avg_edge_strength"] = (
            sum(edge_strengths) / len(edge_strengths) if edge_strengths else 0.0
        )

        # ì—°ê²°ì„±
        total_nodes = len(graph.nodes)
        total_edges = len(graph.edges)
        metrics["connectivity"] = (
            total_edges / (total_nodes * (total_nodes - 1) / 2)
            if total_nodes > 1
            else 0.0
        )

        # í•™ìŠµ ë°ì´í„° í’ˆì§ˆ
        metrics["learning_data_quality"] = (
            len([d for d in learning_data if d.processed]) / len(learning_data)
            if learning_data
            else 0.0
        )

        # ì¢…í•© ì‹ ë¢°ë„
        metrics["overall_confidence"] = (
            metrics["avg_node_confidence"] + metrics["avg_edge_strength"]
        ) / 2.0

        return metrics

    async def _create_model_version(
        self, graph: "DynamicReasoningGraph", strategy: str, metrics: Dict[str, float]
    ) -> Dict[str, Any]:
        """ëª¨ë¸ ë²„ì „ ìƒì„±"""
        version_id = (
            f"v{len(self.model_versions) + 1}_{int(datetime.now().timestamp())}"
        )

        version_info = {
            "version_id": version_id,
            "strategy": strategy,
            "timestamp": datetime.now().isoformat(),
            "metrics": metrics,
            "node_count": len(graph.nodes),
            "edge_count": len(graph.edges),
        }

        self.model_versions[version_id] = version_info
        return version_info

    def _calculate_feedback_score(self, feedback_data: List[LearningData]) -> float:
        """í”¼ë“œë°± ì ìˆ˜ ê³„ì‚°"""
        if not feedback_data:
            return 0.0

        total_score = 0.0
        for data in feedback_data:
            if data.data_type == LearningDataType.USER_INTERACTION:
                # ì‚¬ìš©ì ìƒí˜¸ì‘ìš©ì€ ì–‘ìˆ˜ ì ìˆ˜
                total_score += 0.1
            elif data.data_type == LearningDataType.SYSTEM_FEEDBACK:
                # ì‹œìŠ¤í…œ í”¼ë“œë°±ì€ ì¤‘ì„± ì ìˆ˜
                total_score += 0.0
            elif data.data_type == LearningDataType.ERROR_CORRECTION:
                # ì˜¤ë¥˜ ìˆ˜ì •ì€ ì–‘ìˆ˜ ì ìˆ˜
                total_score += 0.2

        return total_score / len(feedback_data)

    async def _calculate_simple_similarity(self, text1: str, text2: str) -> float:
        """ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚°"""
        keywords1 = set(re.findall(r"[ê°€-í£a-zA-Z]+", text1.lower()))
        keywords2 = set(re.findall(r"[ê°€-í£a-zA-Z]+", text2.lower()))

        if not keywords1 or not keywords2:
            return 0.0

        intersection = len(keywords1.intersection(keywords2))
        union = len(keywords1.union(keywords2))

        return intersection / union if union > 0 else 0.0


class LearningPerformanceEvaluator:
    """í•™ìŠµ ì„±ê³¼ í‰ê°€ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.evaluation_criteria = self._initialize_evaluation_criteria()
        self.performance_history = []

    def _initialize_evaluation_criteria(self) -> Dict[str, Dict[str, Any]]:
        """í‰ê°€ ê¸°ì¤€ ì´ˆê¸°í™”"""
        return {
            "accuracy_improvement": {"weight": 0.3, "description": "ì •í™•ë„ í–¥ìƒ"},
            "adaptability": {"weight": 0.25, "description": "ì ì‘ì„±"},
            "efficiency": {"weight": 0.25, "description": "íš¨ìœ¨ì„±"},
            "stability": {"weight": 0.2, "description": "ì•ˆì •ì„±"},
        }

    async def evaluate_learning_performance(
        self,
        graph: "DynamicReasoningGraph",
        learning_data: List[LearningData],
        learning_result: LearningResult,
    ) -> Dict[str, Any]:
        """í•™ìŠµ ì„±ê³¼ í‰ê°€"""
        logger.info(f"í•™ìŠµ ì„±ê³¼ í‰ê°€ ì‹œì‘: {learning_result.learning_id}")

        # 1. ì •í™•ë„ í–¥ìƒ í‰ê°€
        accuracy_improvement = await self._evaluate_accuracy_improvement(
            graph, learning_data
        )

        # 2. ì ì‘ì„± í‰ê°€
        adaptability = await self._evaluate_adaptability(graph, learning_data)

        # 3. íš¨ìœ¨ì„± í‰ê°€
        efficiency = await self._evaluate_efficiency(learning_result)

        # 4. ì•ˆì •ì„± í‰ê°€
        stability = await self._evaluate_stability(graph)

        # ì¢…í•© ì„±ê³¼ ì ìˆ˜
        overall_performance = (
            accuracy_improvement
            * self.evaluation_criteria["accuracy_improvement"]["weight"]
            + adaptability * self.evaluation_criteria["adaptability"]["weight"]
            + efficiency * self.evaluation_criteria["efficiency"]["weight"]
            + stability * self.evaluation_criteria["stability"]["weight"]
        )

        evaluation_result = {
            "overall_performance": overall_performance,
            "accuracy_improvement": accuracy_improvement,
            "adaptability": adaptability,
            "efficiency": efficiency,
            "stability": stability,
            "evaluation_details": {
                "learning_data_count": len(learning_data),
                "improvements_count": len(learning_result.improvements),
                "graph_complexity": len(graph.nodes) + len(graph.edges),
            },
        }

        # ì„±ê³¼ ì´ë ¥ì— ì¶”ê°€
        self.performance_history.append(
            {
                "evaluation_result": evaluation_result,
                "learning_result": learning_result,
                "timestamp": datetime.now(),
            }
        )

        return evaluation_result

    async def _evaluate_accuracy_improvement(
        self, graph: "DynamicReasoningGraph", learning_data: List[LearningData]
    ) -> float:
        """ì •í™•ë„ í–¥ìƒ í‰ê°€"""
        if not learning_data:
            return 0.0

        # ë…¸ë“œ ì‹ ë¢°ë„ í–¥ìƒ
        node_confidences = [node.confidence for node in graph.nodes.values()]
        avg_confidence = (
            sum(node_confidences) / len(node_confidences) if node_confidences else 0.0
        )

        # ì—£ì§€ ê°•ë„ í–¥ìƒ
        edge_strengths = [edge.strength for edge in graph.edges.values()]
        avg_strength = (
            sum(edge_strengths) / len(edge_strengths) if edge_strengths else 0.0
        )

        # í•™ìŠµ ë°ì´í„° í’ˆì§ˆ
        processed_data = [d for d in learning_data if d.processed]
        data_quality = (
            len(processed_data) / len(learning_data) if learning_data else 0.0
        )

        # ì¢…í•© ì •í™•ë„ í–¥ìƒ
        accuracy_improvement = (avg_confidence + avg_strength + data_quality) / 3.0

        return accuracy_improvement

    async def _evaluate_adaptability(
        self, graph: "DynamicReasoningGraph", learning_data: List[LearningData]
    ) -> float:
        """ì ì‘ì„± í‰ê°€"""
        if not learning_data:
            return 0.0

        # ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜• ì²˜ë¦¬ ëŠ¥ë ¥
        data_types = set(data.data_type for data in learning_data)
        type_diversity = len(data_types) / len(LearningDataType)

        # ì—°ê²°ì„± ì ì‘ì„±
        total_nodes = len(graph.nodes)
        total_edges = len(graph.edges)
        connectivity_adaptability = (
            min(1.0, total_edges / (total_nodes * 2)) if total_nodes > 0 else 0.0
        )

        # í•™ìŠµ ì†ë„
        recent_data = [
            d for d in learning_data if (datetime.now() - d.timestamp).days <= 7
        ]
        learning_speed = len(recent_data) / max(1, len(learning_data))

        # ì¢…í•© ì ì‘ì„±
        adaptability = (
            type_diversity + connectivity_adaptability + learning_speed
        ) / 3.0

        return adaptability

    async def _evaluate_efficiency(self, learning_result: LearningResult) -> float:
        """íš¨ìœ¨ì„± í‰ê°€"""
        if not learning_result.success:
            return 0.0

        # ê°œì„ ì‚¬í•­ ìˆ˜
        improvements_count = len(learning_result.improvements)
        efficiency_score = min(
            1.0, improvements_count / 10.0
        )  # ìµœëŒ€ 10ê°œ ê°œì„ ì‚¬í•­ ê¸°ì¤€

        # ì‹ ë¢°ë„
        confidence_score = learning_result.confidence

        # ë©”íŠ¸ë¦­ í’ˆì§ˆ
        metrics_quality = len(learning_result.metrics) / 5.0  # ìµœëŒ€ 5ê°œ ë©”íŠ¸ë¦­ ê¸°ì¤€

        # ì¢…í•© íš¨ìœ¨ì„±
        efficiency = (efficiency_score + confidence_score + metrics_quality) / 3.0

        return efficiency

    async def _evaluate_stability(self, graph: "DynamicReasoningGraph") -> float:
        """ì•ˆì •ì„± í‰ê°€"""
        if not graph.nodes:
            return 0.0

        # ë…¸ë“œ ì‹ ë¢°ë„ì˜ í‘œì¤€í¸ì°¨ (ë‚®ì„ìˆ˜ë¡ ì•ˆì •ì )
        node_confidences = [node.confidence for node in graph.nodes.values()]
        if len(node_confidences) < 2:
            return 0.5

        confidence_std = np.std(node_confidences)
        confidence_stability = max(0.0, 1.0 - confidence_std)

        # ì—£ì§€ ê°•ë„ì˜ í‘œì¤€í¸ì°¨
        edge_strengths = [edge.strength for edge in graph.edges.values()]
        if len(edge_strengths) < 2:
            return confidence_stability

        strength_std = np.std(edge_strengths)
        strength_stability = max(0.0, 1.0 - strength_std)

        # ì—°ê²°ì„± ì•ˆì •ì„±
        total_nodes = len(graph.nodes)
        total_edges = len(graph.edges)
        connectivity_stability = (
            min(1.0, total_edges / (total_nodes * (total_nodes - 1) / 2))
            if total_nodes > 1
            else 0.0
        )

        # ì¢…í•© ì•ˆì •ì„±
        stability = (
            confidence_stability + strength_stability + connectivity_stability
        ) / 3.0

        return stability


class LearningValidator:
    """í•™ìŠµ ê²€ì¦ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.validation_criteria = self._initialize_validation_criteria()

    def _initialize_validation_criteria(self) -> Dict[str, Dict[str, Any]]:
        """ê²€ì¦ ê¸°ì¤€ ì´ˆê¸°í™”"""
        return {
            "learning_success": {"weight": 0.3, "description": "í•™ìŠµ ì„±ê³µë¥ "},
            "performance_improvement": {"weight": 0.3, "description": "ì„±ëŠ¥ í–¥ìƒë„"},
            "system_stability": {"weight": 0.2, "description": "ì‹œìŠ¤í…œ ì•ˆì •ì„±"},
            "learning_efficiency": {"weight": 0.2, "description": "í•™ìŠµ íš¨ìœ¨ì„±"},
        }

    async def validate_learning(
        self,
        graph: "DynamicReasoningGraph",
        learning_result: LearningResult,
        performance_evaluation: Dict[str, Any],
    ) -> Dict[str, Any]:
        """í•™ìŠµ ê²€ì¦"""
        logger.info(f"í•™ìŠµ ê²€ì¦ ì‹œì‘: {learning_result.learning_id}")

        # 1. í•™ìŠµ ì„±ê³µë¥  í‰ê°€
        learning_success = self._evaluate_learning_success(learning_result)

        # 2. ì„±ëŠ¥ í–¥ìƒë„ í‰ê°€
        performance_improvement = await self._evaluate_performance_improvement(
            performance_evaluation
        )

        # 3. ì‹œìŠ¤í…œ ì•ˆì •ì„± í‰ê°€
        system_stability = await self._evaluate_system_stability(graph)

        # 4. í•™ìŠµ íš¨ìœ¨ì„± í‰ê°€
        learning_efficiency = self._evaluate_learning_efficiency(learning_result)

        # ì¢…í•© ê²€ì¦ ì ìˆ˜
        overall_score = (
            learning_success * self.validation_criteria["learning_success"]["weight"]
            + performance_improvement
            * self.validation_criteria["performance_improvement"]["weight"]
            + system_stability * self.validation_criteria["system_stability"]["weight"]
            + learning_efficiency
            * self.validation_criteria["learning_efficiency"]["weight"]
        )

        return {
            "overall_score": overall_score,
            "learning_success": learning_success,
            "performance_improvement": performance_improvement,
            "system_stability": system_stability,
            "learning_efficiency": learning_efficiency,
            "validation_details": {
                "improvements_count": len(learning_result.improvements),
                "metrics_count": len(learning_result.metrics),
                "graph_complexity": len(graph.nodes) + len(graph.edges),
            },
        }

    def _evaluate_learning_success(self, learning_result: LearningResult) -> float:
        """í•™ìŠµ ì„±ê³µë¥  í‰ê°€"""
        if not learning_result.success:
            return 0.0

        # ê°œì„ ì‚¬í•­ ìˆ˜
        improvements_score = min(1.0, len(learning_result.improvements) / 5.0)

        # ì‹ ë¢°ë„
        confidence_score = learning_result.confidence

        # ë©”íŠ¸ë¦­ í’ˆì§ˆ
        metrics_score = min(1.0, len(learning_result.metrics) / 3.0)

        return (improvements_score + confidence_score + metrics_score) / 3.0

    async def _evaluate_performance_improvement(
        self, performance_evaluation: Dict[str, Any]
    ) -> float:
        """ì„±ëŠ¥ í–¥ìƒë„ í‰ê°€"""
        overall_performance = performance_evaluation.get("overall_performance", 0.0)
        return overall_performance

    async def _evaluate_system_stability(self, graph: "DynamicReasoningGraph") -> float:
        """ì‹œìŠ¤í…œ ì•ˆì •ì„± í‰ê°€"""
        if not graph.nodes:
            return 0.0

        # ë…¸ë“œ ì‹ ë¢°ë„ì˜ í‘œì¤€í¸ì°¨
        node_confidences = [node.confidence for node in graph.nodes.values()]
        if len(node_confidences) < 2:
            return 0.5

        confidence_std = np.std(node_confidences)
        stability_score = max(0.0, 1.0 - confidence_std)

        return stability_score

    def _evaluate_learning_efficiency(self, learning_result: LearningResult) -> float:
        """í•™ìŠµ íš¨ìœ¨ì„± í‰ê°€"""
        if not learning_result.success:
            return 0.0

        # ê°œì„ ì‚¬í•­ ëŒ€ë¹„ ë©”íŠ¸ë¦­ ìˆ˜
        improvements_count = len(learning_result.improvements)
        metrics_count = len(learning_result.metrics)

        if improvements_count == 0:
            return 0.0

        efficiency = min(1.0, metrics_count / improvements_count)
        return efficiency


async def test_realtime_learning_system():
    """ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=== ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Phase 1-3 Week 3 Day 6) ===")

    # í…ŒìŠ¤íŠ¸ ê·¸ë˜í”„ ìƒì„±
    graph = DynamicReasoningGraph(graph_id="test_graph")

    # ì´ˆê¸° ë…¸ë“œë“¤ ìƒì„±
    initial_nodes = {
        "node1": DynamicReasoningNode(
            "node1", NodeType.PREMISE, "ìœ¤ë¦¬ì  í–‰ë™ì€ ì˜³ë‹¤", 0.8, "test"
        ),
        "node2": DynamicReasoningNode(
            "node2", NodeType.INFERENCE, "ìœ¤ë¦¬ì  í–‰ë™ ë¶„ì„: ë„ë•ì  ì˜ë¬´", 0.7, "test"
        ),
        "node3": DynamicReasoningNode(
            "node3", NodeType.CONCLUSION, "ìœ¤ë¦¬ì  í–‰ë™ í•„ìš”: ìµœì¢… íŒë‹¨", 0.9, "test"
        ),
        "node4": DynamicReasoningNode(
            "node4", NodeType.EVIDENCE, "ìœ¤ë¦¬ì  í–‰ë™ì˜ ì¦ê±°: ì‚¬íšŒì  ì´ìµ", 0.8, "test"
        ),
        "node5": DynamicReasoningNode(
            "node5",
            NodeType.COUNTER_ARGUMENT,
            "ìœ¤ë¦¬ì  í–‰ë™ì˜ ë°˜ë¡ : ììœ  ì œí•œ",
            0.6,
            "test",
        ),
    }

    graph.nodes = initial_nodes

    print(f"\nğŸ“Š ì´ˆê¸° ê·¸ë˜í”„ ìƒíƒœ:")
    print(f"  â€¢ ë…¸ë“œ ìˆ˜: {len(graph.nodes)}")
    print(f"  â€¢ ì—£ì§€ ìˆ˜: {len(graph.edges)}")

    # 1. í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
    data_collector = LearningDataCollector()

    print(f"\nğŸ“Š í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸:")

    # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„° ìˆ˜ì§‘
    user_interaction_id = await data_collector.collect_user_interaction(
        "user1",
        "node_feedback",
        {"node_id": "node1", "rating": 5, "comment": "ì¢‹ì€ ì „ì œ"},
    )
    print(f"  â€¢ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© ë°ì´í„° ìˆ˜ì§‘: {user_interaction_id}")

    # ì‹œìŠ¤í…œ í”¼ë“œë°± ë°ì´í„° ìˆ˜ì§‘
    system_feedback_id = await data_collector.collect_system_feedback(
        "performance_metric", {"metric": "accuracy", "value": 0.85}
    )
    print(f"  â€¢ ì‹œìŠ¤í…œ í”¼ë“œë°± ë°ì´í„° ìˆ˜ì§‘: {system_feedback_id}")

    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘
    performance_metric_id = await data_collector.collect_performance_metric(
        "node_confidence", 0.82, {"context": "user_interaction"}
    )
    print(f"  â€¢ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘: {performance_metric_id}")

    # ì˜¤ë¥˜ ìˆ˜ì • ë°ì´í„° ìˆ˜ì§‘
    error_correction_id = await data_collector.collect_error_correction(
        "semantic_error", {"error": "ì˜ë¯¸ì  ë¶ˆì¼ì¹˜"}, {"correction": "ì˜ë¯¸ì  ì¼ì¹˜ ê°œì„ "}
    )
    print(f"  â€¢ ì˜¤ë¥˜ ìˆ˜ì • ë°ì´í„° ìˆ˜ì§‘: {error_correction_id}")

    # ìˆ˜ì§‘ëœ ë°ì´í„° ì¡°íšŒ
    learning_data = await data_collector.get_learning_data()
    print(f"  â€¢ ìˆ˜ì§‘ëœ ë°ì´í„° ìˆ˜: {len(learning_data)}")

    # 2. ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
    model_updater = RealtimeModelUpdater()

    print(f"\nğŸ”„ ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸:")
    learning_result = await model_updater.update_model(graph, learning_data, "adaptive")

    print(f"  â€¢ í•™ìŠµ ì„±ê³µ: {learning_result.success}")
    print(f"  â€¢ ê°œì„ ì‚¬í•­ ìˆ˜: {len(learning_result.improvements)}")
    print(f"  â€¢ ì‹ ë¢°ë„: {learning_result.confidence:.3f}")

    if learning_result.improvements:
        print(f"  â€¢ ì£¼ìš” ê°œì„ ì‚¬í•­:")
        for improvement in learning_result.improvements[:3]:
            print(f"    - {improvement}")

    if learning_result.metrics:
        print(f"  â€¢ í•™ìŠµ ë©”íŠ¸ë¦­:")
        for metric, value in learning_result.metrics.items():
            print(f"    - {metric}: {value:.3f}")

    # 3. í•™ìŠµ ì„±ê³¼ í‰ê°€ í…ŒìŠ¤íŠ¸
    performance_evaluator = LearningPerformanceEvaluator()

    print(f"\nğŸ“Š í•™ìŠµ ì„±ê³¼ í‰ê°€ í…ŒìŠ¤íŠ¸:")
    performance_evaluation = await performance_evaluator.evaluate_learning_performance(
        graph, learning_data, learning_result
    )

    print(f"  â€¢ ì¢…í•© ì„±ê³¼ ì ìˆ˜: {performance_evaluation['overall_performance']:.3f}")
    print(f"  â€¢ ì •í™•ë„ í–¥ìƒ: {performance_evaluation['accuracy_improvement']:.3f}")
    print(f"  â€¢ ì ì‘ì„±: {performance_evaluation['adaptability']:.3f}")
    print(f"  â€¢ íš¨ìœ¨ì„±: {performance_evaluation['efficiency']:.3f}")
    print(f"  â€¢ ì•ˆì •ì„±: {performance_evaluation['stability']:.3f}")

    # 4. í•™ìŠµ ê²€ì¦ í…ŒìŠ¤íŠ¸
    learning_validator = LearningValidator()

    print(f"\nâœ… í•™ìŠµ ê²€ì¦ í…ŒìŠ¤íŠ¸:")
    validation_result = await learning_validator.validate_learning(
        graph, learning_result, performance_evaluation
    )

    print(f"  â€¢ ì¢…í•© ê²€ì¦ ì ìˆ˜: {validation_result['overall_score']:.3f}")
    print(f"  â€¢ í•™ìŠµ ì„±ê³µë¥ : {validation_result['learning_success']:.3f}")
    print(f"  â€¢ ì„±ëŠ¥ í–¥ìƒë„: {validation_result['performance_improvement']:.3f}")
    print(f"  â€¢ ì‹œìŠ¤í…œ ì•ˆì •ì„±: {validation_result['system_stability']:.3f}")
    print(f"  â€¢ í•™ìŠµ íš¨ìœ¨ì„±: {validation_result['learning_efficiency']:.3f}")

    # 5. ìµœì¢… ê·¸ë˜í”„ ìƒíƒœ
    print(f"\nğŸ“Š ìµœì¢… ê·¸ë˜í”„ ìƒíƒœ:")
    print(f"  â€¢ ë…¸ë“œ ìˆ˜: {len(graph.nodes)}")
    print(f"  â€¢ ì—£ì§€ ìˆ˜: {len(graph.edges)} (ì¦ê°€: {len(graph.edges) - 0})")

    # ë…¸ë“œ ì‹ ë¢°ë„ ë³€í™”
    print(f"  â€¢ ë…¸ë“œ ì‹ ë¢°ë„:")
    for node_id, node in graph.nodes.items():
        print(f"    - {node_id}: {node.confidence:.3f}")

    # ì—£ì§€ ê°•ë„ ë³€í™”
    if graph.edges:
        print(f"  â€¢ ì—£ì§€ ê°•ë„:")
        for edge_id, edge in list(graph.edges.items())[:3]:
            print(f"    - {edge_id}: {edge.strength:.3f}")

    print(f"\n{'='*70}")
    print("=== ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Phase 1-3 Week 3 Day 6) ===")
    print("âœ… Day 6 ëª©í‘œ ë‹¬ì„±: ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ì‹¤ì‹œê°„ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… í•™ìŠµ ì„±ê³¼ í‰ê°€ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… í•™ìŠµ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„")


if __name__ == "__main__":
    asyncio.run(test_realtime_learning_system())
