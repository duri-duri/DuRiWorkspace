#!/usr/bin/env python3
"""
í’ˆì§ˆ ê²Œì´íŠ¸ ìŠ¤ì½”ì–´ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ í’ˆì§ˆ ì§€í‘œ ë³€í™”ë¥¼ ì¸¡ì •í•˜ê³  ê²Œì´íŠ¸ í†µê³¼ ì—¬ë¶€ ê²°ì •
"""

import json
import pathlib
import sys
from statistics import mean
from typing import Any, Dict, Optional


def load_metrics(file_path: pathlib.Path) -> Optional[Dict[str, Any]]:
    """ë©”íŠ¸ë¦­ íŒŒì¼ ë¡œë“œ"""
    if not file_path.exists():
        return None

    try:
        return json.loads(file_path.read_text())
    except (json.JSONDecodeError, FileNotFoundError):
        return None


def calculate_mi_average(metrics: Dict[str, Any]) -> float:
    """Maintainability Index í‰ê·  ê³„ì‚°"""
    mi_data = metrics.get("maintainability_index", {})
    if not mi_data:
        return 100.0

    mi_values = []
    for file_path, data in mi_data.items():
        if isinstance(data, dict) and "mi" in data:
            mi_values.append(data["mi"])

    return mean(mi_values) if mi_values else 100.0


def calculate_cc_average(metrics: Dict[str, Any]) -> float:
    """Cyclomatic Complexity í‰ê·  ê³„ì‚°"""
    cc_data = metrics.get("cyclomatic_complexity", {})
    if not cc_data:
        return 1.0

    cc_values = []
    for file_path, data in cc_data.items():
        if isinstance(data, dict) and "complexity" in data:
            cc_values.append(data["complexity"])

    return mean(cc_values) if cc_values else 1.0


def count_high_complexity_functions(
    metrics: Dict[str, Any], threshold: int = 10
) -> int:
    """ë†’ì€ ë³µì¡ë„ í•¨ìˆ˜ ê°œìˆ˜ ê³„ì‚°"""
    cc_data = metrics.get("cyclomatic_complexity", {})
    if not cc_data:
        return 0

    high_complexity_count = 0
    for file_path, data in cc_data.items():
        if isinstance(data, dict) and "complexity" in data:
            if data["complexity"] > threshold:
                high_complexity_count += 1

    return high_complexity_count


def evaluate_gate(
    baseline: Optional[Dict[str, Any]], current: Dict[str, Any]
) -> Dict[str, Any]:
    """ê²Œì´íŠ¸ í‰ê°€ ìˆ˜í–‰"""
    # í˜„ì¬ ë©”íŠ¸ë¦­ ê³„ì‚°
    curr_mi = calculate_mi_average(current)
    curr_cc = calculate_cc_average(current)
    curr_high_cc = count_high_complexity_functions(current)

    # ë² ì´ìŠ¤ë¼ì¸ ë©”íŠ¸ë¦­ ê³„ì‚° (ì—†ìœ¼ë©´ í˜„ì¬ê°’ ì‚¬ìš©)
    base_mi = calculate_mi_average(baseline) if baseline else curr_mi
    base_cc = calculate_cc_average(baseline) if baseline else curr_cc
    base_high_cc = (
        count_high_complexity_functions(baseline) if baseline else curr_high_cc
    )

    # ë¸íƒ€ ê³„ì‚°
    delta_mi = curr_mi - base_mi
    delta_cc = curr_cc - base_cc
    delta_high_cc = curr_high_cc - base_high_cc

    # ê²Œì´íŠ¸ ê·œì¹™ ì ìš©
    gate_results = {
        "maintainability": {
            "current": curr_mi,
            "baseline": base_mi,
            "delta": delta_mi,
            "passed": delta_mi >= -2.0,  # MI í•˜ë½ 2ì  ì´ë‚´ í—ˆìš©
            "threshold": -2.0,
        },
        "complexity": {
            "current": curr_cc,
            "baseline": base_cc,
            "delta": delta_cc,
            "passed": delta_cc <= 1.0,  # CC ì¦ê°€ 1ì  ì´ë‚´ í—ˆìš©
            "threshold": 1.0,
        },
        "high_complexity": {
            "current": curr_high_cc,
            "baseline": base_high_cc,
            "delta": delta_high_cc,
            "passed": delta_high_cc <= 2,  # ë†’ì€ ë³µì¡ë„ í•¨ìˆ˜ 2ê°œ ì´ë‚´ ì¦ê°€ í—ˆìš©
            "threshold": 2,
        },
    }

    # ì „ì²´ ê²Œì´íŠ¸ í†µê³¼ ì—¬ë¶€
    overall_passed = all(result["passed"] for result in gate_results.values())

    return {
        "overall_passed": overall_passed,
        "gate_results": gate_results,
        "summary": {
            "maintainability_delta": delta_mi,
            "complexity_delta": delta_cc,
            "high_complexity_delta": delta_high_cc,
        },
    }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    metrics_dir = pathlib.Path("metrics")
    baseline_file = metrics_dir / "baseline.json"
    current_file = metrics_dir / "current.json"

    # ë©”íŠ¸ë¦­ ë¡œë“œ
    baseline = load_metrics(baseline_file)
    current = load_metrics(current_file)

    if not current:
        print("âŒ No current metrics found. Run collect_static_metrics.py first.")
        sys.exit(1)

    if not baseline:
        print("âš ï¸ No baseline metrics found. Using current metrics as baseline.")
        baseline = current

    # ê²Œì´íŠ¸ í‰ê°€
    evaluation = evaluate_gate(baseline, current)

    # ê²°ê³¼ ì¶œë ¥
    print("ğŸ¯ Quality Gate Evaluation Results:")
    print(f"  Overall: {'âœ… PASSED' if evaluation['overall_passed'] else 'âŒ FAILED'}")
    print()

    for gate_name, result in evaluation["gate_results"].items():
        status = "âœ…" if result["passed"] else "âŒ"
        print(f"  {gate_name.title()}: {status}")
        print(f"    Current: {result['current']:.2f}")
        print(f"    Baseline: {result['baseline']:.2f}")
        print(f"    Delta: {result['delta']:+.2f}")
        print(f"    Threshold: {result['threshold']}")
        print()

    # ìƒì„¸ ì‹¤íŒ¨ ì •ë³´
    if not evaluation["overall_passed"]:
        print("ğŸš¨ Gate failures:")
        for gate_name, result in evaluation["gate_results"].items():
            if not result["passed"]:
                print(
                    f"  - {gate_name}: {result['delta']:+.2f} (threshold: {result['threshold']})"
                )

    # ì¢…ë£Œ ì½”ë“œ ì„¤ì •
    sys.exit(0 if evaluation["overall_passed"] else 1)


if __name__ == "__main__":
    main()
