#!/usr/bin/env python3
"""
ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë¶„ì„ ìœ í‹¸ë¦¬í‹°
"""

import argparse
from datetime import datetime
import hashlib
import json
import logging
import os
import sys
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class ImageProcessor:
    """ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self):
        self.supported_formats = [".png", ".jpg", ".jpeg", ".gif", ".bmp", ".tiff"]
        self.analysis_cache = {}

    def analyze_image(
        self, image_path: str, analysis_type: str = "comprehensive"
    ) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜

        Args:
            image_path: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            analysis_type: ë¶„ì„ íƒ€ì… ("comprehensive", "basic", "metadata")

        Returns:
            ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
        """
        try:
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(image_path):
                return {
                    "status": "error",
                    "error": f"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}",
                    "timestamp": datetime.now().isoformat(),
                }

            # íŒŒì¼ í™•ì¥ì í™•ì¸
            file_ext = os.path.splitext(image_path)[1].lower()
            if file_ext not in self.supported_formats:
                return {
                    "status": "error",
                    "error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤: {file_ext}",
                    "timestamp": datetime.now().isoformat(),
                }

            # ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(image_path, analysis_type)
            if cache_key in self.analysis_cache:
                logger.info(f"ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì‚¬ìš©: {image_path}")
                return self.analysis_cache[cache_key]

            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ë¶„ì„
            metadata = self._analyze_metadata(image_path)

            # ë¶„ì„ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
            if analysis_type == "comprehensive":
                analysis_result = self._comprehensive_analysis(image_path, metadata)
            elif analysis_type == "basic":
                analysis_result = self._basic_analysis(image_path, metadata)
            elif analysis_type == "metadata":
                analysis_result = self._metadata_only_analysis(metadata)
            else:
                analysis_result = self._basic_analysis(image_path, metadata)

            # ê²°ê³¼ì— ê³µí†µ ì •ë³´ ì¶”ê°€
            analysis_result.update(
                {
                    "image_path": image_path,
                    "analysis_type": analysis_type,
                    "timestamp": datetime.now().isoformat(),
                    "status": "success",
                }
            )

            # ìºì‹œì— ì €ì¥
            self.analysis_cache[cache_key] = analysis_result

            logger.info(f"ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: {image_path} ({analysis_type})")
            return analysis_result

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e),
                "image_path": image_path,
                "timestamp": datetime.now().isoformat(),
            }

    def _generate_cache_key(self, image_path: str, analysis_type: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        content = f"{image_path}_{analysis_type}_{os.path.getmtime(image_path)}"
        return hashlib.md5(content.encode()).hexdigest()

    def _analyze_metadata(self, image_path: str) -> Dict[str, Any]:
        """ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ë¶„ì„"""
        try:
            stat_info = os.stat(image_path)

            metadata = {
                "file_size": stat_info.st_size,
                "file_size_mb": round(stat_info.st_size / (1024 * 1024), 2),
                "created_time": datetime.fromtimestamp(stat_info.st_ctime).isoformat(),
                "modified_time": datetime.fromtimestamp(stat_info.st_mtime).isoformat(),
                "file_name": os.path.basename(image_path),
                "file_extension": os.path.splitext(image_path)[1].lower(),
                "file_path": image_path,
            }

            return metadata

        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def _basic_analysis(
        self, image_path: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ê¸°ë³¸ ì´ë¯¸ì§€ ë¶„ì„"""
        try:
            # íŒŒì¼ í¬ê¸° ê¸°ë°˜ ë¶„ì„
            file_size_mb = metadata.get("file_size_mb", 0)

            # íŒŒì¼ í¬ê¸°ì— ë”°ë¥¸ í’ˆì§ˆ ì¶”ì •
            if file_size_mb > 10:
                quality_estimate = "high"
            elif file_size_mb > 5:
                quality_estimate = "medium"
            elif file_size_mb > 1:
                quality_estimate = "low"
            else:
                quality_estimate = "very_low"

            return {
                "analysis_level": "basic",
                "quality_estimate": quality_estimate,
                "file_size_category": self._categorize_file_size(file_size_mb),
                "metadata": metadata,
            }

        except Exception as e:
            logger.error(f"ê¸°ë³¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def _comprehensive_analysis(
        self, image_path: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¢…í•© ì´ë¯¸ì§€ ë¶„ì„"""
        try:
            # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼
            basic_result = self._basic_analysis(image_path, metadata)

            # ì¶”ê°€ ë¶„ì„ ì •ë³´
            comprehensive_result = {
                "analysis_level": "comprehensive",
                "basic_analysis": basic_result,
                "image_characteristics": {
                    "format": metadata.get("file_extension", ""),
                    "size_category": basic_result.get("file_size_category", "unknown"),
                    "quality_estimate": basic_result.get("quality_estimate", "unknown"),
                },
                "processing_recommendations": self._generate_recommendations(
                    metadata, basic_result
                ),
                "metadata": metadata,
            }

            return comprehensive_result

        except Exception as e:
            logger.error(f"ì¢…í•© ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def _metadata_only_analysis(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„°ë§Œ ë¶„ì„"""
        return {"analysis_level": "metadata_only", "metadata": metadata}

    def _categorize_file_size(self, file_size_mb: float) -> str:
        """íŒŒì¼ í¬ê¸° ë¶„ë¥˜"""
        if file_size_mb > 50:
            return "very_large"
        elif file_size_mb > 20:
            return "large"
        elif file_size_mb > 10:
            return "medium_large"
        elif file_size_mb > 5:
            return "medium"
        elif file_size_mb > 1:
            return "small"
        else:
            return "very_small"

    def _generate_recommendations(
        self, metadata: Dict[str, Any], basic_result: Dict[str, Any]
    ) -> List[str]:
        """ì²˜ë¦¬ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        file_size_mb = metadata.get("file_size_mb", 0)
        quality_estimate = basic_result.get("quality_estimate", "unknown")

        if file_size_mb > 20:
            recommendations.append("ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ë¯€ë¡œ ì••ì¶•ì„ ê³ ë ¤í•˜ì„¸ìš”")

        if quality_estimate == "very_low":
            recommendations.append("ì´ë¯¸ì§€ í’ˆì§ˆì´ ë‚®ìœ¼ë¯€ë¡œ ê³ í•´ìƒë„ ë²„ì „ì„ ì‚¬ìš©í•˜ì„¸ìš”")

        if not recommendations:
            recommendations.append("í˜„ì¬ ì´ë¯¸ì§€ê°€ ì ì ˆí•œ ìƒíƒœì…ë‹ˆë‹¤")

        return recommendations


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
image_processor = ImageProcessor()


def analyze_image(
    image_path: str, analysis_type: str = "comprehensive"
) -> Dict[str, Any]:
    """
    ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ (ì „ì—­ í•¨ìˆ˜)

    Args:
        image_path: ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        analysis_type: ë¶„ì„ íƒ€ì… ("comprehensive", "basic", "metadata")

    Returns:
        ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼
    """
    return image_processor.analyze_image(image_path, analysis_type)


def save_analysis_result(result: Dict[str, Any], output_path: str) -> bool:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥

    Args:
        result: ë¶„ì„ ê²°ê³¼
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ

    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ë””ë ‰í† ë¦¬ ìƒì„± (ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
        output_dir = os.path.dirname(output_path)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)

        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        logger.info(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
        return True

    except Exception as e:
        logger.error(f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def main():
    """CLI ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ì´ë¯¸ì§€ ë¶„ì„ ìœ í‹¸ë¦¬í‹°",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python image_processor.py --image_path resources/images/test.png --mode comprehensive
  python image_processor.py --image_path test.png --mode metadata --output result.json
  python image_processor.py --image_path test.png --mode basic --refresh-cache
        """,
    )

    parser.add_argument(
        "--image_path", "-i", required=True, help="ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ"
    )

    parser.add_argument(
        "--mode",
        "-m",
        choices=["basic", "metadata", "comprehensive"],
        default="comprehensive",
        help="ë¶„ì„ ëª¨ë“œ (ê¸°ë³¸ê°’: comprehensive)",
    )

    parser.add_argument("--output", "-o", help="ê²°ê³¼ë¥¼ ì €ì¥í•  JSON íŒŒì¼ ê²½ë¡œ")

    parser.add_argument(
        "--refresh-cache", action="store_true", help="ìºì‹œë¥¼ ë¬´ì‹œí•˜ê³  ì¬ë¶„ì„"
    )

    parser.add_argument("--verbose", "-v", action="store_true", help="ìƒì„¸ ì¶œë ¥")

    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    if args.verbose:
        logging.basicConfig(level=logging.INFO)

    print(f"ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {args.image_path}")
    print(f"ğŸ“Š ë¶„ì„ ëª¨ë“œ: {args.mode}")

    # ìºì‹œ ë¬´ì‹œ ì˜µì…˜ ì²˜ë¦¬
    if args.refresh_cache:
        image_processor.analysis_cache.clear()
        print("ğŸ”„ ìºì‹œ ë¬´ì‹œí•˜ê³  ì¬ë¶„ì„í•©ë‹ˆë‹¤.")

    # ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰
    result = analyze_image(args.image_path, args.mode)

    # ê²°ê³¼ ì¶œë ¥
    if result.get("status") == "success":
        print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {result.get('image_path')}")
        print(f"ğŸ“Š ë¶„ì„ ë ˆë²¨: {result.get('analysis_level', 'unknown')}")

        if args.mode == "comprehensive":
            basic_analysis = result.get("basic_analysis", {})
            quality = basic_analysis.get("quality_estimate", "unknown")
            size_category = basic_analysis.get("file_size_category", "unknown")
            print(f"ğŸ¯ í’ˆì§ˆ ì¶”ì •: {quality}")
            print(f"ğŸ“ í¬ê¸° ë¶„ë¥˜: {size_category}")

        # JSON íŒŒì¼ë¡œ ì €ì¥
        if args.output:
            if save_analysis_result(result, args.output):
                print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {args.output}")
            else:
                print(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {args.output}")

        # ìƒì„¸ ì¶œë ¥
        if args.verbose:
            print("\nğŸ“‹ ìƒì„¸ ê²°ê³¼:")
            print(json.dumps(result, indent=2, ensure_ascii=False))

    else:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        sys.exit(1)


if __name__ == "__main__":
    main()
