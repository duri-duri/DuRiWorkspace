#!/usr/bin/env python3
"""
DuRi Core Node - ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ
ë³‘ë ¬ ì²˜ë¦¬, ìºì‹±, ë¡œë“œ ë°¸ëŸ°ì‹± ê¸°ëŠ¥
"""
import asyncio
import hashlib
import json
import logging
import time
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import aiohttp

logger = logging.getLogger(__name__)


class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ê´€ë¦¬ì"""

    def __init__(self):
        self.cache = {}
        self.cache_ttl = 300  # 5ë¶„ ìºì‹œ
        self.request_history = defaultdict(list)
        self.performance_metrics = {
            "total_requests": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "average_response_time": 0.0,
            "parallel_requests": 0,
            "error_count": 0,
        }
        self.executor = ThreadPoolExecutor(max_workers=10)
        logger.info("âš¡ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def optimize_request(
        self, user_input: str, duri_response: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ìš”ì²­ ìµœì í™” ì²˜ë¦¬"""
        try:
            start_time = time.time()

            # 1. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(user_input, duri_response, metadata)
            cached_result = self._get_from_cache(cache_key)

            if cached_result:
                self.performance_metrics["cache_hits"] += 1
                logger.info(f"âš¡ ìºì‹œ íˆíŠ¸: {cache_key[:20]}...")
                return cached_result

            self.performance_metrics["cache_misses"] += 1

            # 2. ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰
            result = await self._parallel_processing(
                user_input, duri_response, metadata
            )

            # 3. ê²°ê³¼ ìºì‹±
            self._cache_result(cache_key, result)

            # 4. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_performance_metrics(processing_time)

            return result

        except Exception as e:
            logger.error(f"âŒ ì„±ëŠ¥ ìµœì í™” ì˜¤ë¥˜: {e}")
            self.performance_metrics["error_count"] += 1
            raise

    def _generate_cache_key(
        self, user_input: str, duri_response: str, metadata: Dict[str, Any]
    ) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        content = f"{user_input}:{duri_response}:{json.dumps(metadata, sort_keys=True)}"
        return hashlib.md5(content.encode()).hexdigest()

    def _get_from_cache(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """ìºì‹œì—ì„œ ê²°ê³¼ ì¡°íšŒ"""
        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            if time.time() - cached_item["timestamp"] < self.cache_ttl:
                return cached_item["data"]
            else:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                del self.cache[cache_key]
        return None

    def _cache_result(self, cache_key: str, result: Dict[str, Any]):
        """ê²°ê³¼ ìºì‹±"""
        self.cache[cache_key] = {"data": result, "timestamp": time.time()}

        # ìºì‹œ í¬ê¸° ì œí•œ (ìµœëŒ€ 1000ê°œ)
        if len(self.cache) > 1000:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ
            oldest_key = min(
                self.cache.keys(), key=lambda k: self.cache[k]["timestamp"]
            )
            del self.cache[oldest_key]

    async def _parallel_processing(
        self, user_input: str, duri_response: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰"""
        try:
            # Brainê³¼ Evolution ë…¸ë“œì— ë™ì‹œ ìš”ì²­
            brain_task = asyncio.create_task(
                self._call_brain_node(user_input, duri_response, metadata)
            )
            evolution_task = asyncio.create_task(
                self._call_evolution_node(user_input, duri_response, metadata)
            )

            # ë³‘ë ¬ë¡œ ê²°ê³¼ ìˆ˜ì§‘
            brain_result, evolution_result = await asyncio.gather(
                brain_task, evolution_task, return_exceptions=True
            )

            # ì˜¤ë¥˜ ì²˜ë¦¬
            if isinstance(brain_result, Exception):
                logger.error(f"Brain ë…¸ë“œ ì˜¤ë¥˜: {brain_result}")
                brain_result = {"error": str(brain_result)}

            if isinstance(evolution_result, Exception):
                logger.error(f"Evolution ë…¸ë“œ ì˜¤ë¥˜: {evolution_result}")
                evolution_result = {"error": str(evolution_result)}

            # ê²°ê³¼ í†µí•©
            integrated_result = self._integrate_results(brain_result, evolution_result)

            return integrated_result

        except Exception as e:
            logger.error(f"ë³‘ë ¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            raise

    async def _call_brain_node(
        self, user_input: str, duri_response: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Brain ë…¸ë“œ í˜¸ì¶œ (ë¹„ë™ê¸°)"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "http://localhost:8091/analyze",
                    json={
                        "user_input": user_input,
                        "duri_response": duri_response,
                        "metadata": metadata,
                    },
                    timeout=aiohttp.ClientTimeout(total=10),
                ) as response:
                    if response.status == 200:
                        return await response.json()
                    else:
                        return {"error": f"Brain node error: {response.status}"}

        except Exception as e:
            logger.error(f"Brain ë…¸ë“œ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    async def _call_evolution_node(
        self, user_input: str, duri_response: str, metadata: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Evolution ë…¸ë“œ í˜¸ì¶œ (ë¹„ë™ê¸°)"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "http://localhost:8092/learn",
                    json={
                        "user_input": user_input,
                        "duri_response": duri_response,
                        "metadata": metadata,
                    },
                    timeout=aiohttp.ClientTimeout(total=10),
                ) as response:
                    if response.status == 200:
                        return await response.json()
                    else:
                        return {"error": f"Evolution node error: {response.status}"}

        except Exception as e:
            logger.error(f"Evolution ë…¸ë“œ í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def _integrate_results(
        self, brain_result: Dict[str, Any], evolution_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ê²°ê³¼ í†µí•© (ìµœì í™”ëœ ë²„ì „)"""
        try:
            # í†µí•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            brain_score = brain_result.get("analysis_score", 0.0)
            evolution_score = evolution_result.get("learning_score", 0.0)

            # ê°€ì¤‘ì¹˜ ì ìš© (Brain: 0.6, Evolution: 0.4)
            integrated_score = (brain_score * 0.6) + (evolution_score * 0.4)

            return {
                "status": "success",
                "conversation_id": f"optimized_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "integrated_score": integrated_score,
                "brain_analysis": brain_result,
                "evolution_learning": evolution_result,
                "optimization": {
                    "cache_used": False,  # ë³‘ë ¬ ì²˜ë¦¬ì—ì„œëŠ” ìºì‹œ ë¯¸ì‚¬ìš©
                    "parallel_processing": True,
                    "performance_metrics": self.get_performance_metrics(),
                },
                "timestamp": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"ê²°ê³¼ í†µí•© ì˜¤ë¥˜: {e}")
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    def _update_performance_metrics(self, processing_time: float):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.performance_metrics["total_requests"] += 1
        self.performance_metrics["parallel_requests"] += 1

        # í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
        current_avg = self.performance_metrics["average_response_time"]
        total_requests = self.performance_metrics["total_requests"]
        new_avg = (
            (current_avg * (total_requests - 1)) + processing_time
        ) / total_requests
        self.performance_metrics["average_response_time"] = new_avg

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        cache_hit_rate = 0.0
        if self.performance_metrics["total_requests"] > 0:
            cache_hit_rate = (
                self.performance_metrics["cache_hits"]
                / self.performance_metrics["total_requests"]
            )

        return {
            **self.performance_metrics,
            "cache_hit_rate": cache_hit_rate,
            "cache_size": len(self.cache),
            "timestamp": datetime.now().isoformat(),
        }

    def clear_cache(self):
        """ìºì‹œ í´ë¦¬ì–´"""
        self.cache.clear()
        logger.info("ğŸ—‘ï¸ ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ")

    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        return {
            "cache_size": len(self.cache),
            "cache_ttl": self.cache_ttl,
            "cache_keys": list(self.cache.keys())[:10],  # ìƒìœ„ 10ê°œë§Œ
            "timestamp": datetime.now().isoformat(),
        }


class LoadBalancer:
    """ë¡œë“œ ë°¸ëŸ°ì„œ"""

    def __init__(self):
        self.node_health = {
            "brain": {"healthy": True, "last_check": None, "response_time": 0.0},
            "evolution": {"healthy": True, "last_check": None, "response_time": 0.0},
        }
        self.request_count = {"brain": 0, "evolution": 0}
        logger.info("âš–ï¸ ë¡œë“œ ë°¸ëŸ°ì„œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def check_node_health(self):
        """ë…¸ë“œ ìƒíƒœ í™•ì¸"""
        try:
            # Brain ë…¸ë“œ ìƒíƒœ í™•ì¸
            brain_start = time.time()
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        "http://localhost:8091/health", timeout=2
                    ) as response:
                        self.node_health["brain"]["healthy"] = response.status == 200
                        self.node_health["brain"]["response_time"] = (
                            time.time() - brain_start
                        )
                        self.node_health["brain"][
                            "last_check"
                        ] = datetime.now().isoformat()
            except:
                self.node_health["brain"]["healthy"] = False

            # Evolution ë…¸ë“œ ìƒíƒœ í™•ì¸
            evolution_start = time.time()
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(
                        "http://localhost:8092/health", timeout=2
                    ) as response:
                        self.node_health["evolution"]["healthy"] = (
                            response.status == 200
                        )
                        self.node_health["evolution"]["response_time"] = (
                            time.time() - evolution_start
                        )
                        self.node_health["evolution"][
                            "last_check"
                        ] = datetime.now().isoformat()
            except:
                self.node_health["evolution"]["healthy"] = False

        except Exception as e:
            logger.error(f"ë…¸ë“œ ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")

    def get_optimal_node(self, operation_type: str) -> str:
        """ìµœì  ë…¸ë“œ ì„ íƒ"""
        if operation_type == "analysis":
            # ë¶„ì„ ì‘ì—…ì€ Brain ë…¸ë“œ
            return "brain" if self.node_health["brain"]["healthy"] else "evolution"
        elif operation_type == "learning":
            # í•™ìŠµ ì‘ì—…ì€ Evolution ë…¸ë“œ
            return "evolution" if self.node_health["evolution"]["healthy"] else "brain"
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ ì‘ë‹µ ì‹œê°„ì´ ë¹ ë¥¸ ë…¸ë“œ ì„ íƒ
            if (
                self.node_health["brain"]["response_time"]
                <= self.node_health["evolution"]["response_time"]
            ):
                return "brain"
            else:
                return "evolution"

    def get_load_balancing_stats(self) -> Dict[str, Any]:
        """ë¡œë“œ ë°¸ëŸ°ì‹± í†µê³„"""
        return {
            "node_health": self.node_health,
            "request_count": self.request_count,
            "timestamp": datetime.now().isoformat(),
        }
