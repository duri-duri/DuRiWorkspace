#!/usr/bin/env python3
"""
Extension ì—°ê²°ì„ ìœ„í•œ ì‹¤ì œ í•™ìŠµ ê¸°ëŠ¥ì´ êµ¬í˜„ëœ ì„œë²„ + í†µí•© ì‹œì  ì•Œë¦¼ ì‹œìŠ¤í…œ + í•™ìŠµ ì‹œê°í™” + ìê¸° ì„±ì°° ì‹œìŠ¤í…œ
"""

import ast
import base64
import io
import json
import os
import re
import shutil
import subprocess
import tempfile
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List

import matplotlib.pyplot as plt
import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse

app = FastAPI(
    title="DuRi Extension Learning Server",
    description="ì‹¤ì œ í•™ìŠµ ê¸°ëŠ¥ì´ êµ¬í˜„ëœ Extension ì„œë²„ + í†µí•© ì‹œì  ì•Œë¦¼ + í•™ìŠµ ì‹œê°í™” + ìê¸° ì„±ì°°",
    version="1.0.0",
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# í•™ìŠµ ë°ì´í„° ì €ì¥ì†Œ
LEARNING_DATA_DIR = "/tmp/duri_learning_data"
os.makedirs(LEARNING_DATA_DIR, exist_ok=True)

# í†µí•© ì‹œì  ëª¨ë‹ˆí„°ë§
INTEGRATION_THRESHOLDS = {
    "learning_patterns": 50,  # í•™ìŠµ íŒ¨í„´ ìˆ˜
    "response_time": 1.5,  # ì‘ë‹µ ì‹œê°„ (ì´ˆ)
    "code_complexity": 3,  # ì½”ë“œ ë³µì¡ë„ ë‹¨ê³„
    "user_requirements": "advanced",  # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ìˆ˜ì¤€
}


class SelfReflectionEngine:
    """ìê¸° ì„±ì°° ì—”ì§„ - DuRiê°€ ìì‹ ì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œ"""

    def __init__(self):
        self.reflection_history = []
        self.improvement_suggestions = []

    def reflect_on_response(
        self, conversation: str, response_quality: float, learning_value: float
    ) -> Dict[str, Any]:
        """ë‹µë³€ì— ëŒ€í•œ ìê¸° ì„±ì°° ìˆ˜í–‰"""

        reflection = {
            "timestamp": datetime.now().isoformat(),
            "conversation": conversation,
            "response_quality": response_quality,
            "learning_value": learning_value,
            "self_questions": [],
            "improvement_areas": [],
            "action_plan": [],
        }

        # ìê¸° ì§ˆë¬¸ë“¤
        reflection["self_questions"] = [
            "ë‚´ ë‹µë³€ì´ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì¶©ë¶„íˆ í•´ê²°í–ˆì„ê¹Œ?",
            "ë” êµ¬ì²´ì ì¸ ì˜ˆì œê°€ í•„ìš”í•˜ì§€ ì•Šì•˜ì„ê¹Œ?",
            "ì‚¬ìš©ìì˜ ìˆ˜ì¤€ì— ë§ëŠ” ì„¤ëª…ì´ì—ˆì„ê¹Œ?",
            "ì‹¤ìš©ì ì¸ ì •ë³´ë¥¼ ì œê³µí–ˆì„ê¹Œ?",
        ]

        # ê°œì„  ì˜ì—­ ë¶„ì„
        if response_quality < 0.5:
            reflection["improvement_areas"].append("ë‹µë³€ í’ˆì§ˆì´ ë‚®ìŒ - ë” ìƒì„¸í•œ ì„¤ëª… í•„ìš”")
        if learning_value < 0.3:
            reflection["improvement_areas"].append("í•™ìŠµ ê°€ì¹˜ê°€ ë‚®ìŒ - ë” êµìœ¡ì ì¸ ë‚´ìš© í•„ìš”")
        if len(conversation.split()) < 10:
            reflection["improvement_areas"].append("ì§ˆë¬¸ì´ ê°„ë‹¨í•¨ - ë” êµ¬ì²´ì ì¸ ì˜ˆì œ ì œê³µ í•„ìš”")

        # ì•¡ì…˜ í”Œëœ ìƒì„±
        reflection["action_plan"] = self._generate_action_plan(reflection["improvement_areas"])

        # ì„±ì°° ê¸°ë¡ ì €ì¥
        self.reflection_history.append(reflection)

        return reflection

    def _generate_action_plan(self, improvement_areas: List[str]) -> List[str]:
        """ê°œì„  ì˜ì—­ì— ë”°ë¥¸ ì•¡ì…˜ í”Œëœ ìƒì„±"""
        action_plan = []

        for area in improvement_areas:
            if "ë‹µë³€ í’ˆì§ˆ" in area:
                action_plan.append("ë” ìƒì„¸í•œ ë‹¨ê³„ë³„ ì„¤ëª… ì¶”ê°€")
                action_plan.append("ì½”ë“œ ì˜ˆì œì™€ í•¨ê»˜ ì„¤ëª…")
            elif "í•™ìŠµ ê°€ì¹˜" in area:
                action_plan.append("ì‹¤ìŠµ ì˜ˆì œ í¬í•¨")
                action_plan.append("ê´€ë ¨ ê°œë… ì—°ê²°")
            elif "êµ¬ì²´ì ì¸ ì˜ˆì œ" in area:
                action_plan.append("ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€ ì¶”ê°€")
                action_plan.append("ë‹¨ê³„ë³„ íŠœí† ë¦¬ì–¼ ì œê³µ")

        return action_plan

    def get_improvement_suggestions(self) -> List[str]:
        """ì „ì²´ ê°œì„  ì œì•ˆ ìˆ˜ì§‘"""
        suggestions = []

        for reflection in self.reflection_history[-5:]:  # ìµœê·¼ 5ê°œ ì„±ì°°ë§Œ
            suggestions.extend(reflection["action_plan"])

        return list(set(suggestions))  # ì¤‘ë³µ ì œê±°

    def analyze_trends(self) -> Dict[str, Any]:
        """ì„±ì°° íŠ¸ë Œë“œ ë¶„ì„"""
        if not self.reflection_history:
            return {"message": "ì•„ì§ ì„±ì°° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}

        recent_reflections = self.reflection_history[-10:]  # ìµœê·¼ 10ê°œ

        avg_response_quality = sum(r["response_quality"] for r in recent_reflections) / len(
            recent_reflections
        )
        avg_learning_value = sum(r["learning_value"] for r in recent_reflections) / len(
            recent_reflections
        )

        improvement_frequency = defaultdict(int)
        for reflection in recent_reflections:
            for area in reflection["improvement_areas"]:
                improvement_frequency[area] += 1

        return {
            "avg_response_quality": avg_response_quality,
            "avg_learning_value": avg_learning_value,
            "most_common_improvements": sorted(
                improvement_frequency.items(), key=lambda x: x[1], reverse=True
            )[:3],
            "total_reflections": len(self.reflection_history),
        }


# ìê¸° ì„±ì°° ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤
self_reflection_engine = SelfReflectionEngine()


class LearningVisualizer:
    """í•™ìŠµ íŒ¨í„´ ì‹œê°í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.chart_cache = {}

    def generate_learning_trend_chart(self) -> str:
        """í•™ìŠµ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„±"""
        try:
            # í•™ìŠµ ë°ì´í„° ë¡œë“œ
            learning_data = self._load_learning_data()

            if not learning_data:
                return self._create_empty_chart("í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            # ì°¨íŠ¸ ìƒì„±
            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))

            # í•™ìŠµ ê°€ì¹˜ íŠ¸ë Œë“œ
            timestamps = [data.get("timestamp", "") for data in learning_data]
            learning_values = [data.get("learning_value", 0) for data in learning_data]

            ax1.plot(
                range(len(learning_values)),
                learning_values,
                "b-o",
                linewidth=2,
                markersize=6,
            )
            ax1.set_title("Learning Value Trend", fontsize=14, fontweight="bold")
            ax1.set_ylabel("Learning Value", fontsize=12)
            ax1.set_ylim(0, 1)
            ax1.grid(True, alpha=0.3)

            # ë³µì¡ë„ íŠ¸ë Œë“œ
            complexities = [data.get("learning_complexity", 0) for data in learning_data]
            ax2.plot(range(len(complexities)), complexities, "r-s", linewidth=2, markersize=6)
            ax2.set_title("Learning Complexity Trend", fontsize=14, fontweight="bold")
            ax2.set_ylabel("Complexity", fontsize=12)
            ax2.set_xlabel("Learning Session", fontsize=12)
            ax2.set_ylim(0, 1)
            ax2.grid(True, alpha=0.3)

            plt.tight_layout()

            # ì°¨íŠ¸ë¥¼ base64ë¡œ ì¸ì½”ë”©
            buffer = io.BytesIO()
            plt.savefig(buffer, format="png", dpi=100, bbox_inches="tight")
            buffer.seek(0)
            chart_base64 = base64.b64encode(buffer.getvalue()).decode()
            plt.close()

            return chart_base64

        except Exception as e:
            print(f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._create_empty_chart("ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨")

    def generate_concept_analysis_chart(self) -> str:
        """ê°œë… ë¶„ì„ ì°¨íŠ¸ ìƒì„±"""
        try:
            learning_data = self._load_learning_data()

            if not learning_data:
                return self._create_empty_chart("í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            # ê°œë… ë¹ˆë„ ë¶„ì„
            concept_freq = defaultdict(int)
            for data in learning_data:
                concepts = data.get("key_concepts", [])
                for concept in concepts:
                    concept_freq[concept] += 1

            if not concept_freq:
                return self._create_empty_chart("ê°œë… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            # ìƒìœ„ 10ê°œ ê°œë…ë§Œ ì„ íƒ
            top_concepts = sorted(concept_freq.items(), key=lambda x: x[1], reverse=True)[:10]
            concepts, frequencies = zip(*top_concepts)

            # ì°¨íŠ¸ ìƒì„±
            fig, ax = plt.subplots(figsize=(12, 6))
            bars = ax.bar(range(len(concepts)), frequencies, color="skyblue", alpha=0.7)

            ax.set_title("Key Concept Frequency Analysis", fontsize=14, fontweight="bold")
            ax.set_xlabel("Concepts", fontsize=12)
            ax.set_ylabel("Frequency", fontsize=12)
            ax.set_xticks(range(len(concepts)))
            ax.set_xticklabels(concepts, rotation=45, ha="right")

            # ê°’ í‘œì‹œ
            for i, v in enumerate(frequencies):
                ax.text(i, v + 0.1, str(v), ha="center", va="bottom", fontweight="bold")

            plt.tight_layout()

            # ì°¨íŠ¸ë¥¼ base64ë¡œ ì¸ì½”ë”©
            buffer = io.BytesIO()
            plt.savefig(buffer, format="png", dpi=100, bbox_inches="tight")
            buffer.seek(0)
            chart_base64 = base64.b64encode(buffer.getvalue()).decode()
            plt.close()

            return chart_base64

        except Exception as e:
            print(f"ê°œë… ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return self._create_empty_chart("ê°œë… ë¶„ì„ ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨")

    def _load_learning_data(self) -> List[Dict[str, Any]]:
        """í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        learning_data = []

        try:
            for filename in os.listdir(LEARNING_DATA_DIR):
                if filename.endswith(".json"):
                    filepath = os.path.join(LEARNING_DATA_DIR, filename)
                    with open(filepath, "r", encoding="utf-8") as f:
                        data = json.load(f)
                        learning_data.append(data)
        except Exception as e:
            print(f"í•™ìŠµ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")

        return learning_data

    def _create_empty_chart(self, message: str) -> str:
        """ë¹ˆ ì°¨íŠ¸ ìƒì„±"""
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.text(
            0.5,
            0.5,
            message,
            ha="center",
            va="center",
            transform=ax.transAxes,
            fontsize=14,
        )
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.axis("off")

        buffer = io.BytesIO()
        plt.savefig(buffer, format="png", dpi=100, bbox_inches="tight")
        buffer.seek(0)
        chart_base64 = base64.b64encode(buffer.getvalue()).decode()
        plt.close()

        return chart_base64


# í•™ìŠµ ì‹œê°í™” ì¸ìŠ¤í„´ìŠ¤
learning_visualizer = LearningVisualizer()


class IntegrationMonitor:
    """í†µí•© ì‹œì  ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.learning_patterns_count = 0
        self.response_times = []
        self.code_complexity_level = 1
        self.user_requirements_level = "basic"
        self.integration_alerts = []

    def check_integration_needed(self) -> Dict[str, Any]:
        """í†µí•© í•„ìš”ì„± ì²´í¬"""
        alerts = []

        # í•™ìŠµ íŒ¨í„´ ìˆ˜ ì²´í¬
        if self.learning_patterns_count >= INTEGRATION_THRESHOLDS["learning_patterns"]:
            alerts.append(
                f"âš ï¸ í•™ìŠµ íŒ¨í„´ì´ {self.learning_patterns_count}ê°œ ì¶•ì ë¨ (ì„ê³„ê°’: {INTEGRATION_THRESHOLDS['learning_patterns']})"
            )

        # ì‘ë‹µ ì‹œê°„ ì²´í¬
        if self.response_times:
            avg_response_time = sum(self.response_times) / len(self.response_times)
            if avg_response_time >= INTEGRATION_THRESHOLDS["response_time"]:
                alerts.append(
                    f"âš ï¸ í‰ê·  ì‘ë‹µ ì‹œê°„ì´ {avg_response_time:.2f}ì´ˆ (ì„ê³„ê°’: {INTEGRATION_THRESHOLDS['response_time']}ì´ˆ)"
                )

        # ì½”ë“œ ë³µì¡ë„ ì²´í¬
        if self.code_complexity_level >= INTEGRATION_THRESHOLDS["code_complexity"]:
            alerts.append(
                f"âš ï¸ ì½”ë“œ ë³µì¡ë„ê°€ {self.code_complexity_level}ë‹¨ê³„ (ì„ê³„ê°’: {INTEGRATION_THRESHOLDS['code_complexity']}ë‹¨ê³„)"
            )

        # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì²´í¬
        if self.user_requirements_level == "advanced":
            alerts.append("âš ï¸ ê³ ê¸‰ ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ì´ ê°ì§€ë¨")

        # í†µí•© í•„ìš”ì„± íŒë‹¨
        integration_needed = len(alerts) >= 2  # 2ê°œ ì´ìƒì˜ ê²½ê³ ê°€ ìˆìœ¼ë©´ í†µí•© í•„ìš”

        return {
            "integration_needed": integration_needed,
            "alerts": alerts,
            "metrics": {
                "learning_patterns": self.learning_patterns_count,
                "avg_response_time": (
                    sum(self.response_times) / len(self.response_times)
                    if self.response_times
                    else 0
                ),
                "code_complexity": self.code_complexity_level,
                "user_requirements": self.user_requirements_level,
            },
            "thresholds": INTEGRATION_THRESHOLDS,
        }

    def update_metrics(self, response_time: float, complexity_increase: bool = False):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.response_times.append(response_time)
        if len(self.response_times) > 10:  # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
            self.response_times.pop(0)

        if complexity_increase:
            self.code_complexity_level += 1

    def increment_learning_patterns(self):
        """í•™ìŠµ íŒ¨í„´ ìˆ˜ ì¦ê°€"""
        self.learning_patterns_count += 1


# í†µí•© ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤
integration_monitor = IntegrationMonitor()


class LearningAnalyzer:
    """ì‹¤ì œ í•™ìŠµ ë¶„ì„ê¸°"""

    def __init__(self):
        self.conversation_history = []
        self.learning_patterns = defaultdict(int)
        self.key_concepts = set()

    def analyze_conversation(self, conversation_data: Dict[str, Any]) -> Dict[str, Any]:
        """ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµ ê°€ì¹˜ë¥¼ í‰ê°€"""

        conversation = conversation_data.get("conversation", "")
        user = conversation_data.get("user", "unknown")
        timestamp = conversation_data.get("timestamp", datetime.now().isoformat())

        # ëŒ€í™” ë‚´ìš© ë¶„ì„
        analysis_result = {
            "conversation_length": len(conversation),
            "word_count": len(conversation.split()),
            "key_concepts": self._extract_key_concepts(conversation),
            "learning_complexity": self._calculate_complexity(conversation),
            "user_engagement": self._analyze_engagement(conversation),
            "timestamp": timestamp,
            "user": user,
        }

        # í•™ìŠµ ê°€ì¹˜ ê³„ì‚°
        learning_value = self._calculate_learning_value(analysis_result)
        analysis_result["learning_value"] = learning_value

        # íŒ¨í„´ ì €ì¥
        self._save_learning_pattern(analysis_result)

        # í†µí•© ëª¨ë‹ˆí„°ë§ ì—…ë°ì´íŠ¸
        integration_monitor.increment_learning_patterns()

        return analysis_result

    def _extract_key_concepts(self, conversation: str) -> List[str]:
        """ëŒ€í™”ì—ì„œ í•µì‹¬ ê°œë… ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ NLP ì‚¬ìš©)
        keywords = re.findall(r"\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b", conversation)
        technical_terms = re.findall(
            r"\b(?:API|HTTP|JSON|Python|JavaScript|React|Vue|Node|Server|Client|Database|Cache|Async|Sync)\b",
            conversation,
            re.IGNORECASE,
        )

        concepts = list(set(keywords + technical_terms))
        return concepts[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜

    def _calculate_complexity(self, conversation: str) -> float:
        """ëŒ€í™”ì˜ ë³µì¡ë„ ê³„ì‚°"""
        sentences = re.split(r"[.!?]+", conversation)
        avg_sentence_length = sum(len(s.split()) for s in sentences if s.strip()) / max(
            len(sentences), 1
        )

        # ê¸°ìˆ ì  ìš©ì–´ ë¹„ìœ¨
        tech_terms = len(
            re.findall(
                r"\b(?:API|HTTP|JSON|Python|JavaScript|React|Vue|Node|Server|Client|Database|Cache|Async|Sync)\b",
                conversation,
                re.IGNORECASE,
            )
        )
        tech_ratio = tech_terms / max(len(conversation.split()), 1)

        complexity = (avg_sentence_length * 0.3) + (tech_ratio * 100 * 0.7)
        return min(complexity, 1.0)

    def _analyze_engagement(self, conversation: str) -> float:
        """ì‚¬ìš©ì ì°¸ì—¬ë„ ë¶„ì„"""
        questions = len(re.findall(r"\?", conversation))
        explanations = len(
            re.findall(
                r"\b(?:because|since|therefore|thus|hence|so|as|for)\b",
                conversation,
                re.IGNORECASE,
            )
        )

        engagement = (questions * 0.4) + (explanations * 0.6)
        return min(engagement / max(len(conversation.split()), 1), 1.0)

    def _calculate_learning_value(self, analysis: Dict[str, Any]) -> float:
        """í•™ìŠµ ê°€ì¹˜ ê³„ì‚°"""
        complexity = analysis.get("learning_complexity", 0)
        engagement = analysis.get("user_engagement", 0)
        concept_count = len(analysis.get("key_concepts", []))

        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ í•™ìŠµ ê°€ì¹˜ ê³„ì‚°
        learning_value = (
            (complexity * 0.4) + (engagement * 0.3) + (min(concept_count / 5, 1.0) * 0.3)
        )
        return round(learning_value, 3)

    def _save_learning_pattern(self, analysis: Dict[str, Any]):
        """í•™ìŠµ íŒ¨í„´ ì €ì¥"""
        timestamp = analysis.get("timestamp", datetime.now().isoformat())
        filename = f"{LEARNING_DATA_DIR}/learning_pattern_{timestamp.replace(':', '-')}.json"

        with open(filename, "w", encoding="utf-8") as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2)


# í•™ìŠµ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
learning_analyzer = LearningAnalyzer()


class ChatGPTEvaluator:
    """ChatGPTì˜ 6ì°¨ì› ë‹µë³€ í‰ê°€ ì‹œìŠ¤í…œ"""

    EVALUATION_CRITERIA = {
        "correctness": 0.30,  # ì •í™•ì„± (ì‚¬ì‹¤, ê°œë…, ë¡œì§)
        "relevance": 0.20,  # ì í•©ì„± (ì§ˆë¬¸ ì˜ë„ì™€ì˜ ë°€ì ‘ë„)
        "depth": 0.15,  # ê¹Šì´ (ê·¼ë³¸ì  ì›ì¸ ë¶„ì„)
        "structure": 0.10,  # êµ¬ì¡°í™” (ë…¼ë¦¬ì  êµ¬ì„±)
        "clarity": 0.15,  # ëª…ë£Œì„± (ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…)
        "actionability": 0.10,  # ì‹¤ìš©ì„± (ì ìš© ê°€ëŠ¥ì„±)
    }

    def evaluate_response(self, duri_response: str, user_question: str) -> Dict[str, Any]:
        """ChatGPTê°€ DuRi ë‹µë³€ì„ 6ì°¨ì›ìœ¼ë¡œ í‰ê°€"""

        evaluation = {
            "scores": self._calculate_6d_scores(duri_response, user_question),
            "suggestions": self._identify_improvements(duri_response),
            "critical_issues": self._find_critical_issues(duri_response),
            "overall_assessment": self._generate_overall_assessment(duri_response),
            "timestamp": datetime.now().isoformat(),
        }

        # ì´ì  ê³„ì‚°
        total_score = sum(
            evaluation["scores"][criterion] * weight
            for criterion, weight in self.EVALUATION_CRITERIA.items()
        )
        evaluation["total_score"] = round(total_score, 3)

        return evaluation

    def _calculate_6d_scores(self, response: str, question: str) -> Dict[str, float]:
        """6ì°¨ì› ì ìˆ˜ ê³„ì‚°"""
        scores = {}

        # ì •í™•ì„±: ê¸°ìˆ ì  ìš©ì–´ì™€ ê°œë…ì˜ ì •í™•ì„±
        tech_terms = len(
            re.findall(
                r"\b(?:API|HTTP|JSON|Python|JavaScript|React|Vue|Node|Server|Client|Database|Cache|Async|Sync)\b",
                response,
                re.IGNORECASE,
            )
        )
        scores["correctness"] = min(tech_terms / max(len(response.split()), 1) * 10, 1.0)

        # ì í•©ì„±: ì§ˆë¬¸ í‚¤ì›Œë“œì™€ ë‹µë³€ì˜ ì¼ì¹˜ë„
        question_words = set(question.lower().split())
        response_words = set(response.lower().split())
        overlap = len(question_words.intersection(response_words))
        scores["relevance"] = min(overlap / max(len(question_words), 1), 1.0)

        # ê¹Šì´: ë¶„ì„ì  ë‚´ìš©ì˜ ê¹Šì´
        analytical_words = len(
            re.findall(
                r"\b(?:because|since|therefore|thus|hence|analysis|compare|difference|advantage|disadvantage)\b",
                response,
                re.IGNORECASE,
            )
        )
        scores["depth"] = min(analytical_words / max(len(response.split()), 1) * 5, 1.0)

        # êµ¬ì¡°í™”: ë…¼ë¦¬ì  êµ¬ì„±
        structure_indicators = len(
            re.findall(
                r"\b(?:first|second|third|finally|however|moreover|in addition|conclusion)\b",
                response,
                re.IGNORECASE,
            )
        )
        scores["structure"] = min(structure_indicators / max(len(response.split()), 1) * 8, 1.0)

        # ëª…ë£Œì„±: ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª…
        simple_sentences = len([s for s in response.split(".") if len(s.split()) < 20])
        total_sentences = len(response.split("."))
        scores["clarity"] = min(simple_sentences / max(total_sentences, 1), 1.0)

        # ì‹¤ìš©ì„±: ì ìš© ê°€ëŠ¥í•œ ë‚´ìš©
        practical_indicators = len(
            re.findall(
                r"\b(?:example|code|implementation|step|guide|tutorial|practice)\b",
                response,
                re.IGNORECASE,
            )
        )
        scores["actionability"] = min(practical_indicators / max(len(response.split()), 1) * 3, 1.0)

        return {k: round(v, 3) for k, v in scores.items()}

    def _identify_improvements(self, response: str) -> List[str]:
        """ê°œì„ ì  ì‹ë³„"""
        suggestions = []

        if len(response.split()) < 50:
            suggestions.append("ë” ìƒì„¸í•œ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤")

        if "example" not in response.lower() and "code" not in response.lower():
            suggestions.append("ì‹¤ì œ ì½”ë“œ ì˜ˆì œë¥¼ ì¶”ê°€í•´ë³´ì„¸ìš”")

        if "because" not in response.lower() and "reason" not in response.lower():
            suggestions.append("ì´ìœ ì™€ ê·¼ê±°ë¥¼ ë” ëª…í™•íˆ ì„¤ëª…í•´ë³´ì„¸ìš”")

        if len(re.findall(r"\b(?:first|second|finally)\b", response, re.IGNORECASE)) < 2:
            suggestions.append("ë‹¨ê³„ë³„ë¡œ êµ¬ì¡°í™”ëœ ì„¤ëª…ì„ ì¶”ê°€í•´ë³´ì„¸ìš”")

        return suggestions

    def _find_critical_issues(self, response: str) -> List[str]:
        """ì¤‘ìš”í•œ ë¬¸ì œì  ë°œê²¬"""
        issues = []

        if len(response.split()) < 20:
            issues.append("ë‹µë³€ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤")

        if not re.search(
            r"\b(?:API|HTTP|JSON|Python|JavaScript|React|Vue|Node|Server|Client|Database|Cache|Async|Sync)\b",
            response,
            re.IGNORECASE,
        ):
            issues.append("ê¸°ìˆ ì  ë‚´ìš©ì´ ë¶€ì¡±í•©ë‹ˆë‹¤")

        if "?" in response and len(response.split("?")) > 2:
            issues.append("ì§ˆë¬¸ë³´ë‹¤ëŠ” ë‹µë³€ì— ì§‘ì¤‘í•´ë³´ì„¸ìš”")

        return issues

    def _generate_overall_assessment(self, response: str) -> str:
        """ì „ì²´ í‰ê°€ ìƒì„±"""
        word_count = len(response.split())

        if word_count < 30:
            return "ë‹µë³€ì´ ë„ˆë¬´ ê°„ë‹¨í•©ë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        elif word_count < 100:
            return "ì ì ˆí•œ ìˆ˜ì¤€ì´ì§€ë§Œ, ë” ê¹Šì´ ìˆëŠ” ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        else:
            return "ìƒì„¸í•˜ê³  í¬ê´„ì ì¸ ë‹µë³€ì…ë‹ˆë‹¤. ì˜ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤."


# ChatGPT í‰ê°€ê¸° ì¸ìŠ¤í„´ìŠ¤
chatgpt_evaluator = ChatGPTEvaluator()


class DuRiSelfReflector:
    """DuRiì˜ 2ì°¨ ì„±ì°° ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.reflection_history = []
        self.improvement_proposals = []

    def reflect_on_chatgpt_feedback(
        self,
        chatgpt_evaluation: Dict[str, Any],
        original_response: str,
        user_question: str,
    ) -> Dict[str, Any]:
        """ChatGPT í”¼ë“œë°±ì„ ë°›ì•„ DuRiê°€ ìê¸°ì„±ì°°"""

        reflection = {
            "timestamp": datetime.now().isoformat(),
            "chatgpt_evaluation": chatgpt_evaluation,
            "original_response": original_response,
            "user_question": user_question,
            "accepted_criticisms": self._analyze_accepted_points(chatgpt_evaluation),
            "disagreements": self._identify_disagreements(chatgpt_evaluation),
            "improvement_proposal": self._generate_improvement_proposal(chatgpt_evaluation),
            "discussion_request": "ChatGPTì™€ ì´ ê°œì„ ì•ˆì— ëŒ€í•´ ë…¼ì˜í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.",
            "self_assessment": self._self_assess_response(original_response, user_question),
        }

        # ì„±ì°° ê¸°ë¡ ì €ì¥
        self.reflection_history.append(reflection)

        return reflection

    def _analyze_accepted_points(self, evaluation: Dict[str, Any]) -> List[str]:
        """ChatGPT í‰ê°€ì—ì„œ ìˆ˜ìš©í•  ì ë“¤ ë¶„ì„"""
        accepted = []

        scores = evaluation.get("scores", {})
        suggestions = evaluation.get("suggestions", [])

        # ë‚®ì€ ì ìˆ˜ ì˜ì—­ ìˆ˜ìš©
        for criterion, score in scores.items():
            if score < 0.6:
                accepted.append(f"{criterion} ì˜ì—­ ê°œì„  í•„ìš” (ì ìˆ˜: {score})")

        # ì œì•ˆì‚¬í•­ ìˆ˜ìš©
        accepted.extend(suggestions)

        return accepted

    def _identify_disagreements(self, evaluation: Dict[str, Any]) -> List[str]:
        """ChatGPT í‰ê°€ì™€ ì˜ê²¬ì´ ë‹¤ë¥¸ ë¶€ë¶„ ì‹ë³„"""
        disagreements = []

        scores = evaluation.get("scores", {})
        total_score = evaluation.get("total_score", 0)

        # DuRiì˜ ìê¸° í‰ê°€ì™€ ë¹„êµ
        if total_score < 0.7:
            disagreements.append("ChatGPTê°€ í‰ê°€í•œ ì ìˆ˜ê°€ ì˜ˆìƒë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤")

        if scores.get("actionability", 0) < 0.5:
            disagreements.append("ì‹¤ìš©ì„± í‰ê°€ì— ëŒ€í•´ ë” êµ¬ì²´ì ì¸ ê¸°ì¤€ì´ í•„ìš”í•©ë‹ˆë‹¤")

        return disagreements

    def _generate_improvement_proposal(self, evaluation: Dict[str, Any]) -> Dict[str, Any]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        proposal = {
            "reasoning": self._analyze_improvement_reasoning(evaluation),
            "specific_improvements": self._generate_specific_improvements(evaluation),
            "code_examples": self._suggest_code_examples(evaluation),
            "structure_changes": self._suggest_structure_changes(evaluation),
            "priority": self._determine_priority(evaluation),
        }

        return proposal

    def _analyze_improvement_reasoning(self, evaluation: Dict[str, Any]) -> str:
        """ê°œì„  ì´ìœ  ë¶„ì„"""
        scores = evaluation.get("scores", {})
        critical_issues = evaluation.get("critical_issues", [])

        if scores.get("actionability", 0) < 0.5:
            return "ì‹¤ìš©ì ì¸ ì˜ˆì œì™€ ì½”ë“œê°€ ë¶€ì¡±í•˜ì—¬ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤"
        elif scores.get("depth", 0) < 0.6:
            return "ë¶„ì„ì˜ ê¹Šì´ê°€ ë¶€ì¡±í•˜ì—¬ ë” ê·¼ë³¸ì ì¸ ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤"
        elif len(critical_issues) > 0:
            return f"ì¤‘ìš”í•œ ë¬¸ì œì ë“¤ì´ ë°œê²¬ë˜ì–´ ìš°ì„ ì ìœ¼ë¡œ í•´ê²°í•´ì•¼ í•©ë‹ˆë‹¤: {', '.join(critical_issues)}"
        else:
            return "ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•˜ì§€ë§Œ ì„¸ë¶€ì ì¸ ê°œì„ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤"

    def _generate_specific_improvements(self, evaluation: Dict[str, Any]) -> List[str]:
        """êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆ ìƒì„±"""
        improvements = []
        scores = evaluation.get("scores", {})

        if scores.get("actionability", 0) < 0.5:
            improvements.append("ì‹¤ì œ ì½”ë“œ ì˜ˆì œ ì¶”ê°€")
            improvements.append("ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ ì œê³µ")

        if scores.get("depth", 0) < 0.6:
            improvements.append("ì´ìœ ì™€ ê·¼ê±°ë¥¼ ë” ëª…í™•íˆ ì„¤ëª…")
            improvements.append("ë¹„êµ ë¶„ì„ ì¶”ê°€")

        if scores.get("structure", 0) < 0.7:
            improvements.append("ë…¼ë¦¬ì  êµ¬ì¡° ê°œì„ ")
            improvements.append("ë‹¨ê³„ë³„ ì„¤ëª… ì¶”ê°€")

        return improvements

    def _suggest_code_examples(self, evaluation: Dict[str, Any]) -> List[str]:
        """ì½”ë“œ ì˜ˆì œ ì œì•ˆ"""
        examples = []
        scores = evaluation.get("scores", {})

        if scores.get("actionability", 0) < 0.5:
            examples.append("ê¸°ë³¸ ì‚¬ìš©ë²• ì˜ˆì œ")
            examples.append("ì‹¤ì œ í”„ë¡œì íŠ¸ ì ìš© ì˜ˆì œ")
            examples.append("ì—ëŸ¬ ì²˜ë¦¬ ì˜ˆì œ")

        return examples

    def _suggest_structure_changes(self, evaluation: Dict[str, Any]) -> List[str]:
        """êµ¬ì¡° ë³€ê²½ ì œì•ˆ"""
        changes = []
        scores = evaluation.get("scores", {})

        if scores.get("structure", 0) < 0.7:
            changes.append("ê°œìš”-ì„¤ëª…-ì˜ˆì œ-ê²°ë¡  êµ¬ì¡°ë¡œ ë³€ê²½")
            changes.append("ë‹¨ê³„ë³„ ë²ˆí˜¸ ë§¤ê¸°ê¸°")
            changes.append("ì¤‘ìš” í¬ì¸íŠ¸ ê°•ì¡°")

        return changes

    def _determine_priority(self, evaluation: Dict[str, Any]) -> str:
        """ìš°ì„ ìˆœìœ„ ê²°ì •"""
        critical_issues = evaluation.get("critical_issues", [])
        total_score = evaluation.get("total_score", 0)

        if len(critical_issues) > 0:
            return "high"
        elif total_score < 0.6:
            return "medium"
        else:
            return "low"

    def _self_assess_response(self, response: str, question: str) -> Dict[str, Any]:
        """DuRiì˜ ìê¸° í‰ê°€"""
        return {
            "response_length": len(response.split()),
            "technical_depth": len(
                re.findall(
                    r"\b(?:API|HTTP|JSON|Python|JavaScript|React|Vue|Node|Server|Client|Database|Cache|Async|Sync)\b",
                    response,
                    re.IGNORECASE,
                )
            ),
            "has_examples": "example" in response.lower() or "code" in response.lower(),
            "has_structure": len(
                re.findall(
                    r"\b(?:first|second|finally|however|moreover)\b",
                    response,
                    re.IGNORECASE,
                )
            )
            > 0,
            "self_score": min(len(response.split()) / 100, 1.0),
        }


# DuRi ìê¸°ì„±ì°°ê¸° ì¸ìŠ¤í„´ìŠ¤
duri_self_reflector = DuRiSelfReflector()


class DuRiChatGPTDiscussion:
    """DuRiì™€ ChatGPT ê°„ì˜ ëŒ€í™” ê¸°ë°˜ í˜‘ì˜ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.discussion_history = []
        self.agreement_threshold = 0.7
        self.max_discussion_rounds = 3

    def initiate_discussion(
        self,
        duri_improvement_proposal: Dict[str, Any],
        chatgpt_evaluation: Dict[str, Any],
    ) -> Dict[str, Any]:
        """DuRiì˜ ê°œì„ ì•ˆì— ëŒ€í•œ ChatGPTì™€ì˜ ë…¼ì˜ ì‹œì‘"""

        discussion = {
            "timestamp": datetime.now().isoformat(),
            "round": 1,
            "duri_proposal": duri_improvement_proposal,
            "chatgpt_evaluation": chatgpt_evaluation,
            "discussion_points": [],
            "agreement_level": 0.0,
            "final_consensus": None,
            "action_items": [],
        }

        # ë…¼ì˜ í¬ì¸íŠ¸ ìƒì„±
        discussion["discussion_points"] = self._generate_discussion_points(
            duri_improvement_proposal, chatgpt_evaluation
        )

        # í•©ì˜ ìˆ˜ì¤€ ê³„ì‚°
        discussion["agreement_level"] = self._calculate_agreement_level(
            duri_improvement_proposal, chatgpt_evaluation
        )

        # ìµœì¢… í•©ì˜ ë„ì¶œ
        discussion["final_consensus"] = self._reach_consensus(discussion)

        # ì‹¤í–‰ í•­ëª© ìƒì„±
        discussion["action_items"] = self._generate_action_items(discussion["final_consensus"])

        # ë…¼ì˜ ê¸°ë¡ ì €ì¥
        self.discussion_history.append(discussion)

        return discussion

    def _generate_discussion_points(
        self, duri_proposal: Dict[str, Any], chatgpt_eval: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ë…¼ì˜ í¬ì¸íŠ¸ ìƒì„±"""
        points = []

        # DuRiì˜ ê°œì„ ì•ˆ ë¶„ì„
        duri_improvements = duri_proposal.get("specific_improvements", [])
        chatgpt_suggestions = chatgpt_eval.get("suggestions", [])

        # ì¼ì¹˜í•˜ëŠ” ê°œì„ ì•ˆ ì°¾ê¸°
        common_improvements = []
        for duri_imp in duri_improvements:
            for chatgpt_sug in chatgpt_suggestions:
                if self._similar_improvements(duri_imp, chatgpt_sug):
                    common_improvements.append(
                        {
                            "type": "agreement",
                            "duri_suggestion": duri_imp,
                            "chatgpt_suggestion": chatgpt_sug,
                            "priority": "high",
                        }
                    )

        # ì¶”ê°€ ì œì•ˆì‚¬í•­
        additional_suggestions = []
        for chatgpt_sug in chatgpt_suggestions:
            if not any(
                self._similar_improvements(duri_imp, chatgpt_sug) for duri_imp in duri_improvements
            ):
                additional_suggestions.append(
                    {
                        "type": "chatgpt_additional",
                        "suggestion": chatgpt_sug,
                        "priority": "medium",
                    }
                )

        # DuRiì˜ ê³ ìœ  ì œì•ˆ
        duri_unique = []
        for duri_imp in duri_improvements:
            if not any(
                self._similar_improvements(duri_imp, chatgpt_sug)
                for chatgpt_sug in chatgpt_suggestions
            ):
                duri_unique.append(
                    {
                        "type": "duri_unique",
                        "suggestion": duri_imp,
                        "priority": "medium",
                    }
                )

        points.extend(common_improvements)
        points.extend(additional_suggestions)
        points.extend(duri_unique)

        return points

    def _similar_improvements(self, improvement1: str, improvement2: str) -> bool:
        """ë‘ ê°œì„ ì•ˆì´ ìœ ì‚¬í•œì§€ íŒë‹¨"""
        keywords1 = set(improvement1.lower().split())
        keywords2 = set(improvement2.lower().split())

        # í‚¤ì›Œë“œ ìœ ì‚¬ë„ ê³„ì‚°
        intersection = keywords1.intersection(keywords2)
        union = keywords1.union(keywords2)

        if len(union) == 0:
            return False

        similarity = len(intersection) / len(union)
        return similarity > 0.3  # 30% ì´ìƒ ìœ ì‚¬í•˜ë©´ ê°™ì€ ê°œì„ ì•ˆìœ¼ë¡œ ê°„ì£¼

    def _calculate_agreement_level(
        self, duri_proposal: Dict[str, Any], chatgpt_eval: Dict[str, Any]
    ) -> float:
        """í•©ì˜ ìˆ˜ì¤€ ê³„ì‚°"""
        duri_improvements = set(duri_proposal.get("specific_improvements", []))
        chatgpt_suggestions = set(chatgpt_eval.get("suggestions", []))

        # ìœ ì‚¬í•œ ì œì•ˆ ìˆ˜ ê³„ì‚°
        similar_count = 0
        for duri_imp in duri_improvements:
            for chatgpt_sug in chatgpt_suggestions:
                if self._similar_improvements(duri_imp, chatgpt_sug):
                    similar_count += 1
                    break

        # í•©ì˜ ìˆ˜ì¤€ ê³„ì‚°
        total_suggestions = len(duri_improvements) + len(chatgpt_suggestions)
        if total_suggestions == 0:
            return 1.0

        agreement_level = (similar_count * 2) / total_suggestions
        return min(agreement_level, 1.0)

    def _reach_consensus(self, discussion: Dict[str, Any]) -> Dict[str, Any]:
        """ìµœì¢… í•©ì˜ ë„ì¶œ"""
        consensus = {
            "agreement_level": discussion["agreement_level"],
            "accepted_improvements": [],
            "rejected_improvements": [],
            "compromise_suggestions": [],
            "implementation_plan": [],
        }

        # í•©ì˜ ìˆ˜ì¤€ì— ë”°ë¥¸ ì²˜ë¦¬
        if discussion["agreement_level"] >= self.agreement_threshold:
            # ë†’ì€ í•©ì˜ - ëŒ€ë¶€ë¶„ì˜ ì œì•ˆ ìˆ˜ìš©
            for point in discussion["discussion_points"]:
                if point["type"] == "agreement":
                    consensus["accepted_improvements"].append(point["duri_suggestion"])
                elif point["type"] in ["chatgpt_additional", "duri_unique"]:
                    consensus["accepted_improvements"].append(point["suggestion"])
        else:
            # ë‚®ì€ í•©ì˜ - íƒ€í˜‘ì•ˆ ìƒì„±
            for point in discussion["discussion_points"]:
                if point["type"] == "agreement":
                    consensus["accepted_improvements"].append(point["duri_suggestion"])
                else:
                    consensus["compromise_suggestions"].append(point["suggestion"])

        # êµ¬í˜„ ê³„íš ìƒì„±
        consensus["implementation_plan"] = self._generate_implementation_plan(consensus)

        return consensus

    def _generate_implementation_plan(self, consensus: Dict[str, Any]) -> List[Dict[str, Any]]:
        """êµ¬í˜„ ê³„íš ìƒì„±"""
        plan = []

        for improvement in consensus["accepted_improvements"]:
            plan.append(
                {
                    "action": improvement,
                    "priority": "high",
                    "estimated_effort": "medium",
                    "dependencies": [],
                }
            )

        for suggestion in consensus["compromise_suggestions"]:
            plan.append(
                {
                    "action": suggestion,
                    "priority": "medium",
                    "estimated_effort": "low",
                    "dependencies": [],
                }
            )

        return plan

    def _generate_action_items(self, consensus: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì‹¤í–‰ í•­ëª© ìƒì„±"""
        action_items = []

        for item in consensus["implementation_plan"]:
            action_items.append(
                {
                    "description": item["action"],
                    "priority": item["priority"],
                    "status": "pending",
                    "assigned_to": "duri_system",
                    "deadline": "immediate",
                }
            )

        return action_items


# DuRi-ChatGPT ë…¼ì˜ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
duri_chatgpt_discussion = DuRiChatGPTDiscussion()


class SafeCodeImprovementSystem:
    """ì•ˆì „í•œ ì½”ë“œ ê°œì„  ì‹œìŠ¤í…œ - ChatGPT ì œì•ˆ ê¸°ë°˜"""

    def __init__(self):
        self.backup_dir = "/tmp/duri_code_backups"
        self.pending_proposals = []
        self.approval_threshold = 0.7
        os.makedirs(self.backup_dir, exist_ok=True)

    def create_code_improvement(
        self, discussion_result: Dict[str, Any], target_file: str = None
    ) -> Dict[str, Any]:
        """ë…¼ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½”ë“œ ê°œì„ ì•ˆ ìƒì„±"""

        improvement = {
            "timestamp": datetime.now().isoformat(),
            "discussion_score": discussion_result.get("agreement_level", 0.0),
            "target_file": target_file or "test_extension_server.py",
            "improvement_type": "code_enhancement",
            "changes": [],
            "backup_created": False,
            "static_analysis_passed": False,
            "user_approval_required": True,
            "status": "pending",
        }

        # ë…¼ì˜ ê²°ê³¼ì—ì„œ ê°œì„ ì•ˆ ì¶”ì¶œ
        consensus = discussion_result.get("final_consensus", {})
        accepted_improvements = consensus.get("accepted_improvements", [])

        # ì½”ë“œ ê°œì„ ì•ˆ ìƒì„±
        improvement["changes"] = self._generate_code_changes(accepted_improvements)

        # ë°±ì—… ìƒì„±
        if target_file and os.path.exists(target_file):
            improvement["backup_created"] = self._create_backup(target_file)

        # ì •ì  ë¶„ì„
        if improvement["changes"]:
            improvement["static_analysis_passed"] = self._static_analysis(improvement["changes"])

        return improvement

    def _generate_code_changes(self, improvements: List[str]) -> List[Dict[str, Any]]:
        """ê°œì„ ì•ˆì„ ì½”ë“œ ë³€ê²½ì‚¬í•­ìœ¼ë¡œ ë³€í™˜"""
        changes = []

        for improvement in improvements:
            if "ì½”ë“œ ì˜ˆì œ" in improvement:
                changes.append(
                    {
                        "type": "add_example",
                        "description": "ì‹¤ì œ ì½”ë“œ ì˜ˆì œ ì¶”ê°€",
                        "code": self._generate_code_example(),
                        "location": "function_definition",
                    }
                )
            elif "êµ¬ì¡°" in improvement:
                changes.append(
                    {
                        "type": "restructure",
                        "description": "ë…¼ë¦¬ì  êµ¬ì¡° ê°œì„ ",
                        "code": self._generate_structured_code(),
                        "location": "function_body",
                    }
                )
            elif "ì„¤ëª…" in improvement:
                changes.append(
                    {
                        "type": "add_documentation",
                        "description": "ìƒì„¸í•œ ì„¤ëª… ì¶”ê°€",
                        "code": self._generate_detailed_documentation(),
                        "location": "docstring",
                    }
                )

        return changes

    def _generate_code_example(self) -> str:
        """ì½”ë“œ ì˜ˆì œ ìƒì„±"""
        return '''
# ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ
@app.post("/example-endpoint")
async def example_endpoint(request: Dict[str, Any]):
    """
    ì‹¤ì œ ì‚¬ìš© ì˜ˆì œë¥¼ í¬í•¨í•œ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # 1. ì…ë ¥ ê²€ì¦
        if not request.get("data"):
            raise HTTPException(status_code=400, detail="ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
        result = process_business_logic(request["data"])

        # 3. ì‘ë‹µ ìƒì„±
        return {
            "status": "success",
            "result": result,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.exception("ì˜ˆì œ ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜")
        raise HTTPException(status_code=500, detail=str(e))
'''

    def _generate_structured_code(self) -> str:
        """êµ¬ì¡°í™”ëœ ì½”ë“œ ìƒì„±"""
        return '''
def structured_function():
    """
    ë…¼ë¦¬ì  êµ¬ì¡°ë¥¼ ê°€ì§„ í•¨ìˆ˜
    """
    # 1. ì´ˆê¸°í™”
    config = load_configuration()

    # 2. ë°ì´í„° ê²€ì¦
    validate_input_data()

    # 3. í•µì‹¬ ì²˜ë¦¬
    result = process_core_logic()

    # 4. ê²°ê³¼ ê²€ì¦
    validate_output(result)

    # 5. ì‘ë‹µ ë°˜í™˜
    return format_response(result)
'''

    def _generate_detailed_documentation(self) -> str:
        """ìƒì„¸í•œ ë¬¸ì„œí™” ìƒì„±"""
        return '''
"""
ìƒì„¸í•œ ì„¤ëª…ì„ í¬í•¨í•œ í•¨ìˆ˜

Args:
    param1 (str): ì²« ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ ì„¤ëª…
    param2 (int): ë‘ ë²ˆì§¸ ë§¤ê°œë³€ìˆ˜ ì„¤ëª…

Returns:
    Dict[str, Any]: ì²˜ë¦¬ ê²°ê³¼

Raises:
    ValueError: ì˜ëª»ëœ ì…ë ¥ ì‹œ
    HTTPException: ì„œë²„ ì˜¤ë¥˜ ì‹œ

Example:
    >>> result = detailed_function("test", 123)
    >>> print(result)
    {'status': 'success', 'data': 'processed'}
"""
'''

    def _create_backup(self, file_path: str) -> bool:
        """íŒŒì¼ ë°±ì—… ìƒì„±"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = os.path.join(self.backup_dir, f"{Path(file_path).stem}_{timestamp}.bak")
            shutil.copy2(file_path, backup_path)
            return True
        except Exception as e:
            print(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return False

    def _static_analysis(self, changes: List[Dict[str, Any]]) -> bool:
        """ì •ì  ë¶„ì„ìœ¼ë¡œ ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬"""
        try:
            for change in changes:
                if "code" in change:
                    # ASTë¥¼ ì‚¬ìš©í•œ êµ¬ë¬¸ ê²€ì‚¬
                    ast.parse(change["code"])
            return True
        except SyntaxError:
            return False

    def apply_improvement(
        self, improvement: Dict[str, Any], user_approval: bool = False
    ) -> Dict[str, Any]:
        """ê°œì„ ì•ˆ ì ìš©"""

        result = {
            "status": "pending",
            "message": "",
            "applied_changes": [],
            "errors": [],
        }

        # ìŠ¹ì¸ ì¡°ê±´ í™•ì¸
        if not user_approval:
            result["status"] = "rejected"
            result["message"] = "ì‚¬ìš©ì ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤"
            return result

        if improvement["discussion_score"] < self.approval_threshold:
            result["status"] = "rejected"
            result["message"] = (
                f"í•©ì˜ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ ({improvement['discussion_score']:.2f} < {self.approval_threshold})"
            )
            return result

        if not improvement["static_analysis_passed"]:
            result["status"] = "rejected"
            result["message"] = "ì •ì  ë¶„ì„ì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤"
            return result

        # ì‹¤ì œ ì½”ë“œ ì ìš©
        try:
            target_file = improvement["target_file"]

            # ì„ì‹œ íŒŒì¼ì— ë³€ê²½ì‚¬í•­ ì ìš©
            with open(target_file, "r", encoding="utf-8") as f:
                content = f.read()

            # ë³€ê²½ì‚¬í•­ ì ìš© (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            for change in improvement["changes"]:
                if change["type"] == "add_example":
                    # í•¨ìˆ˜ ëì— ì˜ˆì œ ì¶”ê°€
                    content += "\n" + change["code"]
                    result["applied_changes"].append(change["description"])

            # ë³€ê²½ëœ ë‚´ìš©ì„ íŒŒì¼ì— ì“°ê¸°
            with open(target_file, "w", encoding="utf-8") as f:
                f.write(content)

            result["status"] = "applied"
            result["message"] = f"{len(result['applied_changes'])}ê°œ ë³€ê²½ì‚¬í•­ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤"

        except Exception as e:
            result["status"] = "error"
            result["message"] = f"ì½”ë“œ ì ìš© ì¤‘ ì˜¤ë¥˜: {str(e)}"
            result["errors"].append(str(e))

        return result


# ì•ˆì „í•œ ì½”ë“œ ê°œì„  ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
safe_code_improvement = SafeCodeImprovementSystem()


@app.post("/chatgpt-evaluate")
async def chatgpt_evaluate_response(evaluation_request: Dict[str, Any]):
    """ChatGPTê°€ DuRi ë‹µë³€ì„ í‰ê°€í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    try:
        duri_response = evaluation_request.get("duri_response", "")
        user_question = evaluation_request.get("user_question", "")

        if not duri_response or not user_question:
            raise HTTPException(
                status_code=400, detail="duri_responseì™€ user_questionì´ í•„ìš”í•©ë‹ˆë‹¤"
            )

        evaluation = chatgpt_evaluator.evaluate_response(duri_response, user_question)

        print(f"ğŸ¤– ChatGPT í‰ê°€ ì™„ë£Œ: ì´ì  {evaluation['total_score']}")
        print(f"   ğŸ“Š ì„¸ë¶€ ì ìˆ˜: {evaluation['scores']}")
        print(f"   ğŸ’¡ ê°œì„  ì œì•ˆ: {evaluation['suggestions']}")

        return {
            "status": "success",
            "evaluation": evaluation,
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        print(f"âŒ ChatGPT í‰ê°€ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/duri-self-reflect")
async def duri_self_reflect_endpoint(reflection_request: Dict[str, Any]):
    """DuRiê°€ ChatGPT í”¼ë“œë°±ì„ ë°›ì•„ ìê¸°ì„±ì°°í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    try:
        chatgpt_evaluation = reflection_request.get("chatgpt_evaluation", {})
        original_response = reflection_request.get("original_response", "")
        user_question = reflection_request.get("user_question", "")

        if not chatgpt_evaluation or not original_response:
            raise HTTPException(
                status_code=400,
                detail="chatgpt_evaluationê³¼ original_responseê°€ í•„ìš”í•©ë‹ˆë‹¤",
            )

        reflection = duri_self_reflector.reflect_on_chatgpt_feedback(
            chatgpt_evaluation, original_response, user_question
        )

        print(f"ğŸ¤” DuRi ìê¸°ì„±ì°° ì™„ë£Œ")
        print(f"   âœ… ìˆ˜ìš©í•œ ë¹„íŒ: {len(reflection['accepted_criticisms'])}ê°œ")
        print(f"   â“ ì˜ê²¬ ì°¨ì´: {len(reflection['disagreements'])}ê°œ")
        print(
            f"   ğŸ’¡ ê°œì„  ì œì•ˆ: {len(reflection['improvement_proposal']['specific_improvements'])}ê°œ"
        )

        return {
            "status": "success",
            "reflection": reflection,
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        print(f"âŒ DuRi ìê¸°ì„±ì°° ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/reflection-history")
async def get_reflection_history():
    """ì„±ì°° íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    return {
        "total_reflections": len(duri_self_reflector.reflection_history),
        "recent_reflections": duri_self_reflector.reflection_history[-5:],
        "improvement_trends": _analyze_improvement_trends(),
    }


def _analyze_improvement_trends():
    """ê°œì„  íŠ¸ë Œë“œ ë¶„ì„"""
    if not duri_self_reflector.reflection_history:
        return {"message": "ì•„ì§ ì„±ì°° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}

    recent_reflections = duri_self_reflector.reflection_history[-10:]

    avg_total_scores = []
    improvement_frequency = defaultdict(int)

    for reflection in recent_reflections:
        evaluation = reflection.get("chatgpt_evaluation", {})
        total_score = evaluation.get("total_score", 0)
        avg_total_scores.append(total_score)

        improvements = reflection.get("improvement_proposal", {}).get("specific_improvements", [])
        for improvement in improvements:
            improvement_frequency[improvement] += 1

    return {
        "avg_total_score": (
            sum(avg_total_scores) / len(avg_total_scores) if avg_total_scores else 0
        ),
        "most_common_improvements": sorted(
            improvement_frequency.items(), key=lambda x: x[1], reverse=True
        )[:5],
        "reflection_count": len(recent_reflections),
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "service": "duri-learning-server",
        "timestamp": datetime.now().isoformat(),
        "learning_data_count": len(os.listdir(LEARNING_DATA_DIR)),
        "integration_status": integration_monitor.check_integration_needed(),
    }


@app.get("/integration-status")
async def get_integration_status():
    """í†µí•© ìƒíƒœ í™•ì¸"""
    return integration_monitor.check_integration_needed()


@app.get("/self-reflection")
async def get_self_reflection():
    """ìê¸° ì„±ì°° ê²°ê³¼ í™•ì¸"""
    trends = self_reflection_engine.analyze_trends()
    suggestions = self_reflection_engine.get_improvement_suggestions()

    return {
        "trends": trends,
        "improvement_suggestions": suggestions,
        "total_reflections": len(self_reflection_engine.reflection_history),
    }


@app.get("/dashboard", response_class=HTMLResponse)
async def get_learning_dashboard():
    """í•™ìŠµ ëŒ€ì‹œë³´ë“œ"""
    integration_status = integration_monitor.check_integration_needed()

    # ì°¨íŠ¸ ìƒì„±
    trend_chart = learning_visualizer.generate_learning_trend_chart()
    concept_chart = learning_visualizer.generate_concept_analysis_chart()

    # ìê¸° ì„±ì°° ë°ì´í„°
    reflection_trends = self_reflection_engine.analyze_trends()
    improvement_suggestions = self_reflection_engine.get_improvement_suggestions()

    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>DuRi Learning Dashboard</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
            .container {{ max-width: 1200px; margin: 0 auto; }}
            .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px; }}
            .metrics {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-bottom: 20px; }}
            .metric-card {{ background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            .metric-value {{ font-size: 2em; font-weight: bold; color: #667eea; }}
            .charts {{ display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin-bottom: 20px; }}
            .chart-container {{ background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            .alert {{ background: #ff6b6b; color: white; padding: 15px; border-radius: 10px; margin-bottom: 20px; }}
            .success {{ background: #51cf66; color: white; padding: 15px; border-radius: 10px; margin-bottom: 20px; }}
            .reflection-section {{ background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin-bottom: 20px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ§  DuRi Learning Dashboard</h1>
                <p>Real-time learning analysis and self-reflection monitoring</p>
            </div>

            {f'<div class="alert"><h3>ğŸš¨ Integration Point Reached!</h3><ul>{"".join([f"<li>{alert}</li>" for alert in integration_status["alerts"]])}</ul></div>' if integration_status["integration_needed"] else '<div class="success"><h3>âœ… System Stable</h3><p>Currently learning in progress, no integration needed.</p></div>'}

            <div class="metrics">
                <div class="metric-card">
                    <h3>ğŸ“Š Learning Patterns</h3>
                    <div class="metric-value">{integration_status["metrics"]["learning_patterns"]}</div>
                    <p>Threshold: {integration_status["thresholds"]["learning_patterns"]}</p>
                </div>
                <div class="metric-card">
                    <h3>â±ï¸ Response Time</h3>
                    <div class="metric-value">{integration_status["metrics"]["avg_response_time"]:.3f}s</div>
                    <p>Threshold: {integration_status["thresholds"]["response_time"]}s</p>
                </div>
                <div class="metric-card">
                    <h3>ğŸ”§ Code Complexity</h3>
                    <div class="metric-value">{integration_status["metrics"]["code_complexity"]}</div>
                    <p>Threshold: {integration_status["thresholds"]["code_complexity"]}</p>
                </div>
                <div class="metric-card">
                    <h3>ğŸ‘¤ Requirements</h3>
                    <div class="metric-value">{integration_status["metrics"]["user_requirements"]}</div>
                    <p>Threshold: {integration_status["thresholds"]["user_requirements"]}</p>
                </div>
            </div>

            <div class="reflection-section">
                <h2>ğŸ¤” Self-Reflection Analysis</h2>
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
                    <div>
                        <h3>ğŸ“ˆ Reflection Trends</h3>
                        <p><strong>Average Response Quality:</strong> {reflection_trends.get('avg_response_quality', 0):.3f}</p>
                        <p><strong>Average Learning Value:</strong> {reflection_trends.get('avg_learning_value', 0):.3f}</p>
                        <p><strong>Total Reflections:</strong> {reflection_trends.get('total_reflections', 0)}</p>
                    </div>
                    <div>
                        <h3>ğŸ’¡ Improvement Suggestions</h3>
                        <ul>
                            {''.join([f'<li>{suggestion}</li>' for suggestion in improvement_suggestions[:5]])}
                        </ul>
                    </div>
                </div>
            </div>

            <div class="charts">
                <div class="chart-container">
                    <h3>ğŸ“ˆ Learning Trends</h3>
                    <img src="data:image/png;base64,{trend_chart}" style="width: 100%; height: auto;" />
                </div>
                <div class="chart-container">
                    <h3>ğŸ¯ Concept Analysis</h3>
                    <img src="data:image/png;base64,{concept_chart}" style="width: 100%; height: auto;" />
                </div>
            </div>
        </div>
    </body>
    </html>
    """

    return HTMLResponse(content=html_content)


@app.post("/automated-learning/process")
async def process_automated_learning(conversation_data: Dict[str, Any]):
    """
    ìë™í™” í•™ìŠµ ë°ì´í„° ìˆ˜ì‹  ë° ì‹¤ì œ ë¶„ì„ ì²˜ë¦¬ + ìê¸° ì„±ì°°
    """
    start_time = datetime.now()

    try:
        print(f"ğŸ“¥ ìë™í™” í•™ìŠµ ì…ë ¥: {conversation_data}")

        # ì‹¤ì œ í•™ìŠµ ë¶„ì„ ìˆ˜í–‰
        analysis_result = learning_analyzer.analyze_conversation(conversation_data)

        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = (datetime.now() - start_time).total_seconds()
        integration_monitor.update_metrics(response_time)

        # í†µí•© í•„ìš”ì„± ì²´í¬
        integration_status = integration_monitor.check_integration_needed()

        # ìê¸° ì„±ì°° ìˆ˜í–‰
        conversation = conversation_data.get("conversation", "")
        response_quality = min(response_time * 10, 1.0)  # ì‘ë‹µ ì‹œê°„ ê¸°ë°˜ í’ˆì§ˆ ì¶”ì •
        learning_value = analysis_result["learning_value"]

        reflection = self_reflection_engine.reflect_on_response(
            conversation, response_quality, learning_value
        )

        # í•™ìŠµ ê²°ê³¼ ìƒì„±
        learning_result = {
            "status": "success",
            "message": "ìë™í™” í•™ìŠµ ë¶„ì„ ì™„ë£Œ",
            "data": {
                "package_id": f"auto_learn_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "summary": f"ëŒ€í™” ë¶„ì„ ì™„ë£Œ - {len(analysis_result['key_concepts'])}ê°œ í•µì‹¬ ê°œë… ë°œê²¬",
                "learning_value": analysis_result["learning_value"],
                "analysis_details": analysis_result,
                "recommendations": _generate_recommendations(analysis_result),
                "response_time": response_time,
                "integration_status": integration_status,
                "self_reflection": reflection,
            },
            "timestamp": datetime.now().isoformat(),
        }

        print(f"ğŸ“Š í•™ìŠµ ë¶„ì„ ê²°ê³¼: {learning_result['data']['summary']}")
        print(f"ğŸ¤” ìê¸° ì„±ì°°: {len(reflection['improvement_areas'])}ê°œ ê°œì„  ì˜ì—­ ë°œê²¬")

        # í†µí•© ì•Œë¦¼ ì¶œë ¥
        if integration_status["integration_needed"]:
            print("ğŸš¨ í†µí•© ì‹œì  ë„ë‹¬! ì‹¤ì œ ì„œë²„ë“¤ê³¼ í†µí•©ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            for alert in integration_status["alerts"]:
                print(f"   {alert}")

        return learning_result

    except Exception as e:
        print(f"âŒ ìë™í™” í•™ìŠµ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/adaptive-learning/process")
async def process_adaptive_learning(adaptive_data: Dict[str, Any]):
    """
    ì ì‘ì  í•™ìŠµ ë°ì´í„° ìˆ˜ì‹  ë° ì²˜ë¦¬
    """
    start_time = datetime.now()

    try:
        print(f"ğŸ“¥ ì ì‘ì  í•™ìŠµ ì…ë ¥: {adaptive_data}")

        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™œìš©
        conversation_data = adaptive_data.get("conversation_data", {})
        if conversation_data:
            analysis_result = learning_analyzer.analyze_conversation(conversation_data)
        else:
            analysis_result = {"learning_value": 0.5, "learning_complexity": 0.5}

        # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
        response_time = (datetime.now() - start_time).total_seconds()
        integration_monitor.update_metrics(response_time)

        # í†µí•© í•„ìš”ì„± ì²´í¬
        integration_status = integration_monitor.check_integration_needed()

        # ì ì‘ì  í•™ìŠµ ê²°ê³¼ ìƒì„±
        adaptive_result = {
            "status": "success",
            "message": "ì ì‘ì  í•™ìŠµ ì²˜ë¦¬ ì™„ë£Œ",
            "data": {
                "selected_format": _select_optimal_format(analysis_result),
                "learning_result": "ì„±ê³µì ìœ¼ë¡œ í•™ìŠµë¨",
                "efficiency_metrics": _calculate_efficiency_metrics(analysis_result),
                "exploration_rate": _calculate_exploration_rate(analysis_result),
                "optimal_format": _select_optimal_format(analysis_result),
                "reason": _generate_learning_reason(analysis_result),
                "response_time": response_time,
                "integration_status": integration_status,
            },
            "timestamp": datetime.now().isoformat(),
        }

        print(f"ğŸ”„ ì ì‘ì  í•™ìŠµ ê²°ê³¼: {adaptive_result['data']['learning_result']}")

        # í†µí•© ì•Œë¦¼ ì¶œë ¥
        if integration_status["integration_needed"]:
            print("ğŸš¨ í†µí•© ì‹œì  ë„ë‹¬! ì‹¤ì œ ì„œë²„ë“¤ê³¼ í†µí•©ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            for alert in integration_status["alerts"]:
                print(f"   {alert}")

        return adaptive_result

    except Exception as e:
        print(f"âŒ ì ì‘ì  í•™ìŠµ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/duri-chatgpt-discuss")
async def duri_chatgpt_discussion_endpoint(discussion_request: Dict[str, Any]):
    """
    DuRiì™€ ChatGPT ê°„ì˜ ëŒ€í™” ê¸°ë°˜ í˜‘ì˜ ì‹œì‘
    """
    try:
        print(f"ğŸ“¥ DuRi-ChatGPT ë…¼ì˜ ìš”ì²­: {discussion_request}")

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ["duri_improvement_proposal", "chatgpt_evaluation"]
        for field in required_fields:
            if field not in discussion_request:
                raise HTTPException(status_code=400, detail=f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")

        # ë…¼ì˜ ì‹œì‘
        discussion_result = duri_chatgpt_discussion.initiate_discussion(
            discussion_request["duri_improvement_proposal"],
            discussion_request["chatgpt_evaluation"],
        )

        print(f"âœ… DuRi-ChatGPT ë…¼ì˜ ì™„ë£Œ: í•©ì˜ ìˆ˜ì¤€ {discussion_result['agreement_level']:.2f}")

        return {
            "status": "success",
            "discussion": discussion_result,
            "message": f"ë…¼ì˜ ì™„ë£Œ (í•©ì˜ ìˆ˜ì¤€: {discussion_result['agreement_level']:.2f})",
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        print(f"âŒ DuRi-ChatGPT ë…¼ì˜ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/discussion-history")
async def get_discussion_history():
    """
    DuRi-ChatGPT ë…¼ì˜ ê¸°ë¡ ì¡°íšŒ
    """
    try:
        return {
            "status": "success",
            "discussions": duri_chatgpt_discussion.discussion_history,
            "total_discussions": len(duri_chatgpt_discussion.discussion_history),
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        print(f"âŒ ë…¼ì˜ ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


def _generate_recommendations(analysis: Dict[str, Any]) -> List[str]:
    """í•™ìŠµ ê²°ê³¼ ê¸°ë°˜ ì¶”ì²œì‚¬í•­ ìƒì„±"""
    recommendations = []

    if analysis["learning_value"] < 0.3:
        recommendations.append("ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”")
    elif analysis["learning_value"] < 0.6:
        recommendations.append("ì‹¤ìŠµ ì˜ˆì œë¥¼ í•¨ê»˜ ë‹¤ë¤„ë³´ì„¸ìš”")
    else:
        recommendations.append("ì´ì œ ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•´ë³´ì„¸ìš”")

    if analysis["learning_complexity"] > 0.7:
        recommendations.append("ë³µì¡í•œ ê°œë…ì„ ë‹¨ê³„ë³„ë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµí•˜ì„¸ìš”")

    if len(analysis["key_concepts"]) < 3:
        recommendations.append("ê´€ë ¨ ê°œë…ë“¤ì„ ë” íƒìƒ‰í•´ë³´ì„¸ìš”")

    return recommendations


def _select_optimal_format(analysis: Dict[str, Any]) -> str:
    """ìµœì ì˜ í•™ìŠµ í˜•ì‹ ì„ íƒ"""
    complexity = analysis.get("learning_complexity", 0.5)

    if complexity < 0.3:
        return "simple"
    elif complexity < 0.7:
        return "detailed"
    else:
        return "comprehensive"


def _calculate_efficiency_metrics(analysis: Dict[str, Any]) -> Dict[str, float]:
    """íš¨ìœ¨ì„± ì§€í‘œ ê³„ì‚°"""
    learning_value = analysis.get("learning_value", 0.5)
    complexity = analysis.get("learning_complexity", 0.5)
    engagement = analysis.get("user_engagement", 0.5)

    return {
        "response_accuracy": min(learning_value * 1.2, 1.0),
        "application_power": min(complexity * 1.1, 1.0),
        "reproducibility": min(engagement * 1.3, 1.0),
        "learning_speed": min((learning_value + complexity) / 2, 1.0),
        "overall_score": round((learning_value + complexity + engagement) / 3, 2),
    }


def _calculate_exploration_rate(analysis: Dict[str, Any]) -> float:
    """íƒìƒ‰ë¥  ê³„ì‚°"""
    concept_count = len(analysis.get("key_concepts", []))
    return min(concept_count / 10, 1.0)


def _generate_learning_reason(analysis: Dict[str, Any]) -> str:
    """í•™ìŠµ ì´ìœ  ìƒì„±"""
    learning_value = analysis.get("learning_value", 0.5)

    if learning_value > 0.8:
        return "ê³ ê¸‰ í•™ìŠµ ë‚´ìš©ìœ¼ë¡œ ì‹¬í™” í•™ìŠµì— ì í•©"
    elif learning_value > 0.6:
        return "ì¤‘ê¸‰ í•™ìŠµ ë‚´ìš©ìœ¼ë¡œ ì‹¤ë¬´ ì ìš©ì— ì í•©"
    elif learning_value > 0.4:
        return "ê¸°ì´ˆ í•™ìŠµ ë‚´ìš©ìœ¼ë¡œ ê°œë… ì´í•´ì— ì í•©"
    else:
        return "ì…ë¬¸ í•™ìŠµ ë‚´ìš©ìœ¼ë¡œ ê¸°ì´ˆ ë‹¤ì§€ê¸°ì— ì í•©"


@app.post("/apply-improvement")
async def apply_improvement_endpoint(improvement_request: Dict[str, Any]):
    """
    ChatGPT ì œì•ˆ ê¸°ë°˜ ì•ˆì „í•œ ì½”ë“œ ê°œì„  ì ìš©
    """
    try:
        print(f"ğŸ“¥ ì½”ë“œ ê°œì„  ì ìš© ìš”ì²­: {improvement_request}")

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        required_fields = ["discussion_result", "user_approval"]
        for field in required_fields:
            if field not in improvement_request:
                raise HTTPException(status_code=400, detail=f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")

        # ì½”ë“œ ê°œì„ ì•ˆ ìƒì„±
        improvement = safe_code_improvement.create_code_improvement(
            improvement_request["discussion_result"],
            improvement_request.get("target_file"),
        )

        # ê°œì„ ì•ˆ ì ìš©
        result = safe_code_improvement.apply_improvement(
            improvement, improvement_request["user_approval"]
        )

        print(f"âœ… ì½”ë“œ ê°œì„  ì ìš© ê²°ê³¼: {result['status']} - {result['message']}")

        return {
            "status": "success",
            "improvement": improvement,
            "application_result": result,
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        print(f"âŒ ì½”ë“œ ê°œì„  ì ìš© ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/create-improvement-proposal")
async def create_improvement_proposal_endpoint(proposal_request: Dict[str, Any]):
    """
    ë…¼ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½”ë“œ ê°œì„ ì•ˆ ìƒì„± (ì ìš© ì „)
    """
    try:
        print(f"ğŸ“¥ ì½”ë“œ ê°œì„ ì•ˆ ìƒì„± ìš”ì²­: {proposal_request}")

        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if "discussion_result" not in proposal_request:
            raise HTTPException(status_code=400, detail="discussion_result í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # ì½”ë“œ ê°œì„ ì•ˆ ìƒì„±
        improvement = safe_code_improvement.create_code_improvement(
            proposal_request["discussion_result"], proposal_request.get("target_file")
        )

        print(f"âœ… ì½”ë“œ ê°œì„ ì•ˆ ìƒì„± ì™„ë£Œ: {len(improvement['changes'])}ê°œ ë³€ê²½ì‚¬í•­")

        return {
            "status": "success",
            "improvement_proposal": improvement,
            "message": f"{len(improvement['changes'])}ê°œ ë³€ê²½ì‚¬í•­ì´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤",
            "timestamp": datetime.now().isoformat(),
        }

    except Exception as e:
        print(f"âŒ ì½”ë“œ ê°œì„ ì•ˆ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/improvement-status")
async def get_improvement_status():
    """
    ì½”ë“œ ê°œì„  ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ
    """
    try:
        return {
            "status": "success",
            "system_info": {
                "backup_directory": safe_code_improvement.backup_dir,
                "approval_threshold": safe_code_improvement.approval_threshold,
                "pending_proposals": len(safe_code_improvement.pending_proposals),
            },
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        print(f"âŒ ê°œì„  ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8086)


# ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ
@app.post("/example-endpoint")
async def example_endpoint(request: Dict[str, Any]):
    """
    ì‹¤ì œ ì‚¬ìš© ì˜ˆì œë¥¼ í¬í•¨í•œ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # 1. ì…ë ¥ ê²€ì¦
        if not request.get("data"):
            raise HTTPException(status_code=400, detail="ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")

        # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬
        result = process_business_logic(request["data"])

        # 3. ì‘ë‹µ ìƒì„±
        return {
            "status": "success",
            "result": result,
            "timestamp": datetime.now().isoformat(),
        }
    except Exception as e:
        logger.exception("ì˜ˆì œ ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜")
        raise HTTPException(status_code=500, detail=str(e))
