#!/usr/bin/env python3
"""
ì‹¤ì œ ëŒ€í™” ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥ ì‹œìŠ¤í…œ
"""

import hashlib
import json
import os
from datetime import datetime
from typing import Any, Dict, List

DATA_PATH = "/tmp/duri_conversations"
os.makedirs(DATA_PATH, exist_ok=True)


class ConversationStore:
    """ì‹¤ì œ ëŒ€í™” ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.data_path = DATA_PATH
        self.conversation_history = []
        self.learning_patterns = []

    def store_conversation(
        self, user_input: str, duri_response: str, metadata: Dict[str, Any] = None
    ) -> str:
        """ëŒ€í™” ë°ì´í„° ì €ì¥"""

        timestamp = datetime.now()
        conversation_id = self._generate_conversation_id(user_input, timestamp)

        conversation_data = {
            "conversation_id": conversation_id,
            "timestamp": timestamp.isoformat(),
            "user_input": user_input,
            "duri_response": duri_response,
            "metadata": metadata or {},
            "learning_value": self._calculate_learning_value(user_input, duri_response),
            "conversation_length": len(user_input) + len(duri_response),
            "response_time": metadata.get("response_time", 0) if metadata else 0,
        }

        # íŒŒì¼ì— ì €ì¥
        filename = f"{self.data_path}/conversation_{conversation_id}.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(conversation_data, f, ensure_ascii=False, indent=2)

        # ë©”ëª¨ë¦¬ì— ì €ì¥
        self.conversation_history.append(conversation_data)

        print(f"ğŸ’¾ ëŒ€í™” ì €ì¥ ì™„ë£Œ: {conversation_id}")
        print(f"   ğŸ“ ì‚¬ìš©ì ì…ë ¥: {len(user_input)}ì")
        print(f"   ğŸ¤– DuRi ì‘ë‹µ: {len(duri_response)}ì")
        print(f"   ğŸ“Š í•™ìŠµ ê°€ì¹˜: {conversation_data['learning_value']:.2f}")

        return conversation_id

    def _generate_conversation_id(self, user_input: str, timestamp: datetime) -> str:
        """ëŒ€í™” ID ìƒì„±"""
        content_hash = hashlib.md5(f"{user_input}{timestamp}".encode()).hexdigest()[:8]
        return f"{timestamp.strftime('%Y%m%d_%H%M%S')}_{content_hash}"

    def _calculate_learning_value(self, user_input: str, duri_response: str) -> float:
        """í•™ìŠµ ê°€ì¹˜ ê³„ì‚°"""
        # ì…ë ¥ ë³µì¡ë„
        input_complexity = len(user_input.split()) / 10.0

        # ì‘ë‹µ í’ˆì§ˆ
        response_quality = len(duri_response.split()) / 20.0

        # ê¸°ìˆ ì  í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
        tech_keywords = [
            "API",
            "HTTP",
            "JSON",
            "async",
            "await",
            "FastAPI",
            "Flask",
            "Python",
            "ì½”ë“œ",
            "êµ¬í˜„",
        ]
        tech_score = sum(
            1 for keyword in tech_keywords if keyword.lower() in duri_response.lower()
        ) / len(tech_keywords)

        # ì¢…í•© í•™ìŠµ ê°€ì¹˜
        learning_value = (input_complexity + response_quality + tech_score) / 3.0
        return min(learning_value, 1.0)

    def get_conversation_history(self, limit: int = 50) -> List[Dict[str, Any]]:
        """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
        return sorted(self.conversation_history, key=lambda x: x["timestamp"], reverse=True)[:limit]

    def get_learning_statistics(self) -> Dict[str, Any]:
        """í•™ìŠµ í†µê³„ ìƒì„±"""
        if not self.conversation_history:
            return {"total_conversations": 0, "avg_learning_value": 0.0}

        total_conversations = len(self.conversation_history)
        avg_learning_value = (
            sum(conv["learning_value"] for conv in self.conversation_history) / total_conversations
        )
        total_response_time = sum(
            conv.get("response_time", 0) for conv in self.conversation_history
        )
        avg_response_time = (
            total_response_time / total_conversations if total_conversations > 0 else 0
        )

        return {
            "total_conversations": total_conversations,
            "avg_learning_value": avg_learning_value,
            "avg_response_time": avg_response_time,
            "total_conversation_length": sum(
                conv["conversation_length"] for conv in self.conversation_history
            ),
            "high_value_conversations": len(
                [conv for conv in self.conversation_history if conv["learning_value"] > 0.7]
            ),
        }

    def extract_learning_patterns(self) -> List[Dict[str, Any]]:
        """í•™ìŠµ íŒ¨í„´ ì¶”ì¶œ"""
        patterns = []

        # ìì£¼ ë‚˜ì˜¤ëŠ” í‚¤ì›Œë“œ íŒ¨í„´
        keyword_patterns = {}
        for conv in self.conversation_history:
            user_words = set(conv["user_input"].lower().split())
            for word in user_words:
                if len(word) > 3:  # 3ê¸€ì ì´ìƒë§Œ
                    keyword_patterns[word] = keyword_patterns.get(word, 0) + 1

        # ìƒìœ„ í‚¤ì›Œë“œ
        top_keywords = sorted(keyword_patterns.items(), key=lambda x: x[1], reverse=True)[:10]

        # ì‘ë‹µ ê¸¸ì´ íŒ¨í„´
        response_lengths = [conv["conversation_length"] for conv in self.conversation_history]
        avg_length = sum(response_lengths) / len(response_lengths) if response_lengths else 0

        patterns.append(
            {
                "type": "keyword_patterns",
                "data": top_keywords,
                "description": "ìì£¼ ì–¸ê¸‰ë˜ëŠ” í‚¤ì›Œë“œ íŒ¨í„´",
            }
        )

        patterns.append(
            {
                "type": "response_length_pattern",
                "data": {
                    "average_length": avg_length,
                    "total_conversations": len(response_lengths),
                },
                "description": "ì‘ë‹µ ê¸¸ì´ íŒ¨í„´",
            }
        )

        return patterns

    def get_conversation_by_id(self, conversation_id: str) -> Dict[str, Any]:
        """íŠ¹ì • ëŒ€í™” ì¡°íšŒ"""
        for conv in self.conversation_history:
            if conv["conversation_id"] == conversation_id:
                return conv
        return {}

    def get_statistics(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            learning_stats = self.get_learning_statistics()
            patterns = self.extract_learning_patterns()

            return {
                "learning_statistics": learning_stats,
                "learning_patterns": patterns,
                "total_conversations": len(self.conversation_history),
                "recent_conversations": (
                    len(self.conversation_history[-10:]) if self.conversation_history else 0
                ),
            }
        except Exception as e:
            print(f"í†µê³„ ìƒì„± ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def get_recent_conversations(self, limit: int = 10) -> List[Dict[str, Any]]:
        """ìµœê·¼ ëŒ€í™” ê¸°ë¡ ë°˜í™˜"""
        return self.get_conversation_history(limit)


# ëª¨ë“ˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
conversation_store = ConversationStore()
