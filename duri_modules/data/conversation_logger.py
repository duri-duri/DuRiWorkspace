#!/usr/bin/env python3
"""
ëŒ€í™” ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œìŠ¤í…œ - DuRiì˜ ì‹¤ì œ í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
"""

import json
import logging
import os
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


@dataclass
class ConversationEntry:
    """ëŒ€í™” ì—”íŠ¸ë¦¬"""

    timestamp: str
    user_input: str
    duri_response: str
    response_time: float
    success: bool
    learning_patterns: List[str]
    improvement_areas: List[str]
    evolution_metrics: Dict[str, float]


@dataclass
class EvolutionLog:
    """ì§„í™” ë¡œê·¸"""

    conversation_id: str
    start_time: str
    end_time: str
    total_exchanges: int
    average_response_time: float
    learning_efficiency: float
    problem_solving_score: float
    autonomy_level: float
    evolution_patterns: List[str]
    key_insights: List[str]


class ConversationLogger:
    """ëŒ€í™” ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œìŠ¤í…œ"""

    def __init__(self, log_dir: str = "conversation_logs"):
        self.log_dir = log_dir
        self.current_conversation = []
        self.conversation_history = []
        self.evolution_logs = []

        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(log_dir, exist_ok=True)

        # ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ
        self._load_existing_logs()

        logger.info("ğŸ§  ëŒ€í™” ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    def start_conversation(self, conversation_id: str = None) -> str:
        """ìƒˆë¡œìš´ ëŒ€í™” ì‹œì‘"""
        if not conversation_id:
            conversation_id = f"conversation_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        self.current_conversation = []
        self.current_conversation_id = conversation_id

        logger.info(f"ğŸ”„ ëŒ€í™” ì‹œì‘: {conversation_id}")
        return conversation_id

    def log_exchange(
        self,
        user_input: str,
        duri_response: str,
        response_time: float,
        success: bool = True,
        learning_patterns: List[str] = None,
        improvement_areas: List[str] = None,
        evolution_metrics: Dict[str, float] = None,
    ):
        """ëŒ€í™” êµí™˜ ë¡œê·¸"""
        entry = ConversationEntry(
            timestamp=datetime.now().isoformat(),
            user_input=user_input,
            duri_response=duri_response,
            response_time=response_time,
            success=success,
            learning_patterns=learning_patterns or [],
            improvement_areas=improvement_areas or [],
            evolution_metrics=evolution_metrics or {},
        )

        self.current_conversation.append(entry)

        # ì‹¤ì‹œê°„ ë¶„ì„
        self._analyze_exchange(entry)

        logger.info(
            f"ğŸ“ ëŒ€í™” êµí™˜ ë¡œê·¸: {response_time:.3f}ì´ˆ ({'ì„±ê³µ' if success else 'ì‹¤íŒ¨'})"
        )

    def end_conversation(self) -> EvolutionLog:
        """ëŒ€í™” ì¢…ë£Œ ë° ì§„í™” ë¡œê·¸ ìƒì„±"""
        if not self.current_conversation:
            return None

        # ëŒ€í™” ìš”ì•½ ìƒì„±
        evolution_log = self._create_evolution_log()

        # ë¡œê·¸ ì €ì¥
        self._save_conversation_log()
        self._save_evolution_log(evolution_log)

        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.conversation_history.append(self.current_conversation)
        self.evolution_logs.append(evolution_log)

        logger.info(
            f"ğŸ ëŒ€í™” ì¢…ë£Œ: {evolution_log.total_exchanges}êµí™˜, íš¨ìœ¨ì„± {evolution_log.learning_efficiency:.3f}"
        )

        return evolution_log

    def get_conversation_statistics(self) -> Dict[str, Any]:
        """ëŒ€í™” í†µê³„ ë°˜í™˜"""
        if not self.evolution_logs:
            return {"status": "no_data"}

        total_conversations = len(self.evolution_logs)
        total_exchanges = sum(log.total_exchanges for log in self.evolution_logs)
        avg_response_time = (
            sum(log.average_response_time for log in self.evolution_logs)
            / total_conversations
        )
        avg_learning_efficiency = (
            sum(log.learning_efficiency for log in self.evolution_logs)
            / total_conversations
        )
        avg_problem_solving = (
            sum(log.problem_solving_score for log in self.evolution_logs)
            / total_conversations
        )
        avg_autonomy = (
            sum(log.autonomy_level for log in self.evolution_logs) / total_conversations
        )

        # ì§„í™” íŒ¨í„´ ë¶„ì„
        evolution_patterns = self._analyze_evolution_patterns()

        return {
            "status": "success",
            "total_conversations": total_conversations,
            "total_exchanges": total_exchanges,
            "average_response_time": avg_response_time,
            "average_learning_efficiency": avg_learning_efficiency,
            "average_problem_solving": avg_problem_solving,
            "average_autonomy": avg_autonomy,
            "evolution_patterns": evolution_patterns,
            "recent_trends": self._analyze_recent_trends(),
        }

    def extract_learning_patterns(self) -> List[Dict[str, Any]]:
        """í•™ìŠµ íŒ¨í„´ ì¶”ì¶œ"""
        patterns = []

        for conversation in self.conversation_history:
            for entry in conversation:
                if entry.learning_patterns:
                    for pattern in entry.learning_patterns:
                        patterns.append(
                            {
                                "timestamp": entry.timestamp,
                                "pattern": pattern,
                                "context": (
                                    entry.user_input[:100] + "..."
                                    if len(entry.user_input) > 100
                                    else entry.user_input
                                ),
                            }
                        )

        return patterns

    def get_improvement_suggestions(self) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []

        # ì‘ë‹µ ì‹œê°„ ë¶„ì„
        response_times = [
            entry.response_time for conv in self.conversation_history for entry in conv
        ]
        if response_times:
            avg_response_time = sum(response_times) / len(response_times)
            if avg_response_time > 2.0:
                suggestions.append(
                    "ì‘ë‹µ ì‹œê°„ì´ 2ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ì„±ëŠ¥ ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )

        # í•™ìŠµ íš¨ìœ¨ì„± ë¶„ì„
        learning_efficiencies = [log.learning_efficiency for log in self.evolution_logs]
        if learning_efficiencies:
            avg_efficiency = sum(learning_efficiencies) / len(learning_efficiencies)
            if avg_efficiency < 0.6:
                suggestions.append(
                    "í•™ìŠµ íš¨ìœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. í•™ìŠµ ë°©ë²• ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤."
                )

        # ììœ¨ì„± ë¶„ì„
        autonomy_levels = [log.autonomy_level for log in self.evolution_logs]
        if autonomy_levels:
            avg_autonomy = sum(autonomy_levels) / len(autonomy_levels)
            if avg_autonomy < 0.5:
                suggestions.append(
                    "ììœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤. ììœ¨ì  ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ í–¥ìƒì´ í•„ìš”í•©ë‹ˆë‹¤."
                )

        return suggestions

    def _analyze_exchange(self, entry: ConversationEntry):
        """êµí™˜ ë¶„ì„"""
        # í•™ìŠµ íŒ¨í„´ ìë™ ê°ì§€
        if "ê°œì„ " in entry.user_input or "ìˆ˜ì •" in entry.user_input:
            entry.learning_patterns.append("feedback_learning")

        if "ì™œ" in entry.user_input or "ì–´ë–»ê²Œ" in entry.user_input:
            entry.learning_patterns.append("explanation_seeking")

        if "ì˜ˆì‹œ" in entry.user_input or "ì˜ˆë¥¼ ë“¤ì–´" in entry.user_input:
            entry.learning_patterns.append("example_based_learning")

        # ì§„í™” ë©”íŠ¸ë¦­ ê³„ì‚°
        entry.evolution_metrics = {
            "response_quality": (
                min(1.0, 1.0 / entry.response_time) if entry.response_time > 0 else 0.0
            ),
            "learning_depth": len(entry.learning_patterns) / 10.0,
            "problem_solving": 1.0 if entry.success else 0.5,
        }

    def _create_evolution_log(self) -> EvolutionLog:
        """ì§„í™” ë¡œê·¸ ìƒì„±"""
        if not self.current_conversation:
            return None

        start_time = self.current_conversation[0].timestamp
        end_time = self.current_conversation[-1].timestamp

        # í‰ê·  ì‘ë‹µ ì‹œê°„
        response_times = [entry.response_time for entry in self.current_conversation]
        avg_response_time = sum(response_times) / len(response_times)

        # í•™ìŠµ íš¨ìœ¨ì„± ê³„ì‚°
        learning_patterns = [
            pattern
            for entry in self.current_conversation
            for pattern in entry.learning_patterns
        ]
        learning_efficiency = min(
            1.0, len(learning_patterns) / len(self.current_conversation)
        )

        # ë¬¸ì œ í•´ê²° ì ìˆ˜
        success_count = sum(1 for entry in self.current_conversation if entry.success)
        problem_solving_score = success_count / len(self.current_conversation)

        # ììœ¨ì„± ë ˆë²¨ (ì‚¬ìš©ì ê°œì… ìµœì†Œí™”)
        autonomous_responses = sum(
            1 for entry in self.current_conversation if len(entry.learning_patterns) > 0
        )
        autonomy_level = autonomous_responses / len(self.current_conversation)

        # ì§„í™” íŒ¨í„´ ë¶„ì„
        evolution_patterns = self._extract_conversation_patterns()

        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
        key_insights = self._extract_key_insights()

        return EvolutionLog(
            conversation_id=self.current_conversation_id,
            start_time=start_time,
            end_time=end_time,
            total_exchanges=len(self.current_conversation),
            average_response_time=avg_response_time,
            learning_efficiency=learning_efficiency,
            problem_solving_score=problem_solving_score,
            autonomy_level=autonomy_level,
            evolution_patterns=evolution_patterns,
            key_insights=key_insights,
        )

    def _extract_conversation_patterns(self) -> List[str]:
        """ëŒ€í™” íŒ¨í„´ ì¶”ì¶œ"""
        patterns = []

        # ì‘ë‹µ ì‹œê°„ íŒ¨í„´
        response_times = [entry.response_time for entry in self.current_conversation]
        if len(response_times) > 1:
            if all(t2 >= t1 for t1, t2 in zip(response_times[:-1], response_times[1:])):
                patterns.append("response_time_increasing")
            elif all(
                t2 <= t1 for t1, t2 in zip(response_times[:-1], response_times[1:])
            ):
                patterns.append("response_time_decreasing")

        # í•™ìŠµ íŒ¨í„´
        learning_counts = [
            len(entry.learning_patterns) for entry in self.current_conversation
        ]
        if any(count > 0 for count in learning_counts):
            patterns.append("active_learning")

        # ì„±ê³µ íŒ¨í„´
        success_rate = sum(
            1 for entry in self.current_conversation if entry.success
        ) / len(self.current_conversation)
        if success_rate > 0.8:
            patterns.append("high_success_rate")
        elif success_rate < 0.5:
            patterns.append("low_success_rate")

        return patterns

    def _extract_key_insights(self) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []

        # ê°€ì¥ ê¸´ ì‘ë‹µ ì‹œê°„
        max_response_time = max(
            entry.response_time for entry in self.current_conversation
        )
        if max_response_time > 3.0:
            insights.append(f"ìµœëŒ€ ì‘ë‹µ ì‹œê°„: {max_response_time:.2f}ì´ˆ (ê°œì„  í•„ìš”)")

        # í•™ìŠµ íŒ¨í„´
        total_learning_patterns = sum(
            len(entry.learning_patterns) for entry in self.current_conversation
        )
        if total_learning_patterns > 0:
            insights.append(f"í•™ìŠµ íŒ¨í„´ {total_learning_patterns}ê°œ ê°ì§€ë¨")

        # ì„±ê³µë¥ 
        success_rate = sum(
            1 for entry in self.current_conversation if entry.success
        ) / len(self.current_conversation)
        insights.append(f"ì„±ê³µë¥ : {success_rate:.1%}")

        return insights

    def _analyze_evolution_patterns(self) -> Dict[str, Any]:
        """ì§„í™” íŒ¨í„´ ë¶„ì„"""
        if not self.evolution_logs:
            return {}

        patterns = {}
        for log in self.evolution_logs:
            for pattern in log.evolution_patterns:
                patterns[pattern] = patterns.get(pattern, 0) + 1

        return patterns

    def _analyze_recent_trends(self) -> Dict[str, Any]:
        """ìµœê·¼ íŠ¸ë Œë“œ ë¶„ì„"""
        if len(self.evolution_logs) < 2:
            return {}

        recent_logs = self.evolution_logs[-5:]  # ìµœê·¼ 5ê°œ ëŒ€í™”

        trends = {
            "response_time_trend": "stable",
            "learning_efficiency_trend": "stable",
            "problem_solving_trend": "stable",
            "autonomy_trend": "stable",
        }

        # ì‘ë‹µ ì‹œê°„ íŠ¸ë Œë“œ
        response_times = [log.average_response_time for log in recent_logs]
        if len(response_times) >= 2:
            if response_times[-1] < response_times[0]:
                trends["response_time_trend"] = "improving"
            elif response_times[-1] > response_times[0]:
                trends["response_time_trend"] = "declining"

        # í•™ìŠµ íš¨ìœ¨ì„± íŠ¸ë Œë“œ
        efficiencies = [log.learning_efficiency for log in recent_logs]
        if len(efficiencies) >= 2:
            if efficiencies[-1] > efficiencies[0]:
                trends["learning_efficiency_trend"] = "improving"
            elif efficiencies[-1] < efficiencies[0]:
                trends["learning_efficiency_trend"] = "declining"

        return trends

    def _save_conversation_log(self):
        """ëŒ€í™” ë¡œê·¸ ì €ì¥"""
        if not self.current_conversation:
            return

        log_file = os.path.join(self.log_dir, f"{self.current_conversation_id}.json")

        conversation_data = {
            "conversation_id": self.current_conversation_id,
            "entries": [asdict(entry) for entry in self.current_conversation],
        }

        with open(log_file, "w", encoding="utf-8") as f:
            json.dump(conversation_data, f, ensure_ascii=False, indent=2)

    def _save_evolution_log(self, evolution_log: EvolutionLog):
        """ì§„í™” ë¡œê·¸ ì €ì¥"""
        if not evolution_log:
            return

        log_file = os.path.join(
            self.log_dir, f"evolution_{evolution_log.conversation_id}.json"
        )

        with open(log_file, "w", encoding="utf-8") as f:
            json.dump(asdict(evolution_log), f, ensure_ascii=False, indent=2)

    def _load_existing_logs(self):
        """ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ"""
        try:
            # ì§„í™” ë¡œê·¸ íŒŒì¼ë“¤ ë¡œë“œ
            for filename in os.listdir(self.log_dir):
                if filename.startswith("evolution_") and filename.endswith(".json"):
                    filepath = os.path.join(self.log_dir, filename)
                    with open(filepath, "r", encoding="utf-8") as f:
                        log_data = json.load(f)
                        evolution_log = EvolutionLog(**log_data)
                        self.evolution_logs.append(evolution_log)

            logger.info(f"ğŸ“š ê¸°ì¡´ ì§„í™” ë¡œê·¸ {len(self.evolution_logs)}ê°œ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ ì˜¤ë¥˜: {e}")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
conversation_logger = ConversationLogger()
