#!/usr/bin/env python3
"""
DuRi í†µì°° í‰ê°€ ì‹œìŠ¤í…œ (Day 7)
ê°€ì§œ í†µì°° â†’ ì§„ì§œ í†µì°° êµ¬ë¶„ìœ¼ë¡œ ì „í™˜
"""

import asyncio
import json
import logging
import re
from dataclasses import asdict, dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class InsightType(Enum):
    """í†µì°° ìœ í˜•"""

    GENUINE = "genuine"
    SUPERFICIAL = "superficial"
    CONTRIVED = "contrived"
    DEEP = "deep"
    SHALLOW = "shallow"


class AuthenticityLevel(Enum):
    """ì§„ìœ„ì„± ìˆ˜ì¤€"""

    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    UNKNOWN = "unknown"


@dataclass
class JudgmentQualityMetrics:
    """íŒë‹¨ í’ˆì§ˆ ë©”íŠ¸ë¦­"""

    logical_consistency: float  # 0.0-1.0
    evidence_support: float  # 0.0-1.0
    reasoning_depth: float  # 0.0-1.0
    originality: float  # 0.0-1.0
    practical_relevance: float  # 0.0-1.0
    overall_quality: float  # 0.0-1.0


@dataclass
class InsightAuthenticityCheck:
    """í†µì°° ì§„ìœ„ì„± ê²€ì‚¬"""

    insight_id: str
    insight_type: InsightType
    authenticity_level: AuthenticityLevel
    confidence_score: float
    evidence_quality: float
    reasoning_quality: float
    originality_score: float
    practical_value: float
    red_flags: List[str]
    green_flags: List[str]


class JudgmentQualityMetricsEvaluator:
    """íŒë‹¨ í’ˆì§ˆ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.quality_indicators = self._initialize_quality_indicators()
        self.evaluation_criteria = self._initialize_evaluation_criteria()

    def _initialize_quality_indicators(self) -> Dict[str, Dict]:
        """í’ˆì§ˆ ì§€í‘œ ì´ˆê¸°í™”"""
        return {
            "logical_consistency": {
                "keywords": ["ë…¼ë¦¬", "ì¼ê´€ì„±", "ëª¨ìˆœ", "ì „ì œ", "ê²°ë¡ "],
                "weight": 0.25,
                "description": "ë…¼ë¦¬ì  ì¼ê´€ì„± ë° ëª¨ìˆœ ì—†ëŠ” ì¶”ë¡ ",
            },
            "evidence_support": {
                "keywords": ["ì¦ê±°", "ì‚¬ì‹¤", "ë°ì´í„°", "ê·¼ê±°", "ì…ì¦"],
                "weight": 0.20,
                "description": "ì£¼ì¥ì„ ë’·ë°›ì¹¨í•˜ëŠ” ì¦ê±°ì˜ í’ˆì§ˆ",
            },
            "reasoning_depth": {
                "keywords": ["ê¹Šì´", "ë¶„ì„", "íƒêµ¬", "ê³ ì°°", "ì‚¬ê³ "],
                "weight": 0.20,
                "description": "ì‚¬ê³ ì˜ ê¹Šì´ì™€ ë¶„ì„ ìˆ˜ì¤€",
            },
            "originality": {
                "keywords": ["ë…ì°½", "ìƒˆë¡œìš´", "í˜ì‹ ", "ì°½ì˜", "ë…íŠ¹"],
                "weight": 0.15,
                "description": "ë…ì°½ì„±ê³¼ ìƒˆë¡œìš´ ê´€ì ",
            },
            "practical_relevance": {
                "keywords": ["ì‹¤ìš©", "ì ìš©", "ì‹¤ì œ", "ìœ ìš©", "íš¨ê³¼"],
                "weight": 0.20,
                "description": "ì‹¤ìš©ì  ê°€ì¹˜ì™€ ì ìš© ê°€ëŠ¥ì„±",
            },
        }

    def _initialize_evaluation_criteria(self) -> Dict[str, List[str]]:
        """í‰ê°€ ê¸°ì¤€ ì´ˆê¸°í™”"""
        return {
            "high_quality": [
                "ë…¼ë¦¬ì  ì¼ê´€ì„±ì´ ë†’ìŒ",
                "ì¶©ë¶„í•œ ì¦ê±°ë¡œ ë’·ë°›ì¹¨ë¨",
                "ê¹Šì´ ìˆëŠ” ë¶„ì„ í¬í•¨",
                "ë…ì°½ì ì¸ ê´€ì  ì œì‹œ",
                "ì‹¤ìš©ì  ê°€ì¹˜ê°€ ëª…í™•í•¨",
            ],
            "medium_quality": [
                "ì¼ë¶€ ë…¼ë¦¬ì  ì¼ê´€ì„±",
                "ì œí•œì  ì¦ê±°",
                "ì¤‘ê°„ ìˆ˜ì¤€ì˜ ë¶„ì„",
                "ì¼ë°˜ì ì¸ ê´€ì ",
                "ë¶€ë¶„ì  ì‹¤ìš©ì„±",
            ],
            "low_quality": [
                "ë…¼ë¦¬ì  ëª¨ìˆœ ì¡´ì¬",
                "ì¦ê±° ë¶€ì¡±",
                "í‘œë©´ì  ë¶„ì„",
                "ì§„ë¶€í•œ ê´€ì ",
                "ì‹¤ìš©ì„± ë¶€ì¡±",
            ],
        }

    async def evaluate_judgment_quality(
        self, judgment_content: str, reasoning_process: Dict[str, Any]
    ) -> JudgmentQualityMetrics:
        """íŒë‹¨ í’ˆì§ˆ í‰ê°€"""
        logger.info("íŒë‹¨ í’ˆì§ˆ í‰ê°€ ì‹œì‘")

        # ê° í’ˆì§ˆ ì§€í‘œ í‰ê°€
        logical_consistency = self._evaluate_logical_consistency(
            judgment_content, reasoning_process
        )
        evidence_support = self._evaluate_evidence_support(judgment_content, reasoning_process)
        reasoning_depth = self._evaluate_reasoning_depth(judgment_content, reasoning_process)
        originality = self._evaluate_originality(judgment_content, reasoning_process)
        practical_relevance = self._evaluate_practical_relevance(
            judgment_content, reasoning_process
        )

        # ì¢…í•© í’ˆì§ˆ ê³„ì‚°
        overall_quality = self._calculate_overall_quality(
            logical_consistency,
            evidence_support,
            reasoning_depth,
            originality,
            practical_relevance,
        )

        metrics = JudgmentQualityMetrics(
            logical_consistency=logical_consistency,
            evidence_support=evidence_support,
            reasoning_depth=reasoning_depth,
            originality=originality,
            practical_relevance=practical_relevance,
            overall_quality=overall_quality,
        )

        logger.info(f"íŒë‹¨ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ: {overall_quality:.2f}")
        return metrics

    def _evaluate_logical_consistency(
        self, content: str, reasoning_process: Dict[str, Any]
    ) -> float:
        """ë…¼ë¦¬ì  ì¼ê´€ì„± í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ë…¼ë¦¬ì  í‚¤ì›Œë“œ ê²€ì‚¬
        logical_keywords = ["ë”°ë¼ì„œ", "ê·¸ëŸ¬ë¯€ë¡œ", "ê²°ë¡ ì ìœ¼ë¡œ", "ì´ìœ ë¡œ", "ë•Œë¬¸ì—"]
        keyword_count = sum(1 for keyword in logical_keywords if keyword in content)
        score += min(keyword_count * 0.1, 0.3)

        # ì¶”ë¡  ê³¼ì •ì˜ êµ¬ì¡°ì„± ê²€ì‚¬
        if "reasoning_process" in reasoning_process:
            reasoning_steps = reasoning_process.get("logical_steps", [])
            if len(reasoning_steps) >= 3:
                score += 0.2

        # ëª¨ìˆœ í‚¤ì›Œë“œ ê²€ì‚¬
        contradiction_keywords = ["í•˜ì§€ë§Œ", "ê·¸ëŸ°ë°", "ë°˜ë©´", "ë‹¤ë¥¸ í•œí¸"]
        contradiction_count = sum(1 for keyword in contradiction_keywords if keyword in content)
        score -= min(contradiction_count * 0.1, 0.2)

        return min(max(score, 0.0), 1.0)

    def _evaluate_evidence_support(self, content: str, reasoning_process: Dict[str, Any]) -> float:
        """ì¦ê±° ì§€ì› í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ì¦ê±° í‚¤ì›Œë“œ ê²€ì‚¬
        evidence_keywords = ["ì¦ê±°", "ì‚¬ì‹¤", "ë°ì´í„°", "ê·¼ê±°", "ì…ì¦", "í™•ì¸", "ê²€ì¦"]
        evidence_count = sum(1 for keyword in evidence_keywords if keyword in content)
        score += min(evidence_count * 0.1, 0.3)

        # êµ¬ì²´ì  ì˜ˆì‹œ ê²€ì‚¬
        example_patterns = ["ì˜ˆë¥¼ ë“¤ì–´", "ì˜ˆì‹œë¡œ", "ì‚¬ë¡€ë¡œ", "êµ¬ì²´ì ìœ¼ë¡œ"]
        example_count = sum(1 for pattern in example_patterns if pattern in content)
        score += min(example_count * 0.1, 0.2)

        # ì¶”ë¡  ê³¼ì •ì˜ ì¦ê±° í™œìš© ê²€ì‚¬
        if "premises" in reasoning_process:
            premises = reasoning_process.get("premises", [])
            evidence_premises = [
                p for p in premises if any(kw in str(p) for kw in evidence_keywords)
            ]
            if evidence_premises:
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _evaluate_reasoning_depth(self, content: str, reasoning_process: Dict[str, Any]) -> float:
        """ì¶”ë¡  ê¹Šì´ í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ê¹Šì´ í‚¤ì›Œë“œ ê²€ì‚¬
        depth_keywords = ["ë¶„ì„", "íƒêµ¬", "ê³ ì°°", "ì‚¬ê³ ", "ê²€í† ", "ì—°êµ¬", "ì¡°ì‚¬"]
        depth_count = sum(1 for keyword in depth_keywords if keyword in content)
        score += min(depth_count * 0.1, 0.3)

        # ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡° ê²€ì‚¬
        complex_sentences = len([s for s in content.split(".") if len(s.split()) > 15])
        score += min(complex_sentences * 0.05, 0.2)

        # ì¶”ë¡  ê³¼ì •ì˜ ë³µì¡ì„± ê²€ì‚¬
        if "logical_steps" in reasoning_process:
            steps = reasoning_process.get("logical_steps", [])
            if len(steps) >= 4:
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _evaluate_originality(self, content: str, reasoning_process: Dict[str, Any]) -> float:
        """ë…ì°½ì„± í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ë…ì°½ì„± í‚¤ì›Œë“œ ê²€ì‚¬
        originality_keywords = ["ìƒˆë¡œìš´", "ë…ì°½", "í˜ì‹ ", "ì°½ì˜", "ë…íŠ¹", "ì°¨ë³„í™”"]
        originality_count = sum(1 for keyword in originality_keywords if keyword in content)
        score += min(originality_count * 0.1, 0.3)

        # ì¼ë°˜ì  í‘œí˜„ ê²€ì‚¬ (ë…ì°½ì„± ê°ì†Œ)
        common_phrases = ["ì¼ë°˜ì ìœ¼ë¡œ", "ë³´í†µ", "ëŒ€ë¶€ë¶„", "ì „í˜•ì ì¸", "í‘œì¤€ì ì¸"]
        common_count = sum(1 for phrase in common_phrases if phrase in content)
        score -= min(common_count * 0.1, 0.2)

        # ì¶”ë¡  ê³¼ì •ì˜ ë…ì°½ì„± ê²€ì‚¬
        if "reasoning_type" in reasoning_process:
            reasoning_type = reasoning_process.get("reasoning_type", "")
            if "hybrid" in reasoning_type or "integrated" in reasoning_type:
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _evaluate_practical_relevance(
        self, content: str, reasoning_process: Dict[str, Any]
    ) -> float:
        """ì‹¤ìš©ì  ê´€ë ¨ì„± í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ì‹¤ìš©ì„± í‚¤ì›Œë“œ ê²€ì‚¬
        practical_keywords = ["ì‹¤ìš©", "ì ìš©", "ì‹¤ì œ", "ìœ ìš©", "íš¨ê³¼", "ê²°ê³¼", "í•´ê²°"]
        practical_count = sum(1 for keyword in practical_keywords if keyword in content)
        score += min(practical_count * 0.1, 0.3)

        # êµ¬ì²´ì  í–‰ë™ ì œì•ˆ ê²€ì‚¬
        action_keywords = ["í•´ì•¼ í•œë‹¤", "í•´ì•¼ í•œë‹¤", "í•„ìš”í•˜ë‹¤", "ê¶Œì¥í•œë‹¤", "ì œì•ˆí•œë‹¤"]
        action_count = sum(1 for keyword in action_keywords if keyword in content)
        score += min(action_count * 0.1, 0.2)

        # ì¶”ë¡  ê³¼ì •ì˜ ì‹¤ìš©ì„± ê²€ì‚¬
        if "conclusion" in reasoning_process:
            conclusion = reasoning_process.get("conclusion", "")
            if any(keyword in conclusion for keyword in practical_keywords):
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _calculate_overall_quality(
        self,
        logical_consistency: float,
        evidence_support: float,
        reasoning_depth: float,
        originality: float,
        practical_relevance: float,
    ) -> float:
        """ì¢…í•© í’ˆì§ˆ ê³„ì‚°"""
        weights = self.quality_indicators

        overall_score = (
            logical_consistency * weights["logical_consistency"]["weight"]
            + evidence_support * weights["evidence_support"]["weight"]
            + reasoning_depth * weights["reasoning_depth"]["weight"]
            + originality * weights["originality"]["weight"]
            + practical_relevance * weights["practical_relevance"]["weight"]
        )

        return min(max(overall_score, 0.0), 1.0)


class InsightAuthenticityChecker:
    """í†µì°° ì§„ìœ„ì„± ê²€ì‚¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.authenticity_indicators = self._initialize_authenticity_indicators()
        self.red_flag_patterns = self._initialize_red_flag_patterns()
        self.green_flag_patterns = self._initialize_green_flag_patterns()

    def _initialize_authenticity_indicators(self) -> Dict[str, Dict]:
        """ì§„ìœ„ì„± ì§€í‘œ ì´ˆê¸°í™”"""
        return {
            "evidence_quality": {
                "weight": 0.25,
                "indicators": [
                    "êµ¬ì²´ì  ì‚¬ì‹¤",
                    "ê²€ì¦ ê°€ëŠ¥í•œ ì •ë³´",
                    "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜",
                ],
            },
            "reasoning_quality": {
                "weight": 0.25,
                "indicators": ["ë…¼ë¦¬ì  ì¼ê´€ì„±", "ëª…í™•í•œ ì¶”ë¡  ê³¼ì •", "ì ì ˆí•œ ì „ì œ"],
            },
            "originality_score": {
                "weight": 0.20,
                "indicators": ["ë…ì°½ì  ê´€ì ", "ìƒˆë¡œìš´ ì—°ê²°", "í˜ì‹ ì  ì‚¬ê³ "],
            },
            "practical_value": {
                "weight": 0.30,
                "indicators": ["ì‹¤ìš©ì  ì ìš©", "í•´ê²°ì±… ì œì‹œ", "ì‹¤í–‰ ê°€ëŠ¥ì„±"],
            },
        }

    def _initialize_red_flag_patterns(self) -> List[Dict[str, Any]]:
        """ê²½ê³  ì‹ í˜¸ íŒ¨í„´ ì´ˆê¸°í™”"""
        return [
            {
                "pattern": "ê³¼ë„í•œ ì¼ë°˜í™”",
                "keywords": ["ëª¨ë“ ", "í•­ìƒ", "ì ˆëŒ€", "ì™„ì „íˆ", "ì „í˜€"],
                "severity": 0.3,
            },
            {
                "pattern": "ê°ì •ì  ê³¼ì¥",
                "keywords": ["ë”ì°í•œ", "ë†€ë¼ìš´", "ë¯¿ì„ ìˆ˜ ì—†ëŠ”", "ì¶©ê²©ì ì¸"],
                "severity": 0.4,
            },
            {
                "pattern": "ë…¼ë¦¬ì  ë¹„ì•½",
                "keywords": ["ë”°ë¼ì„œ", "ê·¸ëŸ¬ë¯€ë¡œ", "ê²°ë¡ ì ìœ¼ë¡œ"],
                "severity": 0.5,
            },
            {
                "pattern": "ì¦ê±° ë¶€ì¡±",
                "keywords": ["ì•„ë§ˆë„", "ì–´ì©Œë©´", "ì¶”ì •", "ê°€ëŠ¥ì„±"],
                "severity": 0.4,
            },
            {
                "pattern": "ëª¨ìˆœëœ ì£¼ì¥",
                "keywords": ["í•˜ì§€ë§Œ", "ê·¸ëŸ°ë°", "ë°˜ë©´", "ë‹¤ë¥¸ í•œí¸"],
                "severity": 0.6,
            },
        ]

    def _initialize_green_flag_patterns(self) -> List[Dict[str, Any]]:
        """ê¸ì • ì‹ í˜¸ íŒ¨í„´ ì´ˆê¸°í™”"""
        return [
            {
                "pattern": "êµ¬ì²´ì  ì¦ê±°",
                "keywords": ["ì—°êµ¬ì— ë”°ë¥´ë©´", "ë°ì´í„°ëŠ”", "ì‚¬ì‹¤ì€", "ì¦ê±°ë¡œ"],
                "strength": 0.4,
            },
            {
                "pattern": "ê· í˜•ì¡íŒ ê´€ì ",
                "keywords": ["í•œí¸ìœ¼ë¡œëŠ”", "ë‹¤ë¥¸ í•œí¸ìœ¼ë¡œëŠ”", "ì–‘ë©´ì ", "ë³µí•©ì "],
                "strength": 0.3,
            },
            {
                "pattern": "ì‹¤ìš©ì  ì œì•ˆ",
                "keywords": ["í•´ê²°ì±…ì€", "ë°©ë²•ì€", "ì „ëµì€", "ì ‘ê·¼ë²•ì€"],
                "strength": 0.5,
            },
            {
                "pattern": "ê¹Šì´ ìˆëŠ” ë¶„ì„",
                "keywords": ["ë¶„ì„í•´ë³´ë©´", "íƒêµ¬í•´ë³´ë©´", "ê³ ì°°í•´ë³´ë©´", "ê²€í† í•´ë³´ë©´"],
                "strength": 0.4,
            },
            {
                "pattern": "ë…ì°½ì  í†µì°°",
                "keywords": ["ìƒˆë¡œìš´ ê´€ì ", "í˜ì‹ ì ", "ë…ì°½ì ", "ì°¨ë³„í™”ëœ"],
                "strength": 0.3,
            },
        ]

    async def check_insight_authenticity(
        self, insight_content: str, reasoning_process: Dict[str, Any]
    ) -> InsightAuthenticityCheck:
        """í†µì°° ì§„ìœ„ì„± ê²€ì‚¬"""
        logger.info("í†µì°° ì§„ìœ„ì„± ê²€ì‚¬ ì‹œì‘")

        # ê° ì§„ìœ„ì„± ì§€í‘œ í‰ê°€
        evidence_quality = self._evaluate_evidence_quality(insight_content, reasoning_process)
        reasoning_quality = self._evaluate_reasoning_quality(insight_content, reasoning_process)
        originality_score = self._evaluate_originality_score(insight_content, reasoning_process)
        practical_value = self._evaluate_practical_value(insight_content, reasoning_process)

        # ê²½ê³  ì‹ í˜¸ ë° ê¸ì • ì‹ í˜¸ ê²€ì‚¬
        red_flags = self._detect_red_flags(insight_content)
        green_flags = self._detect_green_flags(insight_content)

        # í†µì°° ìœ í˜• ë° ì§„ìœ„ì„± ìˆ˜ì¤€ ê²°ì •
        insight_type = self._determine_insight_type(
            evidence_quality, reasoning_quality, originality_score, practical_value
        )
        authenticity_level = self._determine_authenticity_level(
            evidence_quality,
            reasoning_quality,
            originality_score,
            practical_value,
            red_flags,
            green_flags,
        )

        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence_score = self._calculate_confidence_score(
            evidence_quality,
            reasoning_quality,
            originality_score,
            practical_value,
            red_flags,
            green_flags,
        )

        check = InsightAuthenticityCheck(
            insight_id=f"insight_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            insight_type=insight_type,
            authenticity_level=authenticity_level,
            confidence_score=confidence_score,
            evidence_quality=evidence_quality,
            reasoning_quality=reasoning_quality,
            originality_score=originality_score,
            practical_value=practical_value,
            red_flags=red_flags,
            green_flags=green_flags,
        )

        logger.info(f"í†µì°° ì§„ìœ„ì„± ê²€ì‚¬ ì™„ë£Œ: {authenticity_level.value}")
        return check

    def _evaluate_evidence_quality(self, content: str, reasoning_process: Dict[str, Any]) -> float:
        """ì¦ê±° í’ˆì§ˆ í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # êµ¬ì²´ì  ì¦ê±° í‚¤ì›Œë“œ ê²€ì‚¬
        evidence_keywords = ["ì—°êµ¬", "ë°ì´í„°", "ì‚¬ì‹¤", "ì¦ê±°", "í™•ì¸", "ê²€ì¦", "ì…ì¦"]
        evidence_count = sum(1 for keyword in evidence_keywords if keyword in content)
        score += min(evidence_count * 0.1, 0.3)

        # ì¶”ë¡  ê³¼ì •ì˜ ì¦ê±° í™œìš© ê²€ì‚¬
        if "premises" in reasoning_process:
            premises = reasoning_process.get("premises", [])
            evidence_premises = [
                p for p in premises if any(kw in str(p) for kw in evidence_keywords)
            ]
            if evidence_premises:
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _evaluate_reasoning_quality(self, content: str, reasoning_process: Dict[str, Any]) -> float:
        """ì¶”ë¡  í’ˆì§ˆ í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ë…¼ë¦¬ì  í‚¤ì›Œë“œ ê²€ì‚¬
        logical_keywords = [
            "ë…¼ë¦¬",
            "ì¼ê´€ì„±",
            "ì¶”ë¡ ",
            "ì „ì œ",
            "ê²°ë¡ ",
            "ë”°ë¼ì„œ",
            "ê·¸ëŸ¬ë¯€ë¡œ",
        ]
        logical_count = sum(1 for keyword in logical_keywords if keyword in content)
        score += min(logical_count * 0.1, 0.3)

        # ì¶”ë¡  ê³¼ì •ì˜ êµ¬ì¡°ì„± ê²€ì‚¬
        if "logical_steps" in reasoning_process:
            steps = reasoning_process.get("logical_steps", [])
            if len(steps) >= 3:
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _evaluate_originality_score(self, content: str, reasoning_process: Dict[str, Any]) -> float:
        """ë…ì°½ì„± ì ìˆ˜ í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ë…ì°½ì„± í‚¤ì›Œë“œ ê²€ì‚¬
        originality_keywords = ["ìƒˆë¡œìš´", "ë…ì°½", "í˜ì‹ ", "ì°½ì˜", "ë…íŠ¹", "ì°¨ë³„í™”"]
        originality_count = sum(1 for keyword in originality_keywords if keyword in content)
        score += min(originality_count * 0.1, 0.3)

        # ì¶”ë¡  ê³¼ì •ì˜ ë…ì°½ì„± ê²€ì‚¬
        if "reasoning_type" in reasoning_process:
            reasoning_type = reasoning_process.get("reasoning_type", "")
            if "hybrid" in reasoning_type or "integrated" in reasoning_type:
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _evaluate_practical_value(self, content: str, reasoning_process: Dict[str, Any]) -> float:
        """ì‹¤ìš©ì  ê°€ì¹˜ í‰ê°€"""
        score = 0.5  # ê¸°ë³¸ê°’

        # ì‹¤ìš©ì„± í‚¤ì›Œë“œ ê²€ì‚¬
        practical_keywords = ["ì‹¤ìš©", "ì ìš©", "ì‹¤ì œ", "ìœ ìš©", "íš¨ê³¼", "í•´ê²°", "ë°©ë²•"]
        practical_count = sum(1 for keyword in practical_keywords if keyword in content)
        score += min(practical_count * 0.1, 0.3)

        # ì¶”ë¡  ê³¼ì •ì˜ ì‹¤ìš©ì„± ê²€ì‚¬
        if "conclusion" in reasoning_process:
            conclusion = reasoning_process.get("conclusion", "")
            if any(keyword in conclusion for keyword in practical_keywords):
                score += 0.2

        return min(max(score, 0.0), 1.0)

    def _detect_red_flags(self, content: str) -> List[str]:
        """ê²½ê³  ì‹ í˜¸ ê²€ì¶œ"""
        red_flags = []

        for pattern in self.red_flag_patterns:
            pattern_name = pattern["pattern"]
            keywords = pattern["keywords"]
            severity = pattern["severity"]

            keyword_count = sum(1 for keyword in keywords if keyword in content)
            if keyword_count > 0:
                red_flags.append(
                    f"{pattern_name}: {keyword_count}ê°œ í‚¤ì›Œë“œ ë°œê²¬ (ì‹¬ê°ë„: {severity})"
                )

        return red_flags

    def _detect_green_flags(self, content: str) -> List[str]:
        """ê¸ì • ì‹ í˜¸ ê²€ì¶œ"""
        green_flags = []

        for pattern in self.green_flag_patterns:
            pattern_name = pattern["pattern"]
            keywords = pattern["keywords"]
            strength = pattern["strength"]

            keyword_count = sum(1 for keyword in keywords if keyword in content)
            if keyword_count > 0:
                green_flags.append(
                    f"{pattern_name}: {keyword_count}ê°œ í‚¤ì›Œë“œ ë°œê²¬ (ê°•ë„: {strength})"
                )

        return green_flags

    def _determine_insight_type(
        self,
        evidence_quality: float,
        reasoning_quality: float,
        originality_score: float,
        practical_value: float,
    ) -> InsightType:
        """í†µì°° ìœ í˜• ê²°ì •"""
        avg_score = (evidence_quality + reasoning_quality + originality_score + practical_value) / 4

        if avg_score >= 0.8:
            return InsightType.GENUINE
        elif avg_score >= 0.6:
            return InsightType.DEEP
        elif avg_score >= 0.4:
            return InsightType.SUPERFICIAL
        else:
            return InsightType.SHALLOW

    def _determine_authenticity_level(
        self,
        evidence_quality: float,
        reasoning_quality: float,
        originality_score: float,
        practical_value: float,
        red_flags: List[str],
        green_flags: List[str],
    ) -> AuthenticityLevel:
        """ì§„ìœ„ì„± ìˆ˜ì¤€ ê²°ì •"""
        # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°
        base_score = (
            evidence_quality + reasoning_quality + originality_score + practical_value
        ) / 4

        # ê²½ê³  ì‹ í˜¸ì— ë”°ë¥¸ ê°ì 
        red_flag_penalty = len(red_flags) * 0.1
        green_flag_bonus = len(green_flags) * 0.05

        final_score = base_score - red_flag_penalty + green_flag_bonus

        if final_score >= 0.8:
            return AuthenticityLevel.HIGH
        elif final_score >= 0.6:
            return AuthenticityLevel.MEDIUM
        elif final_score >= 0.4:
            return AuthenticityLevel.LOW
        else:
            return AuthenticityLevel.UNKNOWN

    def _calculate_confidence_score(
        self,
        evidence_quality: float,
        reasoning_quality: float,
        originality_score: float,
        practical_value: float,
        red_flags: List[str],
        green_flags: List[str],
    ) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        # ê¸°ë³¸ ì‹ ë¢°ë„
        base_confidence = (
            evidence_quality + reasoning_quality + originality_score + practical_value
        ) / 4

        # ê²½ê³  ì‹ í˜¸ì— ë”°ë¥¸ ê°ì 
        red_flag_penalty = len(red_flags) * 0.05
        green_flag_bonus = len(green_flags) * 0.03

        confidence = base_confidence - red_flag_penalty + green_flag_bonus
        return min(max(confidence, 0.0), 1.0)


class InsightEvaluationSystem:
    """í†µì°° í‰ê°€ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.quality_metrics = JudgmentQualityMetricsEvaluator()
        self.authenticity_checker = InsightAuthenticityChecker()

    async def evaluate_insight(
        self, insight_content: str, reasoning_process: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í†µì°° ì¢…í•© í‰ê°€"""
        logger.info("í†µì°° ì¢…í•© í‰ê°€ ì‹œì‘")

        # í’ˆì§ˆ ë©”íŠ¸ë¦­ í‰ê°€
        quality_metrics = await self.quality_metrics.evaluate_judgment_quality(
            insight_content, reasoning_process
        )

        # ì§„ìœ„ì„± ê²€ì‚¬
        authenticity_check = await self.authenticity_checker.check_insight_authenticity(
            insight_content, reasoning_process
        )

        # ì¢…í•© í‰ê°€ ê²°ê³¼
        evaluation_result = {
            "quality_metrics": quality_metrics,
            "authenticity_check": authenticity_check,
            "overall_assessment": self._generate_overall_assessment(
                quality_metrics, authenticity_check
            ),
        }

        logger.info("í†µì°° ì¢…í•© í‰ê°€ ì™„ë£Œ")
        return evaluation_result

    def _generate_overall_assessment(
        self,
        quality_metrics: JudgmentQualityMetrics,
        authenticity_check: InsightAuthenticityCheck,
    ) -> Dict[str, Any]:
        """ì¢…í•© í‰ê°€ ìƒì„±"""
        # í’ˆì§ˆê³¼ ì§„ìœ„ì„±ì˜ ê°€ì¤‘ í‰ê· 
        quality_score = quality_metrics.overall_quality
        authenticity_score = authenticity_check.confidence_score

        overall_score = (quality_score * 0.6) + (authenticity_score * 0.4)

        # í‰ê°€ ë“±ê¸‰ ê²°ì •
        if overall_score >= 0.8:
            grade = "A"
            assessment = "ìš°ìˆ˜í•œ í†µì°°"
        elif overall_score >= 0.6:
            grade = "B"
            assessment = "ì–‘í˜¸í•œ í†µì°°"
        elif overall_score >= 0.4:
            grade = "C"
            assessment = "ë³´í†µì˜ í†µì°°"
        else:
            grade = "D"
            assessment = "ê°œì„ ì´ í•„ìš”í•œ í†µì°°"

        return {
            "overall_score": overall_score,
            "grade": grade,
            "assessment": assessment,
            "recommendations": self._generate_recommendations(quality_metrics, authenticity_check),
        }

    def _generate_recommendations(
        self,
        quality_metrics: JudgmentQualityMetrics,
        authenticity_check: InsightAuthenticityCheck,
    ) -> List[str]:
        """ê°œì„  ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # í’ˆì§ˆ ê¸°ë°˜ ê¶Œê³ ì‚¬í•­
        if quality_metrics.logical_consistency < 0.6:
            recommendations.append("ë…¼ë¦¬ì  ì¼ê´€ì„±ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”")

        if quality_metrics.evidence_support < 0.6:
            recommendations.append("ë” ë§ì€ ì¦ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”")

        if quality_metrics.reasoning_depth < 0.6:
            recommendations.append("ë” ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”")

        if quality_metrics.originality < 0.6:
            recommendations.append("ë” ë…ì°½ì ì¸ ê´€ì ì„ ì œì‹œí•˜ì„¸ìš”")

        if quality_metrics.practical_relevance < 0.6:
            recommendations.append("ì‹¤ìš©ì  ê°€ì¹˜ë¥¼ ë” ëª…í™•íˆ í•˜ì„¸ìš”")

        # ì§„ìœ„ì„± ê¸°ë°˜ ê¶Œê³ ì‚¬í•­
        if authenticity_check.red_flags:
            recommendations.append("ê²½ê³  ì‹ í˜¸ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë” ì‹ ì¤‘í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”")

        if len(authenticity_check.green_flags) < 2:
            recommendations.append("ë” ë§ì€ ê¸ì •ì  ì‹ í˜¸ë¥¼ í¬í•¨í•˜ì„¸ìš”")

        return recommendations


async def test_insight_evaluation_system():
    """í†µì°° í‰ê°€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=== í†µì°° í‰ê°€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Day 7) ===")

    evaluation_system = InsightEvaluationSystem()

    # í…ŒìŠ¤íŠ¸ í†µì°° ë‚´ìš©
    test_insight_content = """
    ê±°ì§“ë§ì— ëŒ€í•œ ìœ¤ë¦¬ì  íŒë‹¨ì—ì„œ ì¤‘ìš”í•œ ê²ƒì€ ìƒí™©ì˜ ë§¥ë½ì„ ê³ ë ¤í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ì—°êµ¬ì— ë”°ë¥´ë©´, ì™„ì „í•œ ì§„ì‹¤ë§Œì´ í•­ìƒ ìµœì„ ì˜ ì„ íƒì€ ì•„ë‹™ë‹ˆë‹¤.
    ì˜ˆë¥¼ ë“¤ì–´, ìƒëª…ì„ êµ¬í•˜ê¸° ìœ„í•œ ê±°ì§“ë§ì€ ë„ë•ì ìœ¼ë¡œ ì •ë‹¹í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    í•˜ì§€ë§Œ ì´ëŠ” ë§¤ìš° ì œí•œì ì¸ ìƒí™©ì—ì„œë§Œ ì ìš©ë˜ì–´ì•¼ í•˜ë©°,
    ì¼ë°˜ì ìœ¼ë¡œëŠ” ì§„ì‹¤ì„±ì˜ ê°€ì¹˜ë¥¼ ìš°ì„ ì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
    """

    test_reasoning_process = {
        "logical_steps": [
            {"step": 1, "content": "ìƒí™© ë§¥ë½ ë¶„ì„"},
            {"step": 2, "content": "ìœ¤ë¦¬ì  ì›ì¹™ ì ìš©"},
            {"step": 3, "content": "ê²°ê³¼ ì˜ˆì¸¡"},
            {"step": 4, "content": "ì¢…í•©ì  íŒë‹¨"},
        ],
        "premises": [
            "ì™„ì „í•œ ì§„ì‹¤ì´ í•­ìƒ ìµœì„ ì€ ì•„ë‹˜",
            "ìƒëª… êµ¬ì›ì´ ìš°ì„ ìˆœìœ„",
            "ìƒí™©ì  ë§¥ë½ì˜ ì¤‘ìš”ì„±",
        ],
        "conclusion": "ìƒí™©ì— ë”°ë¥¸ ì¡°ê±´ë¶€ í—ˆìš©",
    }

    # í†µì°° í‰ê°€
    evaluation_result = await evaluation_system.evaluate_insight(
        test_insight_content, test_reasoning_process
    )

    # ê²°ê³¼ ì¶œë ¥
    quality_metrics = evaluation_result["quality_metrics"]
    authenticity_check = evaluation_result["authenticity_check"]
    overall_assessment = evaluation_result["overall_assessment"]

    print(f"\nğŸ“Š í’ˆì§ˆ ë©”íŠ¸ë¦­:")
    print(f"  â€¢ ë…¼ë¦¬ì  ì¼ê´€ì„±: {quality_metrics.logical_consistency:.2f}")
    print(f"  â€¢ ì¦ê±° ì§€ì›: {quality_metrics.evidence_support:.2f}")
    print(f"  â€¢ ì¶”ë¡  ê¹Šì´: {quality_metrics.reasoning_depth:.2f}")
    print(f"  â€¢ ë…ì°½ì„±: {quality_metrics.originality:.2f}")
    print(f"  â€¢ ì‹¤ìš©ì  ê´€ë ¨ì„±: {quality_metrics.practical_relevance:.2f}")
    print(f"  â€¢ ì¢…í•© í’ˆì§ˆ: {quality_metrics.overall_quality:.2f}")

    print(f"\nğŸ” ì§„ìœ„ì„± ê²€ì‚¬:")
    print(f"  â€¢ í†µì°° ìœ í˜•: {authenticity_check.insight_type.value}")
    print(f"  â€¢ ì§„ìœ„ì„± ìˆ˜ì¤€: {authenticity_check.authenticity_level.value}")
    print(f"  â€¢ ì‹ ë¢°ë„: {authenticity_check.confidence_score:.2f}")
    print(f"  â€¢ ì¦ê±° í’ˆì§ˆ: {authenticity_check.evidence_quality:.2f}")
    print(f"  â€¢ ì¶”ë¡  í’ˆì§ˆ: {authenticity_check.reasoning_quality:.2f}")
    print(f"  â€¢ ë…ì°½ì„± ì ìˆ˜: {authenticity_check.originality_score:.2f}")
    print(f"  â€¢ ì‹¤ìš©ì  ê°€ì¹˜: {authenticity_check.practical_value:.2f}")

    print(f"\nğŸš© ê²½ê³  ì‹ í˜¸:")
    for flag in authenticity_check.red_flags:
        print(f"  â€¢ {flag}")

    print(f"\nâœ… ê¸ì • ì‹ í˜¸:")
    for flag in authenticity_check.green_flags:
        print(f"  â€¢ {flag}")

    print(f"\nğŸ¯ ì¢…í•© í‰ê°€:")
    print(f"  â€¢ ì¢…í•© ì ìˆ˜: {overall_assessment['overall_score']:.2f}")
    print(f"  â€¢ ë“±ê¸‰: {overall_assessment['grade']}")
    print(f"  â€¢ í‰ê°€: {overall_assessment['assessment']}")

    print(f"\nğŸ’¡ ê°œì„  ê¶Œê³ ì‚¬í•­:")
    for recommendation in overall_assessment["recommendations"]:
        print(f"  â€¢ {recommendation}")

    print(f"\n{'='*70}")
    print("=== í†µì°° í‰ê°€ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Day 7) ===")
    print("âœ… Day 7 ëª©í‘œ ë‹¬ì„±: ê°€ì§œ í†µì°° â†’ ì§„ì§œ í†µì°° êµ¬ë¶„")
    print("âœ… íŒë‹¨ í’ˆì§ˆ ë©”íŠ¸ë¦­ ë° í†µì°° ì§„ìœ„ì„± ê²€ì‚¬ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ì¢…í•© í‰ê°€ ì‹œìŠ¤í…œ ë° ê°œì„  ê¶Œê³ ì‚¬í•­ ìƒì„± ì‹œìŠ¤í…œ êµ¬í˜„")


if __name__ == "__main__":
    asyncio.run(test_insight_evaluation_system())
