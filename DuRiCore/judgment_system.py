#!/usr/bin/env python3
"""
DuRiCore Phase 5 Day 3 - íŒë‹¨ ì‹œìŠ¤í…œ
ìƒí™© ë¶„ì„, ì˜ì‚¬ê²°ì •, íŒë‹¨ í’ˆì§ˆ í‰ê°€ í†µí•© ì‹œìŠ¤í…œ
"""

import asyncio
import logging
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List

logger = logging.getLogger(__name__)


class JudgmentType(Enum):
    """íŒë‹¨ íƒ€ì… ì—´ê±°í˜•"""

    RULE_BASED = "rule_based"  # ê·œì¹™ ê¸°ë°˜
    ML_BASED = "ml_based"  # ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜
    ETHICAL = "ethical"  # ìœ¤ë¦¬ì  íŒë‹¨
    HYBRID = "hybrid"  # í•˜ì´ë¸Œë¦¬ë“œ


class DecisionConfidence(Enum):
    """ì˜ì‚¬ê²°ì • ì‹ ë¢°ë„ ì—´ê±°í˜•"""

    LOW = "low"  # ë‚®ìŒ (0.0-0.3)
    MEDIUM = "medium"  # ì¤‘ê°„ (0.3-0.7)
    HIGH = "high"  # ë†’ìŒ (0.7-1.0)


@dataclass
class SituationAnalysis:
    """ìƒí™© ë¶„ì„ ê²°ê³¼"""

    situation_type: str
    context_elements: List[str]
    key_factors: List[str]
    risk_level: float
    urgency_level: float
    complexity_score: float
    confidence: float
    analysis_method: str


@dataclass
class DecisionResult:
    """ì˜ì‚¬ê²°ì • ê²°ê³¼"""

    decision: str
    reasoning: str
    confidence: float
    alternatives: List[str]
    risk_assessment: Dict[str, float]
    ethical_score: float
    judgment_type: JudgmentType
    created_at: datetime


@dataclass
class JudgmentQuality:
    """íŒë‹¨ í’ˆì§ˆ í‰ê°€"""

    accuracy_score: float
    consistency_score: float
    ethical_score: float
    efficiency_score: float
    overall_score: float
    feedback: List[str]
    improvement_suggestions: List[str]


class JudgmentSystem:
    """íŒë‹¨ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.situation_patterns = {}
        self.decision_rules = {}
        self.ethical_guidelines = {}
        self.quality_metrics = {}

        # íŒë‹¨ ì„ê³„ê°’
        self.confidence_threshold = 0.7
        self.ethical_threshold = 0.8
        self.quality_threshold = 0.75

        # ì„±ëŠ¥ ì„¤ì •
        self.max_analysis_time = 5.0  # ì´ˆ
        self.max_decision_time = 2.0  # ì´ˆ

        logger.info("íŒë‹¨ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def process_input(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„° ì²˜ë¦¬ (í†µí•© ë£¨í”„ìš©)"""
        try:
            # ë©”ëª¨ë¦¬ ë°ì´í„°ì—ì„œ ìƒí™© ì •ë³´ ì¶”ì¶œ
            memory_data = input_data.get("data", {})
            content = memory_data.get("content", "")
            context = memory_data.get("context", {})

            # ìƒí™© ë¶„ì„
            situation_analysis = await self.analyze_situation({"content": content}, context)

            # ì˜ì‚¬ê²°ì •
            available_actions = ["proceed", "wait", "reconsider", "escalate"]
            constraints = {"time_limit": 10.0, "resource_limit": 0.8}
            decision_result = await self.make_decision(situation_analysis, available_actions, constraints)

            return {
                "status": "success",
                "situation_analysis": situation_analysis,
                "decision_result": decision_result,
                "timestamp": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"ì…ë ¥ ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    async def judge(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤ì œ íŒë‹¨ ë¡œì§ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í˜¸ì¶œìš©) - ì‹¤ì œ ê¸°ëŠ¥ êµ¬í˜„"""
        try:
            logger.info("ğŸ§  ì‹¤ì œ íŒë‹¨ ë¡œì§ ì‹¤í–‰")

            # 1. ì‹¤ì œ ìƒí™© ë¶„ì„
            situation_analysis = self._real_analyze_situation(context, {})

            # 2. ì‹¤ì œ ì˜ì‚¬ê²°ì •
            decision_result = self._real_make_decision(situation_analysis, context)

            # 3. íŒë‹¨ ì „ëµ ì ìš© (ìƒˆë¡œìš´ ê¸°ëŠ¥)
            try:
                import os
                import sys

                sys.path.append(os.path.dirname(os.path.abspath(__file__)))
                from memory.judgment_strategy_applier import JudgmentStrategyApplier

                strategy_applier = JudgmentStrategyApplier()
                decision_result = strategy_applier.apply_strategy(context, decision_result)
                logger.info("âœ… íŒë‹¨ ì „ëµ ì ìš© ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"íŒë‹¨ ì „ëµ ì ìš© ì‹¤íŒ¨: {e}")
                # ì „ëµ ì ìš© ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ í•„ë“œ ì¶”ê°€
                decision_result["applied_strategy"] = None
                decision_result["strategy_source"] = None

            # 4. íŒë‹¨ ì¶”ì  ê¸°ë¡ (ìƒˆë¡œìš´ ê¸°ëŠ¥)
            try:
                import os
                import sys

                sys.path.append(os.path.dirname(os.path.abspath(__file__)))
                from memory.judgment_trace_store import get_reasoning_trace, record_judgment_trace

                reason = get_reasoning_trace(context)
                record_judgment_trace(context, decision_result, reason)
                logger.info("âœ… íŒë‹¨ ì¶”ì  ê¸°ë¡ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"íŒë‹¨ ì¶”ì  ê¸°ë¡ ì‹¤íŒ¨: {e}")

            # 5. ì „ëµ í•™ìŠµ ì—”ì§„ ì ìš© (ìƒˆë¡œìš´ ê¸°ëŠ¥)
            try:
                import os
                import sys

                sys.path.append(os.path.dirname(os.path.abspath(__file__)))
                from learning.strategic_learning_engine import StrategicLearningEngine

                strategic_engine = StrategicLearningEngine()

                # íŒë‹¨ ìƒí™©, í–‰ë™, ì´ìœ  ì¶”ì¶œ
                situation = str(context.get("content", "ì•Œ ìˆ˜ ì—†ëŠ” ìƒí™©"))
                action = decision_result.get("decision", "unknown")
                reasoning = decision_result.get("reasoning", "ì´ìœ  ì—†ìŒ")

                # íŒë‹¨ ê´€ì°° ê¸°ë¡
                strategic_engine.observe_decision(situation, action, reasoning)

                # ì „ëµì  í†µì°° ìƒì„±
                insight = strategic_engine.generate_strategic_insight()

                logger.info("âœ… ì „ëµ í•™ìŠµ ì—”ì§„ ì ìš© ì™„ë£Œ")

                # í•™ìŠµ ê²°ê³¼ë¥¼ íŒë‹¨ ê²°ê³¼ì— ì¶”ê°€
                decision_result["strategic_learning"] = {
                    "total_observations": len(strategic_engine.history),
                    "insight": insight,
                    "learning_summary": strategic_engine.history,
                }

            except Exception as e:
                logger.warning(f"ì „ëµ í•™ìŠµ ì—”ì§„ ì ìš© ì‹¤íŒ¨: {e}")
                decision_result["strategic_learning"] = {
                    "error": str(e),
                    "total_observations": 0,
                    "insight": "í•™ìŠµ ì‹¤íŒ¨",
                    "learning_summary": [],
                }

            return {
                "phase": "judgment",
                "status": "success",
                "decision": decision_result["decision"],
                "reasoning": decision_result["reasoning"],
                "confidence": decision_result["confidence"],
                "alternatives": decision_result["alternatives"],
                "risk_assessment": decision_result["risk_assessment"],
                "ethical_score": decision_result["ethical_score"],
                "situation_analysis": situation_analysis,
                "applied_strategy": decision_result.get("applied_strategy"),
                "strategy_source": decision_result.get("strategy_source"),
                "strategic_learning": decision_result.get("strategic_learning", {}),
                "timestamp": datetime.now().isoformat(),
            }

        except Exception as e:
            logger.error(f"âŒ íŒë‹¨ ë¡œì§ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "phase": "judgment",
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    async def main(self) -> Dict[str, Any]:
        """ë©”ì¸ í•¨ìˆ˜ (ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í˜¸ì¶œìš©)"""
        try:
            logger.info("ğŸš€ íŒë‹¨ ì‹œìŠ¤í…œ ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰")

            # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ë¡œ íŒë‹¨ ì‹¤í–‰
            context = {
                "content": "ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ ë° ìµœì í™” í•„ìš”",
                "priority": "medium",
                "resource_available": 0.8,
            }

            return await self.judge(context)

        except Exception as e:
            logger.error(f"âŒ íŒë‹¨ ì‹œìŠ¤í…œ ë©”ì¸ í•¨ìˆ˜ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

            return {
                "success": True,
                "situation_analysis": situation_analysis,  # noqa: F821
                "decision_result": decision_result,  # noqa: F821
                "data": {
                    "content": content,  # noqa: F821
                    "context": context,
                    "decision": decision_result.decision,  # noqa: F821
                    "confidence": decision_result.confidence,  # noqa: F821
                },
            }

        except Exception as e:
            logger.error(f"íŒë‹¨ ì‹œìŠ¤í…œ ì…ë ¥ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e), "data": {}}

    async def analyze_situation(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> SituationAnalysis:
        """ìƒí™© ë¶„ì„"""
        try:
            start_time = datetime.now()

            # 1. ì…ë ¥ ë°ì´í„° ë¶„ì„
            data_analysis = await self._analyze_input_data(input_data)

            # 2. ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
            context_elements = await self._extract_context_elements(context)

            # 3. ìƒí™© íŒ¨í„´ ì¸ì‹
            situation_pattern = await self._recognize_situation_pattern(input_data, context)

            # 4. í•µì‹¬ ìš”ì†Œ ì‹ë³„
            key_factors = await self._identify_key_factors(input_data, context)

            # 5. ìœ„í—˜ë„ ë° ê¸´ê¸‰ë„ í‰ê°€
            risk_level = await self._assess_risk_level(input_data, context)
            urgency_level = await self._assess_urgency_level(input_data, context)

            # 6. ë³µì¡ë„ ê³„ì‚°
            complexity_score = await self._calculate_complexity(input_data, context)

            # 7. ì‹ ë¢°ë„ ê³„ì‚°
            confidence = await self._calculate_analysis_confidence(data_analysis, context_elements, situation_pattern)

            analysis_time = (datetime.now() - start_time).total_seconds()

            return SituationAnalysis(
                situation_type=situation_pattern.get("type", "unknown"),
                context_elements=context_elements,
                key_factors=key_factors,
                risk_level=risk_level,
                urgency_level=urgency_level,
                complexity_score=complexity_score,
                confidence=confidence,
                analysis_method=f"comprehensive_analysis_{analysis_time:.2f}s",
            )

        except Exception as e:
            logger.error(f"ìƒí™© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return SituationAnalysis(
                situation_type="error",
                context_elements=[],
                key_factors=[],
                risk_level=0.5,
                urgency_level=0.5,
                complexity_score=0.5,
                confidence=0.3,
                analysis_method="error_fallback",
            )

    async def make_decision(
        self,
        situation_analysis: SituationAnalysis,
        available_actions: List[str],
        constraints: Dict[str, Any],
    ) -> DecisionResult:
        """ì˜ì‚¬ê²°ì • ìˆ˜í–‰"""
        try:
            start_time = datetime.now()

            # 1. ê·œì¹™ ê¸°ë°˜ ì˜ì‚¬ê²°ì •
            rule_decision = await self._rule_based_decision(situation_analysis, available_actions, constraints)

            # 2. ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì˜ì‚¬ê²°ì •
            ml_decision = await self._ml_based_decision(situation_analysis, available_actions, constraints)

            # 3. ìœ¤ë¦¬ì  íŒë‹¨
            ethical_review = await self._ethical_review(rule_decision, ml_decision, situation_analysis)

            # 4. ìµœì¢… ì˜ì‚¬ê²°ì • (í•˜ì´ë¸Œë¦¬ë“œ)
            final_decision = await self._hybrid_decision(rule_decision, ml_decision, ethical_review)

            # 5. ëŒ€ì•ˆ ìƒì„±
            alternatives = await self._generate_alternatives(situation_analysis, available_actions)

            # 6. ìœ„í—˜ í‰ê°€
            risk_assessment = await self._assess_decision_risk(final_decision, situation_analysis)

            decision_time = (datetime.now() - start_time).total_seconds()  # noqa: F841

            return DecisionResult(
                decision=final_decision["action"],
                reasoning=final_decision["reasoning"],
                confidence=final_decision["confidence"],
                alternatives=alternatives,
                risk_assessment=risk_assessment,
                ethical_score=ethical_review["score"],
                judgment_type=JudgmentType.HYBRID,
                created_at=datetime.now(),
            )

        except Exception as e:
            logger.error(f"ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}")
            return DecisionResult(
                decision="error_fallback",
                reasoning=f"ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}",
                confidence=0.3,
                alternatives=[],
                risk_assessment={"error": 1.0},
                ethical_score=0.5,
                judgment_type=JudgmentType.RULE_BASED,
                created_at=datetime.now(),
            )

    async def evaluate_judgment_quality(
        self,
        situation_analysis: SituationAnalysis,
        decision_result: DecisionResult,
        outcome: Dict[str, Any],
    ) -> JudgmentQuality:
        """íŒë‹¨ í’ˆì§ˆ í‰ê°€"""
        try:
            # 1. ì •í™•ë„ í‰ê°€
            accuracy_score = await self._evaluate_accuracy(decision_result, outcome)

            # 2. ì¼ê´€ì„± í‰ê°€
            consistency_score = await self._evaluate_consistency(decision_result, situation_analysis)

            # 3. ìœ¤ë¦¬ì„± í‰ê°€
            ethical_score = await self._evaluate_ethical_quality(decision_result, outcome)

            # 4. íš¨ìœ¨ì„± í‰ê°€
            efficiency_score = await self._evaluate_efficiency(decision_result, outcome)

            # 5. ì¢…í•© ì ìˆ˜ ê³„ì‚°
            overall_score = (accuracy_score + consistency_score + ethical_score + efficiency_score) / 4

            # 6. í”¼ë“œë°± ìƒì„±
            feedback = await self._generate_feedback(accuracy_score, consistency_score, ethical_score, efficiency_score)

            # 7. ê°œì„  ì œì•ˆ
            improvement_suggestions = await self._generate_improvement_suggestions(
                accuracy_score, consistency_score, ethical_score, efficiency_score
            )

            return JudgmentQuality(
                accuracy_score=accuracy_score,
                consistency_score=consistency_score,
                ethical_score=ethical_score,
                efficiency_score=efficiency_score,
                overall_score=overall_score,
                feedback=feedback,
                improvement_suggestions=improvement_suggestions,
            )

        except Exception as e:
            logger.error(f"íŒë‹¨ í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
            return JudgmentQuality(
                accuracy_score=0.5,
                consistency_score=0.5,
                ethical_score=0.5,
                efficiency_score=0.5,
                overall_score=0.5,
                feedback=[f"í‰ê°€ ì˜¤ë¥˜: {e}"],
                improvement_suggestions=["ì‹œìŠ¤í…œ ì˜¤ë¥˜ ìˆ˜ì • í•„ìš”"],
            )

    # ë‚´ë¶€ ë©”ì„œë“œë“¤ (ê¸°ë³¸ êµ¬í˜„)
    async def _analyze_input_data(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì…ë ¥ ë°ì´í„° ë¶„ì„"""
        try:
            analysis = {
                "data_type": type(input_data).__name__,
                "data_size": len(str(input_data)),
                "key_fields": (list(input_data.keys()) if isinstance(input_data, dict) else []),
                "complexity": self._calculate_data_complexity(input_data),
                "quality_score": self._assess_data_quality(input_data),
            }
            return analysis
        except Exception as e:
            logger.error(f"ì…ë ¥ ë°ì´í„° ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    async def _extract_context_elements(self, context: Dict[str, Any]) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ ì¶”ì¶œ"""
        try:
            elements = []
            for key, value in context.items():
                if isinstance(value, str):
                    elements.append(f"{key}:{value}")
                elif isinstance(value, (int, float)):
                    elements.append(f"{key}:{value}")
                elif isinstance(value, dict):
                    elements.extend([f"{key}.{k}:{v}" for k, v in value.items()])
                elif isinstance(value, list):
                    elements.append(f"{key}:{len(value)}_items")
            return elements
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ìš”ì†Œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return []

    async def _recognize_situation_pattern(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """ìƒí™© íŒ¨í„´ ì¸ì‹"""
        try:
            patterns = {
                "learning": ["í•™ìŠµ", "ê³µë¶€", "ë°°ìš°", "ì´í•´"],
                "decision": ["ê²°ì •", "ì„ íƒ", "íŒë‹¨", "ê²°ë¡ "],
                "problem": ["ë¬¸ì œ", "ì˜¤ë¥˜", "ì‹¤íŒ¨", "ìœ„í—˜"],
                "opportunity": ["ê¸°íšŒ", "ê°€ëŠ¥ì„±", "ì ì¬ë ¥", "ì„±ì¥"],
                "conflict": ["ê°ˆë“±", "ì¶©ëŒ", "ëŒ€ë¦½", "ë¬¸ì œ"],
            }

            content = str(input_data) + str(context)
            matched_patterns = []

            for pattern_name, keywords in patterns.items():
                if any(keyword in content for keyword in keywords):
                    matched_patterns.append(pattern_name)

            return {
                "type": matched_patterns[0] if matched_patterns else "general",
                "patterns": matched_patterns,
                "confidence": len(matched_patterns) / len(patterns),
            }
        except Exception as e:
            logger.error(f"ìƒí™© íŒ¨í„´ ì¸ì‹ ì˜¤ë¥˜: {e}")
            return {"type": "unknown", "patterns": [], "confidence": 0.0}

    async def _identify_key_factors(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> List[str]:
        """í•µì‹¬ ìš”ì†Œ ì‹ë³„"""
        try:
            factors = []
            if "importance" in context:
                factors.append("importance")
            if "urgency" in context:
                factors.append("urgency")
            if "risk" in context:
                factors.append("risk")
            if "content" in input_data:
                factors.append("content_analysis")
            if "emotion" in context:
                factors.append("emotional_context")
            if "memory" in context:
                factors.append("memory_context")
            return factors
        except Exception as e:
            logger.error(f"í•µì‹¬ ìš”ì†Œ ì‹ë³„ ì˜¤ë¥˜: {e}")
            return []

    async def _assess_risk_level(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> float:
        """ìœ„í—˜ë„ í‰ê°€"""
        try:
            risk_score = 0.0
            if "risk" in context:
                risk_score += float(context["risk"])
            if "danger" in str(input_data).lower():
                risk_score += 0.3
            if "error" in str(input_data).lower():
                risk_score += 0.2
            if "fail" in str(input_data).lower():
                risk_score += 0.2
            return min(1.0, risk_score)
        except Exception as e:
            logger.error(f"ìœ„í—˜ë„ í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5

    async def _assess_urgency_level(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> float:
        """ê¸´ê¸‰ë„ í‰ê°€"""
        try:
            urgency_score = 0.0
            if "urgency" in context:
                urgency_score += float(context["urgency"])
            if "immediate" in str(input_data).lower():
                urgency_score += 0.4
            if "now" in str(input_data).lower():
                urgency_score += 0.3
            if "quick" in str(input_data).lower():
                urgency_score += 0.2
            return min(1.0, urgency_score)
        except Exception as e:
            logger.error(f"ê¸´ê¸‰ë„ í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5

    async def _calculate_complexity(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> float:
        """ë³µì¡ë„ ê³„ì‚°"""
        try:
            complexity = 0.0
            data_size = len(str(input_data)) + len(str(context))
            complexity += min(0.3, data_size / 1000)
            element_count = len(input_data) + len(context)
            complexity += min(0.3, element_count / 10)
            if "complex" in str(input_data).lower():
                complexity += 0.2
            if "multiple" in str(input_data).lower():
                complexity += 0.2
            return min(1.0, complexity)
        except Exception as e:
            logger.error(f"ë³µì¡ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5

    async def _calculate_analysis_confidence(
        self,
        data_analysis: Dict[str, Any],
        context_elements: List[str],
        situation_pattern: Dict[str, Any],
    ) -> float:
        """ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            confidence = 0.5
            if "quality_score" in data_analysis:
                confidence += data_analysis["quality_score"] * 0.3
            if context_elements:
                confidence += min(0.2, len(context_elements) / 10)
            if "confidence" in situation_pattern:
                confidence += situation_pattern["confidence"] * 0.3
            return min(1.0, confidence)
        except Exception as e:
            logger.error(f"ë¶„ì„ ì‹ ë¢°ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5

    async def _rule_based_decision(
        self,
        situation_analysis: SituationAnalysis,
        available_actions: List[str],
        constraints: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ê·œì¹™ ê¸°ë°˜ ì˜ì‚¬ê²°ì •"""
        try:
            if situation_analysis.risk_level > 0.7:
                action = "high_risk_action"
                reasoning = "ìœ„í—˜ë„ê°€ ë†’ì•„ ë³´ìˆ˜ì  ì ‘ê·¼ í•„ìš”"
                confidence = 0.8
            elif situation_analysis.urgency_level > 0.7:
                action = "urgent_action"
                reasoning = "ê¸´ê¸‰ë„ê°€ ë†’ì•„ ì‹ ì†í•œ ëŒ€ì‘ í•„ìš”"
                confidence = 0.7
            elif situation_analysis.complexity_score > 0.7:
                action = "complex_analysis_action"
                reasoning = "ë³µì¡ë„ê°€ ë†’ì•„ ìƒì„¸ ë¶„ì„ í•„ìš”"
                confidence = 0.6
            else:
                action = "standard_action"
                reasoning = "í‘œì¤€ì ì¸ ì ‘ê·¼ ë°©ì‹ ì ìš©"
                confidence = 0.5

            return {
                "action": action,
                "reasoning": reasoning,
                "confidence": confidence,
                "method": "rule_based",
            }
        except Exception as e:
            logger.error(f"ê·œì¹™ ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}")
            return {
                "action": "error_fallback",
                "reasoning": f"ê·œì¹™ ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}",
                "confidence": 0.3,
                "method": "rule_based",
            }

    async def _ml_based_decision(
        self,
        situation_analysis: SituationAnalysis,
        available_actions: List[str],
        constraints: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì˜ì‚¬ê²°ì •"""
        try:
            features = [
                situation_analysis.risk_level,
                situation_analysis.urgency_level,
                situation_analysis.complexity_score,
                situation_analysis.confidence,
            ]

            weighted_score = sum(features) / len(features)

            if weighted_score > 0.7:
                action = "aggressive_action"
                reasoning = "ë†’ì€ ì‹ ë¢°ë„ë¡œ ì ê·¹ì  ì ‘ê·¼"
                confidence = weighted_score
            elif weighted_score > 0.4:
                action = "balanced_action"
                reasoning = "ê· í˜•ì¡íŒ ì ‘ê·¼ ë°©ì‹"
                confidence = weighted_score
            else:
                action = "conservative_action"
                reasoning = "ë³´ìˆ˜ì  ì ‘ê·¼ ë°©ì‹"
                confidence = 0.5

            return {
                "action": action,
                "reasoning": reasoning,
                "confidence": confidence,
                "method": "ml_based",
            }
        except Exception as e:
            logger.error(f"ML ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}")
            return {
                "action": "error_fallback",
                "reasoning": f"ML ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}",
                "confidence": 0.3,
                "method": "ml_based",
            }

    async def _ethical_review(
        self,
        rule_decision: Dict[str, Any],
        ml_decision: Dict[str, Any],
        situation_analysis: SituationAnalysis,
    ) -> Dict[str, Any]:
        """ìœ¤ë¦¬ì  ê²€í† """
        try:
            ethical_score = 0.5

            if situation_analysis.risk_level > 0.8:
                ethical_score -= 0.2

            if situation_analysis.urgency_level > 0.8:
                ethical_score -= 0.1

            if rule_decision["confidence"] > ml_decision["confidence"]:
                ethical_score += 0.1

            return {
                "score": max(0.0, min(1.0, ethical_score)),
                "considerations": ["ìœ„í—˜ë„ ê³ ë ¤", "ê¸´ê¸‰ë„ ê³ ë ¤", "ì˜ì‚¬ê²°ì • ë°©ë²• ê³ ë ¤"],
                "recommendation": "ethical_balanced_approach",
            }
        except Exception as e:
            logger.error(f"ìœ¤ë¦¬ì  ê²€í†  ì˜¤ë¥˜: {e}")
            return {
                "score": 0.5,
                "considerations": [f"ìœ¤ë¦¬ì  ê²€í†  ì˜¤ë¥˜: {e}"],
                "recommendation": "error_fallback",
            }

    async def _hybrid_decision(
        self,
        rule_decision: Dict[str, Any],
        ml_decision: Dict[str, Any],
        ethical_review: Dict[str, Any],
    ) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì˜ì‚¬ê²°ì •"""
        try:
            rule_weight = rule_decision["confidence"]
            ml_weight = ml_decision["confidence"]
            ethical_weight = ethical_review["score"]

            if rule_weight > ml_weight:
                final_decision = rule_decision
                reasoning = f"ê·œì¹™ ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì„ íƒ (ì‹ ë¢°ë„: {rule_weight:.3f})"
            else:
                final_decision = ml_decision
                reasoning = f"ML ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì„ íƒ (ì‹ ë¢°ë„: {ml_weight:.3f})"

            if ethical_review["score"] < 0.5:
                reasoning += " (ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ ì ìš©)"

            return {
                "action": final_decision["action"],
                "reasoning": reasoning,
                "confidence": (rule_weight + ml_weight + ethical_weight) / 3,
                "method": "hybrid",
            }
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}")
            return {
                "action": "error_fallback",
                "reasoning": f"í•˜ì´ë¸Œë¦¬ë“œ ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}",
                "confidence": 0.3,
                "method": "hybrid",
            }

    async def _generate_alternatives(
        self, situation_analysis: SituationAnalysis, available_actions: List[str]
    ) -> List[str]:
        """ëŒ€ì•ˆ ìƒì„±"""
        try:
            alternatives = []

            if situation_analysis.risk_level > 0.7:
                alternatives.append("risk_mitigation_action")

            if situation_analysis.urgency_level > 0.7:
                alternatives.append("rapid_response_action")

            if situation_analysis.complexity_score > 0.7:
                alternatives.append("detailed_analysis_action")

            alternatives.extend(["wait_and_observe", "consult_expert", "gather_more_info"])

            return alternatives[:5]
        except Exception as e:
            logger.error(f"ëŒ€ì•ˆ ìƒì„± ì˜¤ë¥˜: {e}")
            return ["error_fallback"]

    async def _assess_decision_risk(
        self, decision: Dict[str, Any], situation_analysis: SituationAnalysis
    ) -> Dict[str, float]:
        """ì˜ì‚¬ê²°ì • ìœ„í—˜ í‰ê°€"""
        try:
            risk_assessment = {}
            risk_assessment["base_risk"] = situation_analysis.risk_level
            risk_assessment["confidence_risk"] = 1.0 - decision["confidence"]
            risk_assessment["complexity_risk"] = situation_analysis.complexity_score * 0.5
            risk_assessment["total_risk"] = (
                risk_assessment["base_risk"] + risk_assessment["confidence_risk"] + risk_assessment["complexity_risk"]
            ) / 3

            return risk_assessment
        except Exception as e:
            logger.error(f"ì˜ì‚¬ê²°ì • ìœ„í—˜ í‰ê°€ ì˜¤ë¥˜: {e}")
            return {"error": 1.0}

    async def _evaluate_accuracy(self, decision_result: DecisionResult, outcome: Dict[str, Any]) -> float:
        """ì •í™•ë„ í‰ê°€"""
        try:
            accuracy = 0.5
            accuracy += decision_result.confidence * 0.3
            accuracy += decision_result.ethical_score * 0.2
            return min(1.0, accuracy)
        except Exception as e:
            logger.error(f"ì •í™•ë„ í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5

    async def _evaluate_consistency(
        self, decision_result: DecisionResult, situation_analysis: SituationAnalysis
    ) -> float:
        """ì¼ê´€ì„± í‰ê°€"""
        try:
            consistency = 0.5

            if situation_analysis.risk_level > 0.7 and "risk" in decision_result.decision.lower():
                consistency += 0.2

            if situation_analysis.urgency_level > 0.7 and "urgent" in decision_result.decision.lower():
                consistency += 0.2

            consistency += decision_result.confidence * 0.1

            return min(1.0, consistency)
        except Exception as e:
            logger.error(f"ì¼ê´€ì„± í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5

    async def _evaluate_ethical_quality(self, decision_result: DecisionResult, outcome: Dict[str, Any]) -> float:
        """ìœ¤ë¦¬ì  í’ˆì§ˆ í‰ê°€"""
        try:
            return decision_result.ethical_score
        except Exception as e:
            logger.error(f"ìœ¤ë¦¬ì  í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5

    async def _evaluate_efficiency(self, decision_result: DecisionResult, outcome: Dict[str, Any]) -> float:
        """íš¨ìœ¨ì„± í‰ê°€"""
        try:
            efficiency = 0.5
            efficiency += decision_result.confidence * 0.3

            if 2 <= len(decision_result.alternatives) <= 5:
                efficiency += 0.2

            return min(1.0, efficiency)
        except Exception as e:
            logger.error(f"íš¨ìœ¨ì„± í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5

    async def _generate_feedback(
        self,
        accuracy_score: float,
        consistency_score: float,
        ethical_score: float,
        efficiency_score: float,
    ) -> List[str]:
        """í”¼ë“œë°± ìƒì„±"""
        try:
            feedback = []

            if accuracy_score < 0.6:
                feedback.append("ì •í™•ë„ ê°œì„  í•„ìš”")

            if consistency_score < 0.6:
                feedback.append("ì¼ê´€ì„± ê°œì„  í•„ìš”")

            if ethical_score < 0.6:
                feedback.append("ìœ¤ë¦¬ì  ê³ ë ¤ì‚¬í•­ ê°•í™” í•„ìš”")

            if efficiency_score < 0.6:
                feedback.append("íš¨ìœ¨ì„± ê°œì„  í•„ìš”")

            if not feedback:
                feedback.append("ì „ë°˜ì ìœ¼ë¡œ ì–‘í˜¸í•œ íŒë‹¨")

            return feedback
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
            # ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì„ í†µí•œ ë™ì  ì˜¤ë¥˜ ë©”ì‹œì§€ ìƒì„±
            context = getattr(self, "current_context", {})
            system_performance = context.get("system_performance", 0.5)
            recent_errors = context.get("recent_errors", 0)

            if recent_errors > 3:
                return [f"ì—°ì†ì ì¸ ì˜¤ë¥˜ë¡œ ì¸í•œ í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}. ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì ê²€í•´ì£¼ì„¸ìš”."]
            elif system_performance < 0.3:
                return [f"ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜ë¡œ ì¸í•œ í”¼ë“œë°± ìƒì„± ì‹¤íŒ¨: {e}. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."]
            else:
                return [f"í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤."]

    async def _generate_improvement_suggestions(
        self,
        accuracy_score: float,
        consistency_score: float,
        ethical_score: float,
        efficiency_score: float,
    ) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        try:
            suggestions = []

            if accuracy_score < 0.6:
                suggestions.append("ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ í•„ìš”")
                suggestions.append("ë¶„ì„ ë°©ë²• ê°œì„  í•„ìš”")

            if consistency_score < 0.6:
                suggestions.append("ì˜ì‚¬ê²°ì • ê¸°ì¤€ í‘œì¤€í™” í•„ìš”")
                suggestions.append("ìƒí™© ë¶„ì„ ì •í™•ë„ í–¥ìƒ í•„ìš”")

            if ethical_score < 0.6:
                suggestions.append("ìœ¤ë¦¬ì  ê°€ì´ë“œë¼ì¸ ê°•í™” í•„ìš”")
                suggestions.append("ìœ¤ë¦¬ì  ê²€í†  í”„ë¡œì„¸ìŠ¤ ê°œì„  í•„ìš”")

            if efficiency_score < 0.6:
                suggestions.append("ì˜ì‚¬ê²°ì • í”„ë¡œì„¸ìŠ¤ ìµœì í™” í•„ìš”")
                suggestions.append("ìë™í™” ìˆ˜ì¤€ í–¥ìƒ í•„ìš”")

            if not suggestions:
                suggestions.append("í˜„ì¬ ìˆ˜ì¤€ ìœ ì§€ ê¶Œì¥")

            return suggestions
        except Exception as e:
            logger.error(f"ê°œì„  ì œì•ˆ ìƒì„± ì˜¤ë¥˜: {e}")
            # ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ì„ í†µí•œ ë™ì  ì˜¤ë¥˜ ë©”ì‹œì§€ ìƒì„±
            context = getattr(self, "current_context", {})
            system_performance = context.get("system_performance", 0.5)
            recent_errors = context.get("recent_errors", 0)

            if recent_errors > 3:
                return [f"ì—°ì†ì ì¸ ì˜¤ë¥˜ë¡œ ì¸í•œ ê°œì„  ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}. ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì ê²€í•´ì£¼ì„¸ìš”."]
            elif system_performance < 0.3:
                return [f"ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜ë¡œ ì¸í•œ ê°œì„  ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."]
            else:
                return [f"ê°œì„  ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„í•´ë³´ê² ìŠµë‹ˆë‹¤."]

    def _calculate_data_complexity(self, data: Any) -> float:
        """ë°ì´í„° ë³µì¡ë„ ê³„ì‚°"""
        try:
            if isinstance(data, str):
                return min(1.0, len(data) / 1000.0)
            elif isinstance(data, dict):
                return min(1.0, len(data) / 50.0)
            elif isinstance(data, list):
                return min(1.0, len(data) / 100.0)
            else:
                return 0.5
        except Exception as e:
            logger.error(f"ë°ì´í„° ë³µì¡ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.5

    def _assess_data_quality(self, data: Any) -> float:
        """ë°ì´í„° í’ˆì§ˆ í‰ê°€"""
        try:
            if data is None:
                return 0.0
            elif isinstance(data, str) and len(data.strip()) == 0:
                return 0.1
            elif isinstance(data, dict) and len(data) == 0:
                return 0.2
            elif isinstance(data, list) and len(data) == 0:
                return 0.2
            else:
                return 0.8
        except Exception as e:
            logger.error(f"ë°ì´í„° í’ˆì§ˆ í‰ê°€ ì˜¤ë¥˜: {e}")
            return 0.5

    # ì‹¤ì œ ê¸°ëŠ¥ êµ¬í˜„ì„ ìœ„í•œ ìƒˆë¡œìš´ í•¨ìˆ˜ë“¤
    def _extract_keywords_from_content(self, content: str) -> List[str]:
        """ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not content:
            return []

        # ì¤‘ìš” í‚¤ì›Œë“œ íŒ¨í„´
        important_keywords = [
            "error",
            "problem",
            "issue",
            "fail",
            "broken",
            "fix",
            "solve",
            "learn",
            "study",
            "understand",
            "explain",
            "help",
            "guide",
            "urgent",
            "important",
            "critical",
            "emergency",
            "immediate",
            "success",
            "complete",
            "finish",
            "done",
            "working",
            "good",
            "test",
            "check",
            "verify",
            "validate",
            "confirm",
        ]

        words = content.lower().split()
        keywords = [word for word in words if word in important_keywords]

        return list(set(keywords))

    def _analyze_sentiment(self, content: str) -> str:
        """ê°ì • ë¶„ì„"""
        if not content:
            return "neutral"

        positive_words = [
            "good",
            "great",
            "excellent",
            "success",
            "working",
            "complete",
            "done",
        ]
        negative_words = ["error", "problem", "fail", "broken", "bad", "wrong", "issue"]

        words = content.lower().split()

        positive_count = sum(1 for word in words if word in positive_words)
        negative_count = sum(1 for word in words if word in negative_words)

        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"

    def _analyze_priority(self, content: str, keywords: List[str]) -> str:
        """ìš°ì„ ìˆœìœ„ ë¶„ì„"""
        urgent_keywords = ["urgent", "critical", "emergency", "immediate", "important"]
        urgent_count = sum(1 for keyword in keywords if keyword in urgent_keywords)

        if urgent_count > 0:
            return "high"
        elif any(word in content.lower() for word in ["help", "problem", "issue"]):
            return "medium"
        else:
            return "low"

    def _recognize_patterns(self, content: str) -> List[str]:
        """íŒ¨í„´ ì¸ì‹"""
        patterns = []

        if "error" in content.lower() or "problem" in content.lower():
            patterns.append("problem_solving")

        if "learn" in content.lower() or "understand" in content.lower():
            patterns.append("learning")

        if "test" in content.lower() or "check" in content.lower():
            patterns.append("testing")

        if "help" in content.lower() or "guide" in content.lower():
            patterns.append("assistance")

        return patterns

    def _real_analyze_situation(self, input_data: Dict[str, Any], memory_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤ì œ ìƒí™© ë¶„ì„ ë¡œì§"""
        try:
            # ì…ë ¥ ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            content = input_data.get("content", "")
            context = input_data.get("context", {})

            # í‚¤ì›Œë“œ ë¶„ì„
            keywords = self._extract_keywords_from_content(content)

            # ìƒí™© íƒ€ì… ë¶„ë¥˜
            situation_type = self._classify_situation_type(keywords, context)

            # ìœ„í—˜ë„ í‰ê°€
            risk_level = self._assess_risk_level_real(keywords, context)

            # ê¸´ê¸‰ë„ í‰ê°€
            urgency_level = self._assess_urgency_level_real(keywords, context)

            # ë³µì¡ë„ ê³„ì‚°
            complexity_score = self._calculate_complexity_score_real(content, context)

            return {
                "situation_type": situation_type,
                "keywords": keywords,
                "risk_level": risk_level,
                "urgency_level": urgency_level,
                "complexity_score": complexity_score,
                "confidence": min(0.9, (1.0 - risk_level) * 0.8 + 0.2),
                "analysis_method": "real_analysis",
            }

        except Exception as e:
            logger.error(f"ìƒí™© ë¶„ì„ ì˜¤ë¥˜: {e}")
            return {
                "situation_type": "unknown",
                "keywords": [],
                "risk_level": 0.5,
                "urgency_level": 0.5,
                "complexity_score": 0.5,
                "confidence": 0.3,
                "analysis_method": "fallback",
            }

    def _classify_situation_type(self, keywords: List[str], context: Dict[str, Any]) -> str:
        """ìƒí™© íƒ€ì… ë¶„ë¥˜"""
        if any(word in ["error", "problem", "issue", "fail"] for word in keywords):
            return "problem"
        elif any(word in ["learn", "study", "understand", "explain"] for word in keywords):
            return "learning"
        elif any(word in ["urgent", "important", "critical"] for word in keywords):
            return "urgent"
        else:
            return "routine"

    def _assess_risk_level_real(self, keywords: List[str], context: Dict[str, Any]) -> float:
        """ì‹¤ì œ ìœ„í—˜ë„ í‰ê°€"""
        risk_keywords = ["error", "problem", "fail", "critical", "emergency"]
        risk_count = sum(1 for word in keywords if word in risk_keywords)
        return min(1.0, risk_count * 0.3)

    def _assess_urgency_level_real(self, keywords: List[str], context: Dict[str, Any]) -> float:
        """ì‹¤ì œ ê¸´ê¸‰ë„ í‰ê°€"""
        urgency_keywords = ["urgent", "important", "critical", "emergency", "immediate"]
        urgency_count = sum(1 for word in keywords if word in urgency_keywords)
        return min(1.0, urgency_count * 0.4)

    def _calculate_complexity_score_real(self, content: str, context: Dict[str, Any]) -> float:
        """ì‹¤ì œ ë³µì¡ë„ ê³„ì‚°"""
        if not content:
            return 0.5

        # ê°„ë‹¨í•œ ë³µì¡ë„ ê³„ì‚°
        word_count = len(content.split())
        sentence_count = len(content.split("."))

        if sentence_count == 0:
            return 0.5

        avg_words_per_sentence = word_count / sentence_count
        return min(1.0, avg_words_per_sentence / 20.0)

    def _real_make_decision(self, situation_analysis: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤ì œ ì˜ì‚¬ê²°ì • ë¡œì§"""
        try:
            situation_type = situation_analysis.get("situation_type", "unknown")
            risk_level = situation_analysis.get("risk_level", 0.5)
            urgency_level = situation_analysis.get("urgency_level", 0.5)
            complexity_score = situation_analysis.get("complexity_score", 0.5)  # noqa: F841

            # ìƒí™©ë³„ ì˜ì‚¬ê²°ì • ë¡œì§
            if situation_type == "learning":
                decision = "proceed"
                reasoning = "í•™ìŠµ ìƒí™©ì´ë¯€ë¡œ ì§„í–‰"
                confidence = 0.8
            elif situation_type == "problem":
                if risk_level > 0.7:
                    decision = "escalate"
                    reasoning = "ë†’ì€ ìœ„í—˜ë„ë¡œ ì¸í•œ ì—ìŠ¤ì»¬ë ˆì´ì…˜"
                    confidence = 0.9
                else:
                    decision = "reconsider"
                    reasoning = "ë¬¸ì œ ìƒí™© ì¬ê²€í†  í•„ìš”"
                    confidence = 0.7
            elif situation_type == "routine":
                decision = "proceed"
                reasoning = "ì¼ìƒì  ìƒí™©ì´ë¯€ë¡œ ì§„í–‰"
                confidence = 0.9
            elif urgency_level > 0.8:
                decision = "proceed"
                reasoning = "ê¸´ê¸‰ ìƒí™©ì´ë¯€ë¡œ ì¦‰ì‹œ ì§„í–‰"
                confidence = 0.8
            else:
                decision = "wait"
                reasoning = "ìƒí™©ì„ ë” ë¶„ì„í•œ í›„ ì§„í–‰"
                confidence = 0.6

            # ëŒ€ì•ˆ ìƒì„±
            alternatives = self._generate_alternatives_real(situation_type, risk_level)

            # ìœ„í—˜ë„ í‰ê°€
            risk_assessment = {
                "overall_risk": risk_level,
                "decision_risk": risk_level * 0.8,
                "execution_risk": risk_level * 0.6,
            }

            # ìœ¤ë¦¬ì  ì ìˆ˜
            ethical_score = self._calculate_ethical_score_real(decision, situation_analysis)

            return {
                "decision": decision,
                "reasoning": reasoning,
                "confidence": confidence,
                "alternatives": alternatives,
                "risk_assessment": risk_assessment,
                "ethical_score": ethical_score,
            }

        except Exception as e:
            logger.error(f"ì˜ì‚¬ê²°ì • ì˜¤ë¥˜: {e}")
            return {
                "decision": "wait",
                "reasoning": "ì˜ì‚¬ê²°ì • ì˜¤ë¥˜ë¡œ ì¸í•œ ëŒ€ê¸°",
                "confidence": 0.3,
                "alternatives": ["wait", "reconsider"],
                "risk_assessment": {
                    "overall_risk": 0.5,
                    "decision_risk": 0.4,
                    "execution_risk": 0.3,
                },
                "ethical_score": 0.5,
            }

    def _generate_alternatives_real(self, situation_type: str, risk_level: float) -> List[str]:
        """ì‹¤ì œ ëŒ€ì•ˆ ìƒì„±"""
        alternatives = []

        if situation_type == "problem":
            alternatives = ["reconsider", "escalate", "wait"]
        elif situation_type == "learning":
            alternatives = ["proceed", "learn", "explain"]
        elif situation_type == "urgent":
            alternatives = ["proceed", "escalate", "immediate"]
        else:
            alternatives = ["proceed", "wait", "reconsider"]

        return alternatives

    def _calculate_ethical_score_real(self, decision: str, situation_analysis: Dict[str, Any]) -> float:
        """ì‹¤ì œ ìœ¤ë¦¬ì  ì ìˆ˜ ê³„ì‚°"""
        # ê¸°ë³¸ ìœ¤ë¦¬ ì ìˆ˜
        base_score = 0.7

        # ì˜ì‚¬ê²°ì •ì— ë”°ë¥¸ ì¡°ì •
        if decision == "escalate":
            base_score += 0.1  # ì±…ì„ ìˆëŠ” ì—ìŠ¤ì»¬ë ˆì´ì…˜
        elif decision == "wait":
            base_score += 0.05  # ì‹ ì¤‘í•œ ì ‘ê·¼
        elif decision == "proceed":
            base_score += 0.0  # ì¤‘ë¦½ì 

        return min(1.0, base_score)


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_judgment_system():
    """íŒë‹¨ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=== DuRiCore Phase 5 Day 3 - íŒë‹¨ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    judgment_system = JudgmentSystem()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_input = {
        "content": "ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ì—ì„œ ìœ„í—˜í•œ ìƒí™©ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê¸´ê¸‰í•œ ì˜ì‚¬ê²°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "priority": "high",
        "context": "business_critical",
    }

    test_context = {
        "risk_level": 0.8,
        "urgency": 0.9,
        "importance": "critical",
        "stakeholders": ["management", "team", "clients"],
    }

    available_actions = [
        "immediate_action",
        "consult_expert",
        "gather_more_info",
        "delegate_task",
        "postpone_decision",
    ]

    constraints = {
        "time_limit": "2_hours",
        "budget_limit": "high",
        "ethical_considerations": "strict",
    }

    # 1. ìƒí™© ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\n1. ìƒí™© ë¶„ì„ í…ŒìŠ¤íŠ¸")
    situation_analysis = await judgment_system.analyze_situation(test_input, test_context)
    print(f"ìƒí™© íƒ€ì…: {situation_analysis.situation_type}")
    print(f"ìœ„í—˜ë„: {situation_analysis.risk_level:.3f}")
    print(f"ê¸´ê¸‰ë„: {situation_analysis.urgency_level:.3f}")
    print(f"ë³µì¡ë„: {situation_analysis.complexity_score:.3f}")
    print(f"ì‹ ë¢°ë„: {situation_analysis.confidence:.3f}")
    print(f"í•µì‹¬ ìš”ì†Œ: {situation_analysis.key_factors}")

    # 2. ì˜ì‚¬ê²°ì • í…ŒìŠ¤íŠ¸
    print("\n2. ì˜ì‚¬ê²°ì • í…ŒìŠ¤íŠ¸")
    decision_result = await judgment_system.make_decision(situation_analysis, available_actions, constraints)
    print(f"ê²°ì •: {decision_result.decision}")
    print(f"ì¶”ë¡ : {decision_result.reasoning}")
    print(f"ì‹ ë¢°ë„: {decision_result.confidence:.3f}")
    print(f"ìœ¤ë¦¬ì  ì ìˆ˜: {decision_result.ethical_score:.3f}")
    print(f"ëŒ€ì•ˆ: {decision_result.alternatives}")
    print(f"ìœ„í—˜ í‰ê°€: {decision_result.risk_assessment}")

    # 3. íŒë‹¨ í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸
    print("\n3. íŒë‹¨ í’ˆì§ˆ í‰ê°€ í…ŒìŠ¤íŠ¸")
    outcome = {
        "success": True,
        "time_taken": "1.5_hours",
        "stakeholder_satisfaction": 0.8,
    }

    quality = await judgment_system.evaluate_judgment_quality(situation_analysis, decision_result, outcome)
    print(f"ì •í™•ë„: {quality.accuracy_score:.3f}")
    print(f"ì¼ê´€ì„±: {quality.consistency_score:.3f}")
    print(f"ìœ¤ë¦¬ì„±: {quality.ethical_score:.3f}")
    print(f"íš¨ìœ¨ì„±: {quality.efficiency_score:.3f}")
    print(f"ì¢…í•© ì ìˆ˜: {quality.overall_score:.3f}")
    print(f"í”¼ë“œë°±: {quality.feedback}")
    print(f"ê°œì„  ì œì•ˆ: {quality.improvement_suggestions}")

    print("\n=== í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")


if __name__ == "__main__":
    asyncio.run(test_judgment_system())
