#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DuRi Phase Z v2.0: DuRiThoughtFlow - íë¦„ ì¤‘ì‹¬ í†µí•© ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ DuRiì˜ ì‚¬ê³  íë¦„ ì¤‘ì‹¬ í†µí•© ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì •ì  ëª¨ë“ˆ ë¶„ë¦¬ê°€ ì•„ë‹Œ ë™ì  ì—­í•  ì „ì´ë¥¼ í†µí•´ ì§„ì§œ ì‚¬ê³ ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- íë¦„ ì¤‘ì‹¬ í†µí•© êµ¬ì¡°
- ë‚´ì¬í™”ëœ ë°˜ì„± ë©”ì»¤ë‹ˆì¦˜
- ë™ì  ì—­í•  ì „ì´ ì‹œìŠ¤í…œ
- ë‚´ë¶€ ëª¨ìˆœ íƒì§€
- ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•© ì¸í„°í˜ì´ìŠ¤
"""

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

# ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ import
try:
    from adaptive_learning_system import AdaptiveLearningSystem
    from decision_support_system import DecisionSupportSystem
    from dynamic_reasoning_graph import DynamicReasoningGraphAnalyzer, DynamicReasoningGraphBuilder
    from semantic_vector_engine import SemanticVectorEngine

    from logical_reasoning_engine import LogicalReasoningEngine
except ImportError as e:
    logging.warning(f"ì¼ë¶€ ê¸°ì¡´ ì‹œìŠ¤í…œ import ì‹¤íŒ¨: {e}")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class ThoughtRole(Enum):
    """ì‚¬ê³  ì—­í•  ì—´ê±°í˜•"""

    OBSERVER = "observer"
    COUNTER_ARGUER = "counter_arguer"
    REFRAMER = "reframer"
    GOAL_REVISER = "goal_reviser"


class ReflectionLevel(Enum):
    """ë°˜ì„± ìˆ˜ì¤€ ì—´ê±°í˜•"""

    NONE = "none"
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class ConflictType(Enum):
    """ì¶©ëŒ ìœ í˜• ì—´ê±°í˜•"""

    LOGICAL = "logical"
    ETHICAL = "ethical"
    PRACTICAL = "practical"
    GOAL = "goal"
    INTERNAL = "internal"


@dataclass
class ThoughtState:
    """ì‚¬ê³  ìƒíƒœ ë°ì´í„° í´ë˜ìŠ¤"""

    current_role: ThoughtRole
    input_data: Dict[str, Any]
    context: Dict[str, Any]
    thought_history: List[Dict[str, Any]] = field(default_factory=list)
    internal_conflicts: List[Dict[str, Any]] = field(default_factory=list)
    reflection_scores: List[float] = field(default_factory=list)
    current_goal: Optional[str] = None
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class ReflectionResult:
    """ë°˜ì„± ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""

    score: float
    level: ReflectionLevel
    conflicts_detected: List[Dict[str, Any]]
    recommendations: List[str]
    needs_reprocessing: bool = False


@dataclass
class ThoughtFlowResult:
    """ì‚¬ê³  íë¦„ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""

    final_decision: Dict[str, Any]
    thought_process: List[Dict[str, Any]]
    reflection_result: ReflectionResult
    internal_conflicts: List[Dict[str, Any]]
    processing_time: float
    success: bool = True


class DuRiThoughtFlow:
    """DuRiì˜ ì‚¬ê³  íë¦„ ì¤‘ì‹¬ í†µí•© ì‹œìŠ¤í…œ"""

    def __init__(self, input_data: Dict[str, Any], context: Optional[Dict[str, Any]] = None):
        self.input_data = input_data
        self.context = context or {}
        self.thought_history = []
        self.internal_conflicts = []
        self.reflection_scores = []
        self.current_goal = self.context.get("goal", "default_goal")
        self.REFLECTION_THRESHOLD = 0.7
        self.start_time = None
        self.end_time = None

        # ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•© ì¸í„°í˜ì´ìŠ¤
        self._initialize_integration_interfaces()

        # ì‚¬ê³  ìƒíƒœ ì´ˆê¸°í™”
        self.thought_state = ThoughtState(
            current_role=ThoughtRole.OBSERVER,
            input_data=input_data,
            context=self.context,
            current_goal=self.current_goal,
        )

        logger.info(f"DuRiThoughtFlow ì´ˆê¸°í™” ì™„ë£Œ - ëª©í‘œ: {self.current_goal}")

    def _initialize_integration_interfaces(self):
        """ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•© ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”"""
        try:
            # ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ ì´ˆê¸°í™”
            self.semantic_engine = SemanticVectorEngine()
            self.logical_engine = LogicalReasoningEngine()
            self.graph_builder = DynamicReasoningGraphBuilder()
            self.graph_analyzer = DynamicReasoningGraphAnalyzer()
            self.decision_system = DecisionSupportSystem()
            self.learning_system = AdaptiveLearningSystem()

            logger.info("ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•© ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"ê¸°ì¡´ ì‹œìŠ¤í…œ í†µí•© ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            self.semantic_engine = None
            self.logical_engine = None
            self.graph_builder = None
            self.graph_analyzer = None
            self.decision_system = None
            self.learning_system = None

    async def process(self) -> ThoughtFlowResult:
        """ì‚¬ê³  íë¦„ì˜ ì „ì²´ í”„ë¡œì„¸ìŠ¤"""
        logger.info("=== DuRiThoughtFlow ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ===")
        self.start_time = datetime.now()

        try:
            # 1. ê´€ì°° (ìê¸° ìƒíƒœ ì¸ì‹)
            await self.observe()

            # 2. ë°˜ë°• (ë‚´ì  ë…¼ì¦)
            await self.counter_argue()

            # 3. ì¬ì •ì˜ (ë¬¸ì œ ì¬êµ¬ì„±)
            await self.reframe()

            # 4. ëª©í‘œ ìˆ˜ì • (ë©”íƒ€ ì¸ì§€)
            await self.revise_goal()

            # 5. ìµœì¢… ê²°ì •
            final_decision = await self.decide(self_reflect=True)

            self.end_time = datetime.now()
            processing_time = (self.end_time - self.start_time).total_seconds()

            # ë°˜ì„± ê²°ê³¼ ìƒì„±
            reflection_result = await self._calculate_reflection_result(final_decision)

            result = ThoughtFlowResult(
                final_decision=final_decision,
                thought_process=self.thought_history,
                reflection_result=reflection_result,
                internal_conflicts=self.internal_conflicts,
                processing_time=processing_time,
                success=True,
            )

            logger.info(f"=== DuRiThoughtFlow ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {processing_time:.2f}ì´ˆ ===")
            return result

        except Exception as e:
            logger.error(f"DuRiThoughtFlow í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
            self.end_time = datetime.now()
            processing_time = (self.end_time - self.start_time).total_seconds()

            return ThoughtFlowResult(
                final_decision={},
                thought_process=self.thought_history,
                reflection_result=ReflectionResult(0.0, ReflectionLevel.NONE, [], []),
                internal_conflicts=self.internal_conflicts,
                processing_time=processing_time,
                success=False,
            )

    async def observe(self) -> None:
        """ìê¸° ê´€ì°° ì—­í•  (ìˆœê°„ì  ì‹¤í–‰)"""
        logger.info("ğŸ” Observer ì—­í•  ì‹¤í–‰ - ìê¸° ìƒíƒœ ì¸ì‹")

        # í˜„ì¬ ìƒíƒœ ê´€ì°°
        current_state = {
            "role": ThoughtRole.OBSERVER.value,
            "timestamp": datetime.now().isoformat(),
            "input_data": self.input_data,
            "context": self.context,
            "current_goal": self.current_goal,
            "thought_history_length": len(self.thought_history),
            "internal_conflicts_count": len(self.internal_conflicts),
        }

        # ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•©: SemanticVectorEngineì„ í†µí•œ ë¶„ì„ ê²°ê³¼ ê²€ì¦
        if self.semantic_engine:
            semantic_analysis = await self._integrate_semantic_analysis()
            current_state["semantic_analysis"] = semantic_analysis

        # ëª¨ìˆœì´ë‚˜ ë¶ˆì•ˆì •ì„± íƒì§€
        conflicts = await self._detect_internal_conflicts()
        if conflicts:
            self.internal_conflicts.extend(conflicts)
            logger.warning(f"ë‚´ë¶€ ì¶©ëŒ ê°ì§€: {len(conflicts)}ê°œ")

        # ì‚¬ê³  ìƒíƒœ ì—…ë°ì´íŠ¸
        self.thought_state.current_role = ThoughtRole.OBSERVER
        self.thought_state.thought_history.append(current_state)
        self.thought_history.append(current_state)

        logger.info("âœ… Observer ì—­í•  ì™„ë£Œ")

    async def counter_argue(self) -> None:
        """ë‚´ì  ë°˜ë°• ì—­í•  (ìˆœê°„ì  ì‹¤í–‰)"""
        logger.info("ğŸ¤” Counter-arguer ì—­í•  ì‹¤í–‰ - ë‚´ì  ë°˜ë°•")

        # í˜„ì¬ ì£¼ì¥ì— ëŒ€í•œ ë°˜ë¡  ìƒì„±
        counter_arguments = await self._generate_counter_arguments()

        # ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•©: LogicalReasoningEngineì„ í†µí•œ ë…¼ë¦¬ì  ê²€í† 
        if self.logical_engine:
            logical_review = await self._integrate_logical_review()
            # LogicalArgument ê°ì²´ì˜ counter_arguments ì†ì„±ì— ì ‘ê·¼
            if hasattr(logical_review, "counter_arguments"):
                counter_arguments.extend(logical_review.counter_arguments)
            elif isinstance(logical_review, dict):
                counter_arguments.extend(logical_review.get("counter_arguments", []))

        counter_state = {
            "role": ThoughtRole.COUNTER_ARGUER.value,
            "timestamp": datetime.now().isoformat(),
            "counter_arguments": counter_arguments,
            "arguments_count": len(counter_arguments),
        }

        # ë…¼ë¦¬ì , ìœ¤ë¦¬ì , ì‹¤ìš©ì  ê´€ì ì—ì„œ ê²€í† 
        for arg in counter_arguments:
            if isinstance(arg, dict) and arg.get("strength", 0) > 0.7:  # ê°•í•œ ë°˜ë¡ 
                self.internal_conflicts.append(
                    {
                        "type": ConflictType.LOGICAL.value,
                        "description": arg.get("description", ""),
                        "strength": arg.get("strength", 0),
                        "timestamp": datetime.now().isoformat(),
                    }
                )

        # ì‚¬ê³  ìƒíƒœ ì—…ë°ì´íŠ¸
        self.thought_state.current_role = ThoughtRole.COUNTER_ARGUER
        self.thought_state.thought_history.append(counter_state)
        self.thought_history.append(counter_state)

        logger.info(f"âœ… Counter-arguer ì—­í•  ì™„ë£Œ - {len(counter_arguments)}ê°œ ë°˜ë¡  ìƒì„±")

    async def reframe(self) -> None:
        """ë¬¸ì œ ì¬ì •ì˜ ì—­í•  (ìˆœê°„ì  ì‹¤í–‰)"""
        logger.info("ğŸ”„ Reframer ì—­í•  ì‹¤í–‰ - ë¬¸ì œ ì¬ì •ì˜")

        # ë‚´ë¶€ ëª¨ìˆœ ë°œê²¬ ì‹œ ë¬¸ì œ ìì²´ ì¬ì •ì˜
        if self.internal_conflicts:
            reframed_problem = await self._redefine_problem()

            # ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•©: DynamicReasoningGraphë¥¼ í†µí•œ ë‚´ì  ë…¼ë¦¬ íë¦„ ê²€ì¦
            if self.graph_analyzer:
                graph_analysis = await self._integrate_graph_analysis()
                reframed_problem["graph_analysis"] = graph_analysis

            reframe_state = {
                "role": ThoughtRole.REFRAMER.value,
                "timestamp": datetime.now().isoformat(),
                "original_problem": self.input_data,
                "reframed_problem": reframed_problem,
                "conflicts_resolved": len(self.internal_conflicts),
            }

            # ì „ì œ ìˆ˜ì • ë° ìƒˆë¡œìš´ ê´€ì  ë„ì¶œ
            if reframed_problem:
                self.input_data.update(reframed_problem)
                logger.info("ë¬¸ì œ ì¬ì •ì˜ ì™„ë£Œ")
        else:
            reframe_state = {
                "role": ThoughtRole.REFRAMER.value,
                "timestamp": datetime.now().isoformat(),
                "original_problem": self.input_data,
                "reframed_problem": None,
                "conflicts_resolved": 0,
            }

        # ì‚¬ê³  ìƒíƒœ ì—…ë°ì´íŠ¸
        self.thought_state.current_role = ThoughtRole.REFRAMER
        self.thought_state.thought_history.append(reframe_state)
        self.thought_history.append(reframe_state)

        logger.info("âœ… Reframer ì—­í•  ì™„ë£Œ")

    async def revise_goal(self) -> None:
        """ëª©í‘œ ìˆ˜ì • ì—­í•  (ìˆœê°„ì  ì‹¤í–‰)"""
        logger.info("ğŸ¯ Goal-reviser ì—­í•  ì‹¤í–‰ - ëª©í‘œ ìˆ˜ì •")

        # ë©”íƒ€ ì¸ì§€ì  ëª©í‘œ ê²€í†  ë° ìˆ˜ì •
        goal_revision = await self._evaluate_goal_validity()

        # ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•©: DecisionSupportSystemì„ í†µí•œ ì˜ì‚¬ê²°ì • ê²€í† 
        if self.decision_system:
            decision_review = await self._integrate_decision_review()
            goal_revision["decision_review"] = decision_review

        if goal_revision.get("needs_revision", False):
            new_goal = goal_revision.get("new_goal", self.current_goal)
            self.current_goal = new_goal
            self.thought_state.current_goal = new_goal
            logger.info(f"ëª©í‘œ ìˆ˜ì •: {new_goal}")

        revise_state = {
            "role": ThoughtRole.GOAL_REVISER.value,
            "timestamp": datetime.now().isoformat(),
            "original_goal": self.context.get("goal", "default_goal"),
            "current_goal": self.current_goal,
            "goal_revision": goal_revision,
        }

        # ì‚¬ê³  ìƒíƒœ ì—…ë°ì´íŠ¸
        self.thought_state.current_role = ThoughtRole.GOAL_REVISER
        self.thought_state.thought_history.append(revise_state)
        self.thought_history.append(revise_state)

        logger.info("âœ… Goal-reviser ì—­í•  ì™„ë£Œ")

    async def decide(self, self_reflect: bool = True) -> Dict[str, Any]:
        """ìµœì¢… ê²°ì • (ë‚´ì¬í™”ëœ ë°˜ì„± í¬í•¨)"""
        logger.info("ğŸ¯ ìµœì¢… ê²°ì • ì‹¤í–‰")

        # ê¸°ë³¸ ê²°ì •
        decision = await self._make_decision()

        if self_reflect:
            # ìë™ ë°˜ì„± ì ìˆ˜ ê³„ì‚°
            reflection_score = await self._calculate_reflection_score(decision)
            self.reflection_scores.append(reflection_score)

            # ë°˜ì„± ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ì¬ì²˜ë¦¬
            if reflection_score < self.REFLECTION_THRESHOLD:
                logger.warning(f"ë°˜ì„± ì ìˆ˜ ë‚®ìŒ ({reflection_score:.2f}), ì¬ì²˜ë¦¬ ì‹œì‘")
                await self._reprocess_with_reflection(decision)
                # ì¬ì²˜ë¦¬ í›„ ìƒˆë¡œìš´ ê²°ì •
                decision = await self._make_decision()

        decision_state = {
            "role": "decider",
            "timestamp": datetime.now().isoformat(),
            "decision": decision,
            "reflection_score": (self.reflection_scores[-1] if self.reflection_scores else 0.0),
            "self_reflect": self_reflect,
        }

        self.thought_history.append(decision_state)

        logger.info(
            f"âœ… ìµœì¢… ê²°ì • ì™„ë£Œ - ë°˜ì„± ì ìˆ˜: {self.reflection_scores[-1] if self.reflection_scores else 0.0:.2f}"
        )
        return decision

    # ê¸°ì¡´ ì‹œìŠ¤í…œë“¤ê³¼ì˜ í†µí•© ë©”ì„œë“œë“¤
    async def _integrate_semantic_analysis(self) -> Dict[str, Any]:
        """SemanticVectorEngineê³¼ì˜ í†µí•©"""
        if not self.semantic_engine:
            return {}

        try:
            # ì˜ë¯¸ ë¶„ì„ ìˆ˜í–‰
            semantic_result = await self.semantic_engine.analyze_semantic_situation(
                self.input_data.get("question", ""), self.context
            )
            return semantic_result
        except Exception as e:
            logger.warning(f"SemanticVectorEngine í†µí•© ì‹¤íŒ¨: {e}")
            return {}

    async def _integrate_logical_review(self) -> Dict[str, Any]:
        """LogicalReasoningEngineê³¼ì˜ í†µí•©"""
        if not self.logical_engine:
            return {}

        try:
            # ë…¼ë¦¬ì  ê²€í†  ìˆ˜í–‰
            logical_result = await self.logical_engine.analyze_logical_reasoning(
                self.input_data.get("question", ""), self.input_data.get("action", "")
            )
            return logical_result
        except Exception as e:
            logger.warning(f"LogicalReasoningEngine í†µí•© ì‹¤íŒ¨: {e}")
            return {}

    async def _integrate_graph_analysis(self) -> Dict[str, Any]:
        """DynamicReasoningGraphì™€ì˜ í†µí•©"""
        if not self.graph_analyzer:
            return {}

        try:
            # ê·¸ë˜í”„ ë¶„ì„ ìˆ˜í–‰
            graph_result = await self.graph_analyzer.analyze_dynamic_reasoning_process(
                self.input_data.get("question", ""), self.context, self.thought_history
            )
            return graph_result
        except Exception as e:
            logger.warning(f"DynamicReasoningGraph í†µí•© ì‹¤íŒ¨: {e}")
            return {}

    async def _integrate_decision_review(self) -> Dict[str, Any]:
        """DecisionSupportSystemê³¼ì˜ í†µí•©"""
        if not self.decision_system:
            return {}

        try:
            # ì˜ì‚¬ê²°ì • ê²€í†  ìˆ˜í–‰
            decision_result = await self.decision_system.support_decision(
                {
                    "type": "multi_criteria",
                    "data": self.input_data,
                    "context": self.context,
                    "thought_history": self.thought_history,
                }
            )
            return decision_result
        except Exception as e:
            logger.warning(f"DecisionSupportSystem í†µí•© ì‹¤íŒ¨: {e}")
            return {}

    async def _detect_internal_conflicts(self) -> List[Dict[str, Any]]:
        """ë‚´ë¶€ ëª¨ìˆœ íƒì§€"""
        conflicts = []

        # ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬
        logical_conflicts = await self._check_logical_consistency()
        conflicts.extend(logical_conflicts)

        # ëª©í‘œ ì¶©ëŒ ê°ì§€
        goal_conflicts = await self._check_goal_conflicts()
        conflicts.extend(goal_conflicts)

        # ë¶ˆì•ˆì •ì„± íƒì§€
        stability_conflicts = await self._check_stability()
        conflicts.extend(stability_conflicts)

        return conflicts

    async def _generate_counter_arguments(self) -> List[Dict[str, Any]]:
        """ë°˜ë¡  ìƒì„±"""
        counter_arguments = []

        # ë…¼ë¦¬ì  ë°˜ë¡ 
        logical_counters = await self._generate_logical_counters()
        counter_arguments.extend(logical_counters)

        # ìœ¤ë¦¬ì  ë°˜ë¡ 
        ethical_counters = await self._generate_ethical_counters()
        counter_arguments.extend(ethical_counters)

        # ì‹¤ìš©ì  ë°˜ë¡ 
        practical_counters = await self._generate_practical_counters()
        counter_arguments.extend(practical_counters)

        return counter_arguments

    async def _redefine_problem(self) -> Optional[Dict[str, Any]]:
        """ë¬¸ì œ ì¬ì •ì˜"""
        if not self.internal_conflicts:
            return None

        # ì¶©ëŒ íŒ¨í„´ ë¶„ì„
        conflict_patterns = await self._analyze_conflict_patterns()

        # ë¬¸ì œ ì¬ì •ì˜
        reframed_problem = {
            "original_input": self.input_data,
            "conflict_patterns": conflict_patterns,
            "new_perspective": await self._generate_new_perspective(),
            "modified_premises": await self._modify_premises(),
        }

        return reframed_problem

    async def _evaluate_goal_validity(self) -> Dict[str, Any]:
        """ëª©í‘œ íƒ€ë‹¹ì„± í‰ê°€"""
        goal_evaluation = {
            "current_goal": self.current_goal,
            "validity_score": await self._calculate_goal_validity(),
            "needs_revision": False,
            "new_goal": None,
        }

        # ëª©í‘œ íƒ€ë‹¹ì„± ì ìˆ˜ê°€ ë‚®ìœ¼ë©´ ìˆ˜ì • í•„ìš”
        if goal_evaluation["validity_score"] < 0.6:
            goal_evaluation["needs_revision"] = True
            goal_evaluation["new_goal"] = await self._generate_new_goal()

        return goal_evaluation

    async def _make_decision(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²°ì • ìƒì„±"""
        # í˜„ì¬ ì‚¬ê³  ìƒíƒœë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²°ì • ìƒì„±
        decision = {
            "input_data": self.input_data,
            "context": self.context,
            "current_goal": self.current_goal,
            "thought_process": self.thought_history,
            "internal_conflicts": self.internal_conflicts,
            "decision_timestamp": datetime.now().isoformat(),
            "confidence_score": await self._calculate_confidence_score(),
        }

        return decision

    async def _calculate_reflection_score(self, decision: Dict[str, Any]) -> float:
        """ë‚´ë¶€ ëª¨ìˆœ ë° ë¶ˆì•ˆì •ì„± ê¸°ë°˜ ë°˜ì„± ì ìˆ˜"""
        # ë…¼ë¦¬ì  ì¼ê´€ì„±
        logical_consistency = await self._check_logical_consistency_score(decision)

        # ëª©í‘œ ì¼ì¹˜ë„
        goal_alignment = await self._check_goal_alignment_score(decision)

        # ë‚´ì  ì¶©ëŒ ì •ë„
        internal_conflicts_score = await self._calculate_internal_conflicts_score()

        # ì¢…í•© ë°˜ì„± ì ìˆ˜
        reflection_score = (logical_consistency + goal_alignment + (1.0 - internal_conflicts_score)) / 3.0

        return max(0.0, min(1.0, reflection_score))

    async def _reprocess_with_reflection(self, original_decision: Dict[str, Any]) -> None:
        """ë°˜ì„±ì„ í†µí•œ ì¬ì²˜ë¦¬"""
        logger.info("ğŸ”„ ë°˜ì„±ì„ í†µí•œ ì¬ì²˜ë¦¬ ì‹œì‘")

        # ë°˜ì„± ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ê³  ê³¼ì • ì¬ì¡°ì •
        reflection_insights = await self._generate_reflection_insights(original_decision)

        # ì‚¬ê³  ê³¼ì •ì— ë°˜ì„± í†µì°° ì¶”ê°€
        reflection_state = {
            "role": "reflection",
            "timestamp": datetime.now().isoformat(),
            "original_decision": original_decision,
            "reflection_insights": reflection_insights,
            "reprocessing_triggered": True,
        }

        self.thought_history.append(reflection_state)

        # ì¬ì²˜ë¦¬ ë¡œì§ ì‹¤í–‰
        await self._execute_reprocessing_logic(reflection_insights)

    async def _calculate_reflection_result(self, decision: Dict[str, Any]) -> ReflectionResult:
        """ë°˜ì„± ê²°ê³¼ ê³„ì‚°"""
        reflection_score = await self._calculate_reflection_score(decision)

        # ë°˜ì„± ìˆ˜ì¤€ ê²°ì •
        if reflection_score >= 0.9:
            level = ReflectionLevel.HIGH
        elif reflection_score >= 0.7:
            level = ReflectionLevel.MEDIUM
        elif reflection_score >= 0.5:
            level = ReflectionLevel.LOW
        else:
            level = ReflectionLevel.CRITICAL

        # ì¶©ëŒ ê°ì§€
        conflicts_detected = self.internal_conflicts.copy()

        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = await self._generate_recommendations(reflection_score, conflicts_detected)

        # ì¬ì²˜ë¦¬ í•„ìš” ì—¬ë¶€
        needs_reprocessing = reflection_score < self.REFLECTION_THRESHOLD

        return ReflectionResult(
            score=reflection_score,
            level=level,
            conflicts_detected=conflicts_detected,
            recommendations=recommendations,
            needs_reprocessing=needs_reprocessing,
        )

    # í—¬í¼ ë©”ì„œë“œë“¤ (êµ¬ì²´ì  êµ¬í˜„ì€ í•„ìš”ì— ë”°ë¼ í™•ì¥)
    async def _check_logical_consistency(self) -> List[Dict[str, Any]]:
        """ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬"""
        return []

    async def _check_goal_conflicts(self) -> List[Dict[str, Any]]:
        """ëª©í‘œ ì¶©ëŒ ê°ì§€"""
        return []

    async def _check_stability(self) -> List[Dict[str, Any]]:
        """ë¶ˆì•ˆì •ì„± íƒì§€"""
        return []

    async def _generate_logical_counters(self) -> List[Dict[str, Any]]:
        """ë…¼ë¦¬ì  ë°˜ë¡  ìƒì„±"""
        return []

    async def _generate_ethical_counters(self) -> List[Dict[str, Any]]:
        """ìœ¤ë¦¬ì  ë°˜ë¡  ìƒì„±"""
        return []

    async def _generate_practical_counters(self) -> List[Dict[str, Any]]:
        """ì‹¤ìš©ì  ë°˜ë¡  ìƒì„±"""
        return []

    async def _analyze_conflict_patterns(self) -> List[Dict[str, Any]]:
        """ì¶©ëŒ íŒ¨í„´ ë¶„ì„"""
        return []

    async def _generate_new_perspective(self) -> Dict[str, Any]:
        """ìƒˆë¡œìš´ ê´€ì  ìƒì„±"""
        return {}

    async def _modify_premises(self) -> List[Dict[str, Any]]:
        """ì „ì œ ìˆ˜ì •"""
        return []

    async def _calculate_goal_validity(self) -> float:
        """ëª©í‘œ íƒ€ë‹¹ì„± ê³„ì‚°"""
        return 0.8

    async def _generate_new_goal(self) -> str:
        """ìƒˆë¡œìš´ ëª©í‘œ ìƒì„±"""
        return "new_goal"

    async def _calculate_confidence_score(self) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        return 0.7

    async def _check_logical_consistency_score(self, decision: Dict[str, Any]) -> float:
        """ë…¼ë¦¬ì  ì¼ê´€ì„± ì ìˆ˜"""
        return 0.8

    async def _check_goal_alignment_score(self, decision: Dict[str, Any]) -> float:
        """ëª©í‘œ ì¼ì¹˜ë„ ì ìˆ˜"""
        return 0.8

    async def _calculate_internal_conflicts_score(self) -> float:
        """ë‚´ì  ì¶©ëŒ ì ìˆ˜"""
        return len(self.internal_conflicts) * 0.1

    async def _generate_reflection_insights(self, decision: Dict[str, Any]) -> List[str]:
        """ë°˜ì„± í†µì°° ìƒì„±"""
        return ["ê¸°ë³¸ ë°˜ì„± í†µì°°"]

    async def _execute_reprocessing_logic(self, insights: List[str]) -> None:
        """ì¬ì²˜ë¦¬ ë¡œì§ ì‹¤í–‰"""
        pass

    async def _generate_recommendations(self, reflection_score: float, conflicts: List[Dict[str, Any]]) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        if reflection_score < 0.5:
            recommendations.append("ì‚¬ê³  ê³¼ì •ì˜ ê·¼ë³¸ì  ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

        if conflicts:
            recommendations.append("ë‚´ë¶€ ì¶©ëŒ í•´ê²°ì„ ìœ„í•œ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        return recommendations


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í…ŒìŠ¤íŠ¸ìš© ì…ë ¥ ë°ì´í„°
    test_input = {
        "question": "DuRiëŠ” ì§„ì§œë¡œ ìƒê°í•  ìˆ˜ ìˆëŠ”ê°€?",
        "context": "AIì˜ ì‚¬ê³  ëŠ¥ë ¥ì— ëŒ€í•œ ì² í•™ì  ì§ˆë¬¸",
    }

    test_context = {
        "goal": "ì§„ì§œ ì‚¬ê³  ëŠ¥ë ¥ êµ¬í˜„",
        "user_expectation": "ìê¸° ë°˜ì„± ê°€ëŠ¥í•œ AI",
    }

    # DuRiThoughtFlow ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    thought_flow = DuRiThoughtFlow(test_input, test_context)

    # ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
    result = await thought_flow.process()

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ğŸ§  DuRiThoughtFlow ì‹¤í–‰ ê²°ê³¼")
    print("=" * 80)

    print("\nğŸ“Š ê¸°ë³¸ ì •ë³´:")
    print(f"  - ì„±ê³µ ì—¬ë¶€: {'âœ… ì„±ê³µ' if result.success else 'âŒ ì‹¤íŒ¨'}")
    print(f"  - ì²˜ë¦¬ ì‹œê°„: {result.processing_time:.2f}ì´ˆ")
    print(f"  - ë°˜ì„± ì ìˆ˜: {result.reflection_result.score:.2f}")
    print(f"  - ë°˜ì„± ìˆ˜ì¤€: {result.reflection_result.level.value}")

    print("\nğŸ¤” ì‚¬ê³  ê³¼ì •:")
    print(f"  - ì‚¬ê³  ë‹¨ê³„ ìˆ˜: {len(result.thought_process)}")
    print(f"  - ë‚´ë¶€ ì¶©ëŒ ìˆ˜: {len(result.internal_conflicts)}")

    print("\nğŸ¯ ìµœì¢… ê²°ì •:")
    print(f"  - ì‹ ë¢°ë„: {result.final_decision.get('confidence_score', 0):.2f}")
    print(f"  - ëª©í‘œ: {result.final_decision.get('current_goal', 'N/A')}")

    if result.reflection_result.recommendations:
        print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
        for rec in result.reflection_result.recommendations:
            print(f"  - {rec}")

    return result


if __name__ == "__main__":
    asyncio.run(main())
