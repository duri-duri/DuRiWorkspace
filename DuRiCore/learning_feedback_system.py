#!/usr/bin/env python3
"""
DuRi í•™ìŠµ í”¼ë“œë°± ì‹œìŠ¤í…œ (Day 6)
ì¼íšŒì„± íŒë‹¨ â†’ ì§€ì†ì  ê°œì„ ìœ¼ë¡œ ì „í™˜
"""

import asyncio
import json
import logging
import pickle
import re
import sqlite3
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class JudgmentType(Enum):
    """íŒë‹¨ ìœ í˜•"""

    ETHICAL = "ethical"
    PRACTICAL = "practical"
    LOGICAL = "logical"
    EMOTIONAL = "emotional"
    STRATEGIC = "strategic"


class FeedbackType(Enum):
    """í”¼ë“œë°± ìœ í˜•"""

    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    CORRECTIVE = "corrective"
    ENHANCING = "enhancing"


@dataclass
class JudgmentMemory:
    """íŒë‹¨ ê¸°ì–µ"""

    judgment_id: str
    situation: str
    judgment_type: JudgmentType
    reasoning_process: Dict[str, Any]
    conclusion: str
    confidence_score: float
    timestamp: datetime
    context_metadata: Dict[str, Any]


@dataclass
class FeedbackEntry:
    """í”¼ë“œë°± í•­ëª©"""

    feedback_id: str
    judgment_id: str
    feedback_type: FeedbackType
    content: str
    source: str
    impact_score: float  # 0.0-1.0
    timestamp: datetime
    metadata: Dict[str, Any]


@dataclass
class LearningPattern:
    """í•™ìŠµ íŒ¨í„´"""

    pattern_id: str
    pattern_type: str
    frequency: int
    success_rate: float
    last_occurrence: datetime
    improvement_suggestions: List[str]


class JudgmentMemorySystem:
    """íŒë‹¨ ê¸°ì–µ ì‹œìŠ¤í…œ"""

    def __init__(self, db_path: str = "judgment_memory.db"):
        self.db_path = db_path
        self.init_database()

    def init_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # íŒë‹¨ í…Œì´ë¸”
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS judgments (
                judgment_id TEXT PRIMARY KEY,
                situation TEXT,
                judgment_type TEXT,
                reasoning_process TEXT,
                conclusion TEXT,
                confidence_score REAL,
                timestamp TEXT,
                context_metadata TEXT
            )
        """
        )

        # í”¼ë“œë°± í…Œì´ë¸”
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS feedback (
                feedback_id TEXT PRIMARY KEY,
                judgment_id TEXT,
                feedback_type TEXT,
                content TEXT,
                source TEXT,
                impact_score REAL,
                timestamp TEXT,
                metadata TEXT,
                FOREIGN KEY (judgment_id) REFERENCES judgments (judgment_id)
            )
        """
        )

        # í•™ìŠµ íŒ¨í„´ í…Œì´ë¸”
        cursor.execute(
            """
            CREATE TABLE IF NOT EXISTS learning_patterns (
                pattern_id TEXT PRIMARY KEY,
                pattern_type TEXT,
                frequency INTEGER,
                success_rate REAL,
                last_occurrence TEXT,
                improvement_suggestions TEXT
            )
        """
        )

        conn.commit()
        conn.close()

    async def store_judgment(self, judgment: JudgmentMemory) -> bool:
        """íŒë‹¨ ì €ì¥"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT INTO judgments VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    judgment.judgment_id,
                    judgment.situation,
                    judgment.judgment_type.value,
                    json.dumps(judgment.reasoning_process),
                    judgment.conclusion,
                    judgment.confidence_score,
                    judgment.timestamp.isoformat(),
                    json.dumps(judgment.context_metadata),
                ),
            )

            conn.commit()
            conn.close()
            logger.info(f"íŒë‹¨ ì €ì¥ ì™„ë£Œ: {judgment.judgment_id}")
            return True
        except Exception as e:
            logger.error(f"íŒë‹¨ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False

    async def retrieve_similar_judgments(
        self, situation: str, limit: int = 5
    ) -> List[JudgmentMemory]:
        """ìœ ì‚¬í•œ íŒë‹¨ ê²€ìƒ‰"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ì„± ê²€ìƒ‰
            keywords = situation.split()
            placeholders = ",".join(["?" for _ in keywords])

            cursor.execute(
                f"""
                SELECT * FROM judgments
                WHERE situation LIKE '%' || ? || '%'
                ORDER BY confidence_score DESC
                LIMIT ?
            """,
                (keywords[0], limit),
            )

            results = cursor.fetchall()
            conn.close()

            judgments = []
            for row in results:
                judgment = JudgmentMemory(
                    judgment_id=row[0],
                    situation=row[1],
                    judgment_type=JudgmentType(row[2]),
                    reasoning_process=json.loads(row[3]),
                    conclusion=row[4],
                    confidence_score=row[5],
                    timestamp=datetime.fromisoformat(row[6]),
                    context_metadata=json.loads(row[7]),
                )
                judgments.append(judgment)

            return judgments
        except Exception as e:
            logger.error(f"ìœ ì‚¬í•œ íŒë‹¨ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    async def add_feedback(self, feedback: FeedbackEntry) -> bool:
        """í”¼ë“œë°± ì¶”ê°€"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                INSERT INTO feedback VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    feedback.feedback_id,
                    feedback.judgment_id,
                    feedback.feedback_type.value,
                    feedback.content,
                    feedback.source,
                    feedback.impact_score,
                    feedback.timestamp.isoformat(),
                    json.dumps(feedback.metadata),
                ),
            )

            conn.commit()
            conn.close()
            logger.info(f"í”¼ë“œë°± ì¶”ê°€ ì™„ë£Œ: {feedback.feedback_id}")
            return True
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False

    async def get_judgment_feedback(self, judgment_id: str) -> List[FeedbackEntry]:
        """íŒë‹¨ì— ëŒ€í•œ í”¼ë“œë°± ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                SELECT * FROM feedback WHERE judgment_id = ?
                ORDER BY timestamp DESC
            """,
                (judgment_id,),
            )

            results = cursor.fetchall()
            conn.close()

            feedback_entries = []
            for row in results:
                feedback = FeedbackEntry(
                    feedback_id=row[0],
                    judgment_id=row[1],
                    feedback_type=FeedbackType(row[2]),
                    content=row[3],
                    source=row[4],
                    impact_score=row[5],
                    timestamp=datetime.fromisoformat(row[6]),
                    metadata=json.loads(row[7]),
                )
                feedback_entries.append(feedback)

            return feedback_entries
        except Exception as e:
            logger.error(f"í”¼ë“œë°± ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []


class SelfImprovementSystem:
    """ìê¸° ê°œì„  ì‹œìŠ¤í…œ"""

    def __init__(self, memory_system: JudgmentMemorySystem):
        self.memory_system = memory_system
        self.improvement_patterns = self._initialize_improvement_patterns()
        self.learning_metrics = self._initialize_learning_metrics()

    def _initialize_improvement_patterns(self) -> Dict[str, Dict]:
        """ê°œì„  íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "confidence_improvement": {
                "pattern": "ì‹ ë¢°ë„ í–¥ìƒ",
                "threshold": 0.1,
                "suggestions": ["ë” ë§ì€ ë§¥ë½ ì •ë³´ ìˆ˜ì§‘", "ë‹¤ì¤‘ ê´€ì  ë¶„ì„ ê°•í™”"],
            },
            "reasoning_consistency": {
                "pattern": "ì¶”ë¡  ì¼ê´€ì„±",
                "threshold": 0.8,
                "suggestions": ["ë…¼ë¦¬ì  ë‹¨ê³„ ëª…í™•í™”", "ì „ì œ ê²€ì¦ ê°•í™”"],
            },
            "feedback_integration": {
                "pattern": "í”¼ë“œë°± í†µí•©",
                "threshold": 0.6,
                "suggestions": ["í”¼ë“œë°± ê¸°ë°˜ í•™ìŠµ", "íŒ¨í„´ ì¸ì‹ ê°œì„ "],
            },
            "situation_adaptation": {
                "pattern": "ìƒí™© ì ì‘",
                "threshold": 0.7,
                "suggestions": ["ìœ ì‚¬ ìƒí™© í•™ìŠµ", "ë§¥ë½ ë¶„ì„ ì •êµí™”"],
            },
        }

    def _initialize_learning_metrics(self) -> Dict[str, float]:
        """í•™ìŠµ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        return {
            "overall_improvement": 0.0,
            "confidence_trend": 0.0,
            "consistency_score": 0.0,
            "adaptation_rate": 0.0,
            "feedback_effectiveness": 0.0,
        }

    async def analyze_learning_progress(
        self, time_period: timedelta = timedelta(days=30)
    ) -> Dict[str, Any]:
        """í•™ìŠµ ì§„í–‰ë„ ë¶„ì„"""
        logger.info("í•™ìŠµ ì§„í–‰ë„ ë¶„ì„ ì‹œì‘")

        # ìµœê·¼ íŒë‹¨ë“¤ ì¡°íšŒ
        recent_judgments = await self._get_recent_judgments(time_period)

        # í•™ìŠµ ë©”íŠ¸ë¦­ ê³„ì‚°
        learning_metrics = await self._calculate_learning_metrics(recent_judgments)

        # ê°œì„  íŒ¨í„´ ì‹ë³„
        improvement_patterns = await self._identify_improvement_patterns(recent_judgments)

        # ê°œì„  ì œì•ˆ ìƒì„±
        improvement_suggestions = await self._generate_improvement_suggestions(
            learning_metrics, improvement_patterns
        )

        return {
            "learning_metrics": learning_metrics,
            "improvement_patterns": improvement_patterns,
            "improvement_suggestions": improvement_suggestions,
            "analysis_period": time_period,
        }

    async def _get_recent_judgments(self, time_period: timedelta) -> List[JudgmentMemory]:
        """ìµœê·¼ íŒë‹¨ë“¤ ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.memory_system.db_path)
            cursor = conn.cursor()

            cutoff_date = (datetime.now() - time_period).isoformat()

            cursor.execute(
                """
                SELECT * FROM judgments
                WHERE timestamp >= ?
                ORDER BY timestamp DESC
            """,
                (cutoff_date,),
            )

            results = cursor.fetchall()
            conn.close()

            judgments = []
            for row in results:
                judgment = JudgmentMemory(
                    judgment_id=row[0],
                    situation=row[1],
                    judgment_type=JudgmentType(row[2]),
                    reasoning_process=json.loads(row[3]),
                    conclusion=row[4],
                    confidence_score=row[5],
                    timestamp=datetime.fromisoformat(row[6]),
                    context_metadata=json.loads(row[7]),
                )
                judgments.append(judgment)

            return judgments
        except Exception as e:
            logger.error(f"ìµœê·¼ íŒë‹¨ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    async def _calculate_learning_metrics(
        self, judgments: List[JudgmentMemory]
    ) -> Dict[str, float]:
        """í•™ìŠµ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not judgments:
            return self.learning_metrics

        metrics = {}

        # ì „ì²´ ê°œì„ ë„
        confidence_scores = [j.confidence_score for j in judgments]
        metrics["overall_improvement"] = sum(confidence_scores) / len(confidence_scores)

        # ì‹ ë¢°ë„ íŠ¸ë Œë“œ
        if len(judgments) >= 2:
            recent_avg = sum(j.confidence_score for j in judgments[: len(judgments) // 2])
            older_avg = sum(j.confidence_score for j in judgments[len(judgments) // 2 :])
            metrics["confidence_trend"] = recent_avg - older_avg
        else:
            metrics["confidence_trend"] = 0.0

        # ì¼ê´€ì„± ì ìˆ˜
        judgment_types = [j.judgment_type for j in judgments]
        type_consistency = len(set(judgment_types)) / len(judgment_types)
        metrics["consistency_score"] = 1.0 - type_consistency

        # ì ì‘ë¥ 
        unique_situations = len(set(j.situation for j in judgments))
        metrics["adaptation_rate"] = unique_situations / len(judgments)

        # í”¼ë“œë°± íš¨ê³¼ì„±
        feedback_count = 0
        for judgment in judgments:
            feedback = await self.memory_system.get_judgment_feedback(judgment.judgment_id)
            feedback_count += len(feedback)

        metrics["feedback_effectiveness"] = min(feedback_count / len(judgments), 1.0)

        return metrics

    async def _identify_improvement_patterns(
        self, judgments: List[JudgmentMemory]
    ) -> List[Dict[str, Any]]:
        """ê°œì„  íŒ¨í„´ ì‹ë³„"""
        patterns = []

        if len(judgments) < 2:
            return patterns

        # ì‹ ë¢°ë„ í–¥ìƒ íŒ¨í„´
        recent_judgments = judgments[: len(judgments) // 2]
        older_judgments = judgments[len(judgments) // 2 :]

        recent_avg_confidence = sum(j.confidence_score for j in recent_judgments) / len(
            recent_judgments
        )
        older_avg_confidence = sum(j.confidence_score for j in older_judgments) / len(
            older_judgments
        )

        if recent_avg_confidence - older_avg_confidence > 0.1:
            patterns.append(
                {
                    "pattern_type": "confidence_improvement",
                    "description": "ì‹ ë¢°ë„ê°€ í–¥ìƒë˜ê³  ìˆìŒ",
                    "magnitude": recent_avg_confidence - older_avg_confidence,
                    "suggestions": self.improvement_patterns["confidence_improvement"][
                        "suggestions"
                    ],
                }
            )

        # ì¶”ë¡  ì¼ê´€ì„± íŒ¨í„´
        reasoning_consistency = self._calculate_reasoning_consistency(judgments)
        if reasoning_consistency > 0.8:
            patterns.append(
                {
                    "pattern_type": "reasoning_consistency",
                    "description": "ì¶”ë¡  ì¼ê´€ì„±ì´ ë†’ìŒ",
                    "magnitude": reasoning_consistency,
                    "suggestions": self.improvement_patterns["reasoning_consistency"][
                        "suggestions"
                    ],
                }
            )

        return patterns

    def _calculate_reasoning_consistency(self, judgments: List[JudgmentMemory]) -> float:
        """ì¶”ë¡  ì¼ê´€ì„± ê³„ì‚°"""
        if not judgments:
            return 0.0

        # ê°„ë‹¨í•œ ì¼ê´€ì„± ê³„ì‚°: ë™ì¼í•œ ìƒí™©ì— ëŒ€í•œ íŒë‹¨ì˜ ì¼ê´€ì„±
        situation_groups = {}
        for judgment in judgments:
            situation_key = judgment.situation[:50]  # ìƒí™©ì˜ ì²« 50ìë¡œ ê·¸ë£¹í™”
            if situation_key not in situation_groups:
                situation_groups[situation_key] = []
            situation_groups[situation_key].append(judgment)

        consistency_scores = []
        for group in situation_groups.values():
            if len(group) > 1:
                # ê°™ì€ ìƒí™©ì— ëŒ€í•œ íŒë‹¨ë“¤ì˜ ì‹ ë¢°ë„ ë¶„ì‚° ê³„ì‚°
                confidences = [j.confidence_score for j in group]
                variance = sum(
                    (c - sum(confidences) / len(confidences)) ** 2 for c in confidences
                ) / len(confidences)
                consistency_scores.append(1.0 - min(variance, 1.0))

        return sum(consistency_scores) / len(consistency_scores) if consistency_scores else 0.0

    async def _generate_improvement_suggestions(
        self, metrics: Dict[str, float], patterns: List[Dict[str, Any]]
    ) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""
        suggestions = []

        # ë©”íŠ¸ë¦­ ê¸°ë°˜ ì œì•ˆ
        if metrics["confidence_trend"] < 0:
            suggestions.append("ì‹ ë¢°ë„ í–¥ìƒì„ ìœ„í•´ ë” ë§ì€ ë§¥ë½ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”")

        if metrics["consistency_score"] < 0.7:
            suggestions.append("ì¶”ë¡  ì¼ê´€ì„± í–¥ìƒì„ ìœ„í•´ ë…¼ë¦¬ì  ë‹¨ê³„ë¥¼ ëª…í™•í™”í•˜ì„¸ìš”")

        if metrics["adaptation_rate"] < 0.5:
            suggestions.append("ìƒí™© ì ì‘ë ¥ì„ ë†’ì´ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ìƒí™©ì— ëŒ€í•œ í•™ìŠµì„ ê°•í™”í•˜ì„¸ìš”")

        if metrics["feedback_effectiveness"] < 0.3:
            suggestions.append("í”¼ë“œë°± í™œìš©ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ í”¼ë“œë°± ìˆ˜ì§‘ ë° ë¶„ì„ì„ ê°•í™”í•˜ì„¸ìš”")

        # íŒ¨í„´ ê¸°ë°˜ ì œì•ˆ
        for pattern in patterns:
            suggestions.extend(pattern["suggestions"])

        return list(set(suggestions))  # ì¤‘ë³µ ì œê±°


class AdaptiveLearningEngine:
    """ì ì‘ì  í•™ìŠµ ì—”ì§„"""

    def __init__(
        self,
        memory_system: JudgmentMemorySystem,
        improvement_system: SelfImprovementSystem,
    ):
        self.memory_system = memory_system
        self.improvement_system = improvement_system
        self.learning_rate = 0.1
        self.adaptation_threshold = 0.7

    async def adapt_to_feedback(self, judgment_id: str, feedback: FeedbackEntry) -> Dict[str, Any]:
        """í”¼ë“œë°±ì— ë”°ë¥¸ ì ì‘"""
        logger.info(f"í”¼ë“œë°± ì ì‘ ì‹œì‘: {judgment_id}")

        # ì›ë³¸ íŒë‹¨ ì¡°íšŒ
        original_judgment = await self._get_judgment_by_id(judgment_id)
        if not original_judgment:
            return {"success": False, "reason": "íŒë‹¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"}

        # í”¼ë“œë°± ë¶„ì„
        feedback_analysis = self._analyze_feedback_impact(feedback, original_judgment)

        # í•™ìŠµ íŒ¨í„´ ì—…ë°ì´íŠ¸
        learning_pattern = await self._update_learning_pattern(original_judgment, feedback)

        # ì ì‘ ì œì•ˆ ìƒì„±
        adaptation_suggestions = self._generate_adaptation_suggestions(
            feedback_analysis, learning_pattern
        )

        return {
            "success": True,
            "feedback_analysis": feedback_analysis,
            "learning_pattern": learning_pattern,
            "adaptation_suggestions": adaptation_suggestions,
        }

    async def _get_judgment_by_id(self, judgment_id: str) -> Optional[JudgmentMemory]:
        """IDë¡œ íŒë‹¨ ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.memory_system.db_path)
            cursor = conn.cursor()

            cursor.execute("SELECT * FROM judgments WHERE judgment_id = ?", (judgment_id,))
            result = cursor.fetchone()
            conn.close()

            if result:
                return JudgmentMemory(
                    judgment_id=result[0],
                    situation=result[1],
                    judgment_type=JudgmentType(result[2]),
                    reasoning_process=json.loads(result[3]),
                    conclusion=result[4],
                    confidence_score=result[5],
                    timestamp=datetime.fromisoformat(result[6]),
                    context_metadata=json.loads(result[7]),
                )

            return None
        except Exception as e:
            logger.error(f"íŒë‹¨ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def _analyze_feedback_impact(
        self, feedback: FeedbackEntry, judgment: JudgmentMemory
    ) -> Dict[str, Any]:
        """í”¼ë“œë°± ì˜í–¥ ë¶„ì„"""
        impact_analysis = {
            "impact_level": "low",
            "learning_potential": 0.0,
            "adaptation_needed": False,
            "key_insights": [],
        }

        # í”¼ë“œë°± íƒ€ì…ì— ë”°ë¥¸ ì˜í–¥ ë¶„ì„
        if feedback.feedback_type == FeedbackType.NEGATIVE:
            impact_analysis["impact_level"] = "high"
            impact_analysis["learning_potential"] = 0.8
            impact_analysis["adaptation_needed"] = True
            impact_analysis["key_insights"].append("ë¶€ì •ì  í”¼ë“œë°±ìœ¼ë¡œ ì¸í•œ ê°œì„  í•„ìš”")

        elif feedback.feedback_type == FeedbackType.CORRECTIVE:
            impact_analysis["impact_level"] = "medium"
            impact_analysis["learning_potential"] = 0.6
            impact_analysis["adaptation_needed"] = True
            impact_analysis["key_insights"].append("ìˆ˜ì •ì  í”¼ë“œë°±ìœ¼ë¡œ ì¸í•œ ì¡°ì • í•„ìš”")

        elif feedback.feedback_type == FeedbackType.ENHANCING:
            impact_analysis["impact_level"] = "medium"
            impact_analysis["learning_potential"] = 0.5
            impact_analysis["adaptation_needed"] = False
            impact_analysis["key_insights"].append("í–¥ìƒì  í”¼ë“œë°±ìœ¼ë¡œ ì¸í•œ ê°œì„  ê¸°íšŒ")

        # ì‹ ë¢°ë„ì™€ í”¼ë“œë°±ì˜ ê´€ê³„ ë¶„ì„
        if judgment.confidence_score > 0.8 and feedback.impact_score > 0.7:
            impact_analysis["key_insights"].append(
                "ë†’ì€ ì‹ ë¢°ë„ì—ë„ ë¶ˆêµ¬í•˜ê³  í”¼ë“œë°±ì´ ìˆìŒ - ì¬ê²€í†  í•„ìš”"
            )

        return impact_analysis

    async def _update_learning_pattern(
        self, judgment: JudgmentMemory, feedback: FeedbackEntry
    ) -> LearningPattern:
        """í•™ìŠµ íŒ¨í„´ ì—…ë°ì´íŠ¸"""
        pattern_id = f"pattern_{judgment.judgment_type.value}_{feedback.feedback_type.value}"

        # ê¸°ì¡´ íŒ¨í„´ ì¡°íšŒ ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        try:
            conn = sqlite3.connect(self.memory_system.db_path)
            cursor = conn.cursor()

            cursor.execute(
                """
                SELECT * FROM learning_patterns WHERE pattern_id = ?
            """,
                (pattern_id,),
            )

            result = cursor.fetchone()

            if result:
                # ê¸°ì¡´ íŒ¨í„´ ì—…ë°ì´íŠ¸
                frequency = result[2] + 1
                success_rate = (result[3] * (frequency - 1) + feedback.impact_score) / frequency

                cursor.execute(
                    """
                    UPDATE learning_patterns
                    SET frequency = ?, success_rate = ?, last_occurrence = ?
                    WHERE pattern_id = ?
                """,
                    (frequency, success_rate, datetime.now().isoformat(), pattern_id),
                )
            else:
                # ìƒˆ íŒ¨í„´ ìƒì„±
                cursor.execute(
                    """
                    INSERT INTO learning_patterns VALUES (?, ?, ?, ?, ?, ?)
                """,
                    (
                        pattern_id,
                        f"{judgment.judgment_type.value}_{feedback.feedback_type.value}",
                        1,
                        feedback.impact_score,
                        datetime.now().isoformat(),
                        json.dumps([]),
                    ),
                )

            conn.commit()
            conn.close()

            return LearningPattern(
                pattern_id=pattern_id,
                pattern_type=f"{judgment.judgment_type.value}_{feedback.feedback_type.value}",
                frequency=result[2] + 1 if result else 1,
                success_rate=success_rate if result else feedback.impact_score,
                last_occurrence=datetime.now(),
                improvement_suggestions=[],
            )

        except Exception as e:
            logger.error(f"í•™ìŠµ íŒ¨í„´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return LearningPattern(
                pattern_id=pattern_id,
                pattern_type="unknown",
                frequency=1,
                success_rate=0.0,
                last_occurrence=datetime.now(),
                improvement_suggestions=[],
            )

    def _generate_adaptation_suggestions(
        self, feedback_analysis: Dict[str, Any], learning_pattern: LearningPattern
    ) -> List[str]:
        """ì ì‘ ì œì•ˆ ìƒì„±"""
        suggestions = []

        if feedback_analysis["adaptation_needed"]:
            suggestions.append("í”¼ë“œë°±ì„ ë°˜ì˜í•˜ì—¬ íŒë‹¨ ê¸°ì¤€ì„ ì¡°ì •í•˜ì„¸ìš”")
            suggestions.append("ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ë” ì‹ ì¤‘í•œ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”")

        if learning_pattern.success_rate < 0.5:
            suggestions.append("í•´ë‹¹ íŒ¨í„´ì˜ ì„±ê³µë¥ ì´ ë‚®ìœ¼ë¯€ë¡œ ì ‘ê·¼ ë°©ì‹ì„ ì¬ê²€í† í•˜ì„¸ìš”")

        if learning_pattern.frequency > 5:
            suggestions.append("ë°˜ë³µë˜ëŠ” íŒ¨í„´ì´ë¯€ë¡œ ì²´ê³„ì ì¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤")

        return suggestions


async def test_learning_feedback_system():
    """í•™ìŠµ í”¼ë“œë°± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=== í•™ìŠµ í”¼ë“œë°± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Day 6) ===")

    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    memory_system = JudgmentMemorySystem()
    improvement_system = SelfImprovementSystem(memory_system)
    learning_engine = AdaptiveLearningEngine(memory_system, improvement_system)

    # í…ŒìŠ¤íŠ¸ íŒë‹¨ ì €ì¥
    test_judgment = JudgmentMemory(
        judgment_id="test_judgment_001",
        situation="ê±°ì§“ë§ì„ í•´ì•¼ í•˜ëŠ” ìƒí™©",
        judgment_type=JudgmentType.ETHICAL,
        reasoning_process={
            "semantic_analysis": {"situation_type": "ethical_dilemma"},
            "philosophical_analysis": {"kantian": "ê¸ˆì§€", "utilitarian": "ê¸ˆì§€"},
        },
        conclusion="ê±°ì§“ë§ì€ ë„ë•ì ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠëŠ”ë‹¤",
        confidence_score=0.8,
        timestamp=datetime.now(),
        context_metadata={"complexity": "high", "urgency": "medium"},
    )

    await memory_system.store_judgment(test_judgment)

    # í…ŒìŠ¤íŠ¸ í”¼ë“œë°± ì¶”ê°€
    test_feedback = FeedbackEntry(
        feedback_id="test_feedback_001",
        judgment_id="test_judgment_001",
        feedback_type=FeedbackType.CORRECTIVE,
        content="ìƒí™©ì˜ ë§¥ë½ì„ ë” ê³ ë ¤í•´ì•¼ í•œë‹¤",
        source="human_expert",
        impact_score=0.7,
        timestamp=datetime.now(),
        metadata={"expertise_level": "high"},
    )

    await memory_system.add_feedback(test_feedback)

    # í•™ìŠµ ì§„í–‰ë„ ë¶„ì„
    learning_progress = await improvement_system.analyze_learning_progress()

    print(f"\nğŸ“Š í•™ìŠµ ì§„í–‰ë„ ë¶„ì„:")
    print(f"  â€¢ ì „ì²´ ê°œì„ ë„: {learning_progress['learning_metrics']['overall_improvement']:.2f}")
    print(f"  â€¢ ì‹ ë¢°ë„ íŠ¸ë Œë“œ: {learning_progress['learning_metrics']['confidence_trend']:.2f}")
    print(f"  â€¢ ì¼ê´€ì„± ì ìˆ˜: {learning_progress['learning_metrics']['consistency_score']:.2f}")
    print(f"  â€¢ ì ì‘ë¥ : {learning_progress['learning_metrics']['adaptation_rate']:.2f}")
    print(
        f"  â€¢ í”¼ë“œë°± íš¨ê³¼ì„±: {learning_progress['learning_metrics']['feedback_effectiveness']:.2f}"
    )

    print(f"\nğŸ” ê°œì„  íŒ¨í„´:")
    for pattern in learning_progress["improvement_patterns"]:
        print(f"  â€¢ {pattern['pattern_type']}: {pattern['description']}")

    print(f"\nğŸ’¡ ê°œì„  ì œì•ˆ:")
    for suggestion in learning_progress["improvement_suggestions"]:
        print(f"  â€¢ {suggestion}")

    # í”¼ë“œë°± ì ì‘ í…ŒìŠ¤íŠ¸
    adaptation_result = await learning_engine.adapt_to_feedback("test_judgment_001", test_feedback)

    print(f"\nğŸ”„ í”¼ë“œë°± ì ì‘ ê²°ê³¼:")
    print(f"  â€¢ ì„±ê³µ: {adaptation_result['success']}")
    print(f"  â€¢ ì˜í–¥ ìˆ˜ì¤€: {adaptation_result['feedback_analysis']['impact_level']}")
    print(f"  â€¢ í•™ìŠµ ì ì¬ë ¥: {adaptation_result['feedback_analysis']['learning_potential']:.2f}")
    print(f"  â€¢ ì ì‘ í•„ìš”: {adaptation_result['feedback_analysis']['adaptation_needed']}")

    print(f"\nğŸ“ ì ì‘ ì œì•ˆ:")
    for suggestion in adaptation_result["adaptation_suggestions"]:
        print(f"  â€¢ {suggestion}")

    print(f"\n{'='*70}")
    print("=== í•™ìŠµ í”¼ë“œë°± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Day 6) ===")
    print("âœ… Day 6 ëª©í‘œ ë‹¬ì„±: ì¼íšŒì„± íŒë‹¨ â†’ ì§€ì†ì  ê°œì„ ")
    print("âœ… íŒë‹¨ ê¸°ì–µ ì‹œìŠ¤í…œ ë° ìê¸° ê°œì„  ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ì ì‘ì  í•™ìŠµ ì—”ì§„ ë° í”¼ë“œë°± í†µí•© ì‹œìŠ¤í…œ êµ¬í˜„")


if __name__ == "__main__":
    asyncio.run(test_learning_feedback_system())
