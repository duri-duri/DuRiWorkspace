#!/usr/bin/env python3
"""
DuRi ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œ
ìƒí™© ê°ì§€, ëª¨ë“ˆ ë¼ìš°íŒ…, ìì› ë¶„ë°°, í”„ë¦¬í˜ì¹˜ë¥¼ í†µí•©í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import json
import os
import sys
from datetime import datetime
from typing import Any, Dict, List, Optional

# DuRiCore ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.evolution.self_evolution_manager import SelfEvolutionManager
from modules.integrated_learning_system import IntegratedLearningSystem
from modules.judgment_system.judgment_trace_logger import JudgmentTraceLogger
from modules.thought_flow.du_ri_thought_flow import DuRiThoughtFlow

# ğŸ“¦ í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ (í˜„ì¬ êµ¬í˜„ëœ ì‹œìŠ¤í…œì— ë§ê²Œ ìˆ˜ì •)
from modules.thought_flow.self_reflection_loop import SelfReflectionLoop


class ContextSentinel:
    """ìƒí™© ê°ì§€ ë° ë§¥ë½ íŒë‹¨ ì‹œìŠ¤í…œ"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ContextSentinel, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "initialized"):
            self.context_history = []
            self.thought_flow = DuRiThoughtFlow()
            self.initialized = True

    def detect_context(self, context_type: str) -> List[Dict[str, Any]]:
        """
        ì£¼ì–´ì§„ ë§¥ë½ íƒ€ì…ì— ëŒ€í•œ í™œì„± ë§¥ë½ë“¤ì„ ê°ì§€í•©ë‹ˆë‹¤.

        Args:
            context_type: ê°ì§€í•  ë§¥ë½ íƒ€ì…

        Returns:
            ê°ì§€ëœ í™œì„± ë§¥ë½ë“¤
        """
        print(f"ğŸ” ë§¥ë½ ê°ì§€ ì‹œì‘: {context_type}")

        # ë§¥ë½ ê°ì§€ ë¡œì§
        active_contexts = [
            {
                "context_type": context_type,
                "timestamp": datetime.now().isoformat(),
                "priority": "high",
                "status": "active",
                "description": f"{context_type} ê´€ë ¨ ë§¥ë½ ê°ì§€ë¨",
            }
        ]

        # ì‚¬ê³  íë¦„ì— ë§¥ë½ ê°ì§€ ê¸°ë¡
        context_summary = {
            "detection_type": context_type,
            "active_contexts": active_contexts,
            "timestamp": datetime.now().isoformat(),
        }

        self.thought_flow.register_stream("context_detection", context_summary)

        print(f"âœ… ë§¥ë½ ê°ì§€ ì™„ë£Œ: {len(active_contexts)}ê°œ ë§¥ë½ ê°ì§€ë¨")

        return active_contexts


class ModuleRouter:
    """ëª¨ë“ˆ ë¼ìš°íŒ… ì‹œìŠ¤í…œ"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ModuleRouter, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "initialized"):
            self.routing_history = []
            self.thought_flow = DuRiThoughtFlow()
            self.initialized = True

    def route(self, active_contexts: List[Dict[str, Any]]) -> List[str]:
        """
        í™œì„± ë§¥ë½ì— ë”°ë¼ í™œì„±í™”í•  ëª¨ë“ˆë“¤ì„ ì„ íƒí•©ë‹ˆë‹¤.

        Args:
            active_contexts: í™œì„± ë§¥ë½ë“¤

        Returns:
            í™œì„±í™”ëœ ëª¨ë“ˆ ëª©ë¡
        """
        print(f"ğŸ”§ ëª¨ë“ˆ ë¼ìš°íŒ… ì‹œì‘: {len(active_contexts)}ê°œ ë§¥ë½")

        # ë§¥ë½ì— ë”°ë¥¸ ëª¨ë“ˆ ì„ íƒ ë¡œì§
        active_modules = []

        for context in active_contexts:
            context_type = context.get("context_type", "")

            if "strategic_judgment" in context_type:
                active_modules.extend(
                    [
                        "SelfReflection",
                        "GrowthLoop",
                        "JudgmentTrace",
                        "ContextSentinel",
                        "ModuleRouter",
                        "CognitiveResourceAllocator",
                        "PrefetchMemoryMap",
                    ]
                )

        # ì¤‘ë³µ ì œê±°
        active_modules = list(set(active_modules))

        # ì‚¬ê³  íë¦„ì— ë¼ìš°íŒ… ê²°ê³¼ ê¸°ë¡
        routing_summary = {
            "active_contexts": active_contexts,
            "active_modules": active_modules,
            "timestamp": datetime.now().isoformat(),
        }

        self.thought_flow.register_stream("module_routing", routing_summary)

        print(f"âœ… ëª¨ë“ˆ ë¼ìš°íŒ… ì™„ë£Œ: {len(active_modules)}ê°œ ëª¨ë“ˆ í™œì„±í™”")

        return active_modules


class CognitiveResourceAllocator:
    """ì¸ì§€ ìì› ë¶„ë°° ì‹œìŠ¤í…œ"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(CognitiveResourceAllocator, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "initialized"):
            self.allocation_history = []
            self.thought_flow = DuRiThoughtFlow()
            self.initialized = True

    def allocate(self, active_modules: List[str]) -> Dict[str, float]:
        """
        í™œì„± ëª¨ë“ˆë“¤ì— ì¸ì§€ ìì›ì„ ë¶„ë°°í•©ë‹ˆë‹¤.

        Args:
            active_modules: í™œì„± ëª¨ë“ˆ ëª©ë¡

        Returns:
            ìì› ë¶„ë°° ê²°ê³¼
        """
        print(f"ğŸ§  ìì› ë¶„ë°° ì‹œì‘: {len(active_modules)}ê°œ ëª¨ë“ˆ")

        # ìì› ë¶„ë°° ë¡œì§
        allocation = {}
        total_modules = len(active_modules)

        if total_modules > 0:
            base_allocation = 1.0 / total_modules

            for module in active_modules:
                # ëª¨ë“ˆë³„ ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ìì› ë¶„ë°°
                if module in ["SelfReflection", "GrowthLoop", "JudgmentTrace"]:
                    allocation[module] = (
                        base_allocation * 1.5
                    )  # í•µì‹¬ ëª¨ë“ˆì€ ë” ë§ì€ ìì›
                else:
                    allocation[module] = base_allocation

        # ì‚¬ê³  íë¦„ì— ìì› ë¶„ë°° ê²°ê³¼ ê¸°ë¡
        allocation_summary = {
            "active_modules": active_modules,
            "allocation": allocation,
            "timestamp": datetime.now().isoformat(),
        }

        self.thought_flow.register_stream("resource_allocation", allocation_summary)

        print(f"âœ… ìì› ë¶„ë°° ì™„ë£Œ: {len(allocation)}ê°œ ëª¨ë“ˆì— ìì› í• ë‹¹")

        return allocation


class PrefetchMemoryMap:
    """í”„ë¦¬í˜ì¹˜ ë©”ëª¨ë¦¬ ë§µ ì‹œìŠ¤í…œ"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(PrefetchMemoryMap, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "initialized"):
            self.prefetch_history = []
            self.thought_flow = DuRiThoughtFlow()
            self.initialized = True

    def prefetch(self, active_modules: List[str]) -> Dict[str, Any]:
        """
        í™œì„± ëª¨ë“ˆë“¤ì˜ ì¡°í•©ì„ ì‚¬ì „ ë¡œë”©í•©ë‹ˆë‹¤.

        Args:
            active_modules: í™œì„± ëª¨ë“ˆ ëª©ë¡

        Returns:
            í”„ë¦¬í˜ì¹˜ ê²°ê³¼
        """
        print(f"ğŸš€ í”„ë¦¬í˜ì¹˜ ì‹œì‘: {len(active_modules)}ê°œ ëª¨ë“ˆ")

        # í”„ë¦¬í˜ì¹˜ ë¡œì§
        prefetch_result = {
            "prefetched_modules": active_modules,
            "prefetch_status": "completed",
            "timestamp": datetime.now().isoformat(),
        }

        # ì‚¬ê³  íë¦„ì— í”„ë¦¬í˜ì¹˜ ê²°ê³¼ ê¸°ë¡
        self.thought_flow.register_stream("prefetch_memory", prefetch_result)

        print(f"âœ… í”„ë¦¬í˜ì¹˜ ì™„ë£Œ: {len(active_modules)}ê°œ ëª¨ë“ˆ ì‚¬ì „ ë¡œë”©")

        return prefetch_result


class SelfReflection:
    """ìê°€ ë°˜ì„± ì‹œìŠ¤í…œ (ê¸°ì¡´ê³¼ ë™ì¼)"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(SelfReflection, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "initialized"):
            self.reflection_loop = SelfReflectionLoop()
            self.thought_flow = DuRiThoughtFlow()
            self.initialized = True

    @classmethod
    def self_reflection_sync(cls, trigger: str = "user_request") -> Dict[str, Any]:
        """ìê°€ ë°˜ì„± ë™ê¸°í™”ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        instance = cls()
        print(f"ğŸª ìê°€ ë°˜ì„± ë™ê¸°í™” ì‹œì‘ (íŠ¸ë¦¬ê±°: {trigger})")

        try:
            reflection_result = instance.reflection_loop.reflection_loop(trigger)

            reflection_summary = {
                "trigger": trigger,
                "timestamp": datetime.now().isoformat(),
                "reflection_result": reflection_result,
                "status": "synchronized",
            }

            instance.thought_flow.register_stream(
                "self_reflection_sync", reflection_summary
            )

            print(
                f"âœ… ìê°€ ë°˜ì„± ë™ê¸°í™” ì™„ë£Œ: {reflection_result.get('new_insights', 0)}ê°œ í†µì°° ìƒì„±"
            )

            return reflection_summary

        except Exception as e:
            print(f"âŒ ìê°€ ë°˜ì„± ë™ê¸°í™” ì‹¤íŒ¨: {e}")
            return {"status": "failed", "error": str(e)}


class GrowthLoop:
    """ì„±ì¥ ë£¨í”„ ì‹œìŠ¤í…œ (ê¸°ì¡´ê³¼ ë™ì¼)"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GrowthLoop, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "initialized"):
            self.evolution_manager = SelfEvolutionManager()
            self.thought_flow = DuRiThoughtFlow()
            self.initialized = True

    @classmethod
    def growth_loop_trigger(cls, source: str = "user_request") -> Dict[str, Any]:
        """ì„±ì¥ ë£¨í”„ë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤."""
        instance = cls()
        print(f"ğŸŒ± ì„±ì¥ ë£¨í”„ íŠ¸ë¦¬ê±° ì‹œì‘ (ì†ŒìŠ¤: {source})")

        try:
            evolution_result = (
                instance.evolution_manager.execute_self_improvement_sequence()
            )

            growth_summary = {
                "source": source,
                "timestamp": datetime.now().isoformat(),
                "evolution_result": evolution_result,
                "status": "triggered",
            }

            instance.thought_flow.register_stream("growth_loop_trigger", growth_summary)

            print(
                f"âœ… ì„±ì¥ ë£¨í”„ íŠ¸ë¦¬ê±° ì™„ë£Œ: {evolution_result.get('evolution_steps', 0)}ê°œ ì§„í™” ë‹¨ê³„"
            )

            return growth_summary

        except Exception as e:
            print(f"âŒ ì„±ì¥ ë£¨í”„ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
            return {"status": "failed", "error": str(e)}


class JudgmentTrace:
    """íŒë‹¨ ì‹œê°í™” ì‹œìŠ¤í…œ (ê¸°ì¡´ê³¼ ë™ì¼)"""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(JudgmentTrace, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, "initialized"):
            self.judgment_logger = JudgmentTraceLogger()
            self.thought_flow = DuRiThoughtFlow()
            self.initialized = True

    @classmethod
    def visualize(cls, trace_type: str = "all") -> Dict[str, Any]:
        """íŒë‹¨ ì‹œê°í™”ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        instance = cls()
        print(f"ğŸ” íŒë‹¨ ì‹œê°í™” ì‹œì‘ (íƒ€ì…: {trace_type})")

        try:
            traces_summary = instance.judgment_logger.get_traces_summary()
            recent_traces = instance.judgment_logger.get_recent_traces(limit=10)

            visualization_data = {
                "trace_type": trace_type,
                "timestamp": datetime.now().isoformat(),
                "summary": traces_summary,
                "recent_traces": [
                    {
                        "timestamp": trace.timestamp,
                        "context": trace.context,
                        "judgment": trace.judgment,
                        "confidence_level": trace.confidence_level,
                        "tags": trace.tags,
                    }
                    for trace in recent_traces
                ],
                "visualization_type": "judgment_trace_analysis",
            }

            instance.thought_flow.register_stream(
                "judgment_visualization", visualization_data
            )

            print(f"âœ… íŒë‹¨ ì‹œê°í™” ì™„ë£Œ: {len(recent_traces)}ê°œ ìµœê·¼ ê¸°ë¡ ë¶„ì„")

            return visualization_data

        except Exception as e:
            print(f"âŒ íŒë‹¨ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return {"status": "failed", "error": str(e)}


def run(tag="strategic_judgment"):
    """
    ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜

    Args:
        tag: ì‹¤í–‰ íƒœê·¸ (ê¸°ë³¸ê°’: "strategic_judgment")
    """
    print(f"\n[START] Running advanced cognitive system for tag: {tag}\n")

    try:
        # 1ë‹¨ê³„: ë§¥ë½ ê°ì§€
        print("=" * 50)
        print("[1] ë§¥ë½ ê°ì§€ ì‹œì‘")
        print("=" * 50)
        context = ContextSentinel().detect_context(tag)
        print(f"[1] Context detected: {context}")

    except Exception as e:
        print(f"âŒ [1ë‹¨ê³„] ë§¥ë½ ê°ì§€ ì‹¤íŒ¨: {e}")
        context = []

    try:
        # 2ë‹¨ê³„: ëª¨ë“ˆ ì„ íƒ
        print("\n" + "=" * 50)
        print("[2] ëª¨ë“ˆ ì„ íƒ ì‹œì‘")
        print("=" * 50)
        active_modules = ModuleRouter().route(context)
        print(f"[2] Active modules: {active_modules}")

    except Exception as e:
        print(f"âŒ [2ë‹¨ê³„] ëª¨ë“ˆ ì„ íƒ ì‹¤íŒ¨: {e}")
        active_modules = []

    try:
        # 3ë‹¨ê³„: ìì› ë¶„ë°°
        print("\n" + "=" * 50)
        print("[3] ìì› ë¶„ë°° ì‹œì‘")
        print("=" * 50)
        status = CognitiveResourceAllocator().allocate(active_modules)
        print(f"[3] Resource allocation status: {status}")

    except Exception as e:
        print(f"âŒ [3ë‹¨ê³„] ìì› ë¶„ë°° ì‹¤íŒ¨: {e}")
        status = {}

    try:
        # 4ë‹¨ê³„: ë©”ëª¨ë¦¬ ì‚¬ì „ ë¡œë”©
        print("\n" + "=" * 50)
        print("[4] ë©”ëª¨ë¦¬ ì‚¬ì „ ë¡œë”© ì‹œì‘")
        print("=" * 50)
        cached = PrefetchMemoryMap().prefetch(active_modules)
        print(f"[4] Prefetch result: {cached}")

    except Exception as e:
        print(f"âŒ [4ë‹¨ê³„] ë©”ëª¨ë¦¬ ì‚¬ì „ ë¡œë”© ì‹¤íŒ¨: {e}")
        cached = {}

    try:
        # 5ë‹¨ê³„: ìê°€ ë°˜ì„±
        print("\n" + "=" * 50)
        print("[5] ìê°€ ë°˜ì„± ì‹œì‘")
        print("=" * 50)
        reflection = SelfReflection.self_reflection_sync(trigger=tag)
        print(f"[5] Self-reflection: {reflection}")

    except Exception as e:
        print(f"âŒ [5ë‹¨ê³„] ìê°€ ë°˜ì„± ì‹¤íŒ¨: {e}")
        reflection = {"status": "failed", "error": str(e)}

    try:
        # 6ë‹¨ê³„: ì„±ì¥ ë£¨í”„
        print("\n" + "=" * 50)
        print("[6] ì„±ì¥ ë£¨í”„ ì‹œì‘")
        print("=" * 50)
        result = GrowthLoop.growth_loop_trigger(source=tag)
        print(f"[6] Growth result: {result}")

    except Exception as e:
        print(f"âŒ [6ë‹¨ê³„] ì„±ì¥ ë£¨í”„ ì‹¤íŒ¨: {e}")
        result = {"status": "failed", "error": str(e)}

    try:
        # 7ë‹¨ê³„: íŒë‹¨ ì‹œê°í™”
        print("\n" + "=" * 50)
        print("[7] íŒë‹¨ ì‹œê°í™” ì‹œì‘")
        print("=" * 50)
        trace = JudgmentTrace.visualize(tag)
        print(f"[7] Judgment trace: {trace}")

    except Exception as e:
        print(f"âŒ [7ë‹¨ê³„] íŒë‹¨ ì‹œê°í™” ì‹¤íŒ¨: {e}")
        trace = {"status": "failed", "error": str(e)}

    # ğŸ“Š ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
    execution_summary = {
        "timestamp": datetime.now().isoformat(),
        "tag": tag,
        "context": context,
        "active_modules": active_modules,
        "resource_allocation": status,
        "prefetch_result": cached,
        "reflection_result": reflection,
        "growth_result": result,
        "visualization_result": trace,
        "execution_status": "completed",
    }

    print(f"\n[END] Cognitive system run complete.\n")
    print("=" * 60)
    print("ğŸ‰ ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“… ì‹¤í–‰ ì‹œê°„: {execution_summary['timestamp']}")
    print(f"ğŸ·ï¸ ì‹¤í–‰ íƒœê·¸: {execution_summary['tag']}")
    print(f"ğŸ§  ê°ì§€ëœ ë§¥ë½: {len(execution_summary['context'])}ê°œ")
    print(f"âš™ï¸ í™œì„±í™”ëœ ëª¨ë“ˆ: {len(execution_summary['active_modules'])}ê°œ")
    print(f"ğŸ”‹ ìì› ë¶„ë°°: {len(execution_summary['resource_allocation'])}ê°œ ëª¨ë“ˆ")
    print(f"ğŸ—ºï¸ í”„ë¦¬í˜ì¹˜: {len(execution_summary['active_modules'])}ê°œ ëª¨ë“ˆ")
    print(
        f"ğŸª ìê°€ ë°˜ì„±: {execution_summary['reflection_result'].get('status', 'unknown')}"
    )
    print(
        f"ğŸŒ± ì„±ì¥ ë£¨í”„: {execution_summary['growth_result'].get('status', 'unknown')}"
    )
    print(
        f"ğŸ” íŒë‹¨ ì‹œê°í™”: {execution_summary['visualization_result'].get('status', 'unknown')}"
    )
    print(f"ğŸ¯ ì‹¤í–‰ ìƒíƒœ: {execution_summary['execution_status']}")
    print("=" * 60)

    return execution_summary


def execute_advanced_cognitive_system():
    """
    ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜ (ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€)
    """
    return run("strategic_judgment")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ DuRi ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œ ì‹¤í–‰")

    # ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œ ì‹¤í–‰
    result = run("strategic_judgment")

    if result.get("execution_status") == "completed":
        print(f"\nâœ… ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œ ì„±ê³µ!")
        return True
    else:
        print(f"\nâŒ ê³ ê¸‰ ì¸ì§€ ì‹œìŠ¤í…œ ì‹¤íŒ¨!")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
