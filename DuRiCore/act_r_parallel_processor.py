#!/usr/bin/env python3
"""
ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
DuRi Phase 6.1 - ì„±ëŠ¥ 23% í–¥ìƒ ëª©í‘œ

ê¸°ëŠ¥:
1. asyncio.gatherë¥¼ í™œìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
2. ì‘ì—… ìš°ì„ ìˆœìœ„ ê´€ë¦¬
3. ë¦¬ì†ŒìŠ¤ ìµœì í™”
4. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import asyncio
import logging
import statistics
import time
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class TaskPriority(Enum):
    """ì‘ì—… ìš°ì„ ìˆœìœ„"""

    CRITICAL = 1
    HIGH = 2
    MEDIUM = 3
    LOW = 4


class TaskStatus(Enum):
    """ì‘ì—… ìƒíƒœ"""

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class ParallelTask:
    """ë³‘ë ¬ ì‘ì—… ì •ë³´"""

    id: str
    name: str
    function: Callable
    args: tuple = ()
    kwargs: dict = None
    priority: TaskPriority = TaskPriority.MEDIUM
    status: TaskStatus = TaskStatus.PENDING
    created_at: datetime = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Any = None
    error: Optional[str] = None
    execution_time: float = 0.0

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.kwargs is None:
            self.kwargs = {}


class ACTRParallelProcessor:
    """ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self, max_concurrent_tasks: int = 10):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.active_tasks: Dict[str, ParallelTask] = {}
        self.completed_tasks: List[ParallelTask] = []
        self.task_queue: List[ParallelTask] = []
        self.performance_metrics = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "average_execution_time": 0.0,
            "parallel_efficiency": 0.0,
            "performance_improvement": 0.0,
        }
        self.execution_history = []

        # ì„±ëŠ¥ ì¸¡ì •ìš©
        self.baseline_execution_time = 0.104  # í˜„ì¬ ê¸°ì¤€ ì‹œê°„
        self.target_execution_time = 0.08  # ëª©í‘œ ì‹œê°„ (23% í–¥ìƒ)

        logger.info("ğŸš€ ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def execute_parallel_tasks(self, tasks: List[ParallelTask]) -> List[Any]:
        """ë³‘ë ¬ ì‘ì—… ì‹¤í–‰"""
        logger.info(f"âš¡ {len(tasks)}ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘")

        start_time = time.time()

        try:
            # ì‘ì—…ì„ ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬
            sorted_tasks = sorted(tasks, key=lambda x: x.priority.value)

            # ë³‘ë ¬ ì‹¤í–‰ì„ ìœ„í•œ ì½”ë£¨í‹´ ìƒì„±
            coroutines = []
            for task in sorted_tasks:
                coroutine = self._execute_single_task(task)
                coroutines.append(coroutine)

            # asyncio.gatherë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì‹¤í–‰
            results = await asyncio.gather(*coroutines, return_exceptions=True)

            execution_time = time.time() - start_time

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self._update_performance_metrics(execution_time, len(tasks))

            logger.info(f"âœ… ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ: {execution_time:.3f}ì´ˆ")
            return results

        except Exception as e:
            logger.error(f"âŒ ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []

    async def _execute_single_task(self, task: ParallelTask) -> Any:
        """ë‹¨ì¼ ì‘ì—… ì‹¤í–‰"""
        task.status = TaskStatus.RUNNING
        task.started_at = datetime.now()

        try:
            # ì‘ì—… ì‹¤í–‰
            if asyncio.iscoroutinefunction(task.function):
                result = await task.function(*task.args, **task.kwargs)
            else:
                # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(None, task.function, *task.args, **task.kwargs)

            task.status = TaskStatus.COMPLETED
            task.result = result
            task.completed_at = datetime.now()
            task.execution_time = (task.completed_at - task.started_at).total_seconds()

            logger.info(f"âœ… ì‘ì—… ì™„ë£Œ: {task.name} ({task.execution_time:.3f}ì´ˆ)")
            return result

        except Exception as e:
            task.status = TaskStatus.FAILED
            task.error = str(e)
            task.completed_at = datetime.now()
            task.execution_time = (task.completed_at - task.started_at).total_seconds()

            logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨: {task.name} - {e}")
            return None

    def _update_performance_metrics(self, execution_time: float, task_count: int):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.performance_metrics["total_tasks"] += task_count
        self.performance_metrics["completed_tasks"] += task_count

        # í‰ê·  ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        if self.completed_tasks:
            avg_time = statistics.mean([task.execution_time for task in self.completed_tasks])
            self.performance_metrics["average_execution_time"] = avg_time

        # ë³‘ë ¬ íš¨ìœ¨ì„± ê³„ì‚°
        if self.baseline_execution_time > 0:
            efficiency = (self.baseline_execution_time / execution_time) * 100
            self.performance_metrics["parallel_efficiency"] = efficiency

        # ì„±ëŠ¥ í–¥ìƒë¥  ê³„ì‚°
        if self.baseline_execution_time > 0:
            improvement = ((self.baseline_execution_time - execution_time) / self.baseline_execution_time) * 100
            self.performance_metrics["performance_improvement"] = improvement

    async def execute_judgment_parallel(self, judgment_tasks: List[Callable]) -> List[Any]:
        """íŒë‹¨ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰"""
        logger.info("ğŸ§  íŒë‹¨ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰")

        tasks = []
        for i, task_func in enumerate(judgment_tasks):
            task = ParallelTask(
                id=f"judgment_{i}",
                name=f"íŒë‹¨ ì‘ì—… {i+1}",
                function=task_func,
                priority=TaskPriority.HIGH,
            )
            tasks.append(task)

        return await self.execute_parallel_tasks(tasks)

    async def execute_action_parallel(self, action_tasks: List[Callable]) -> List[Any]:
        """í–‰ë™ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰"""
        logger.info("âš¡ í–‰ë™ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰")

        tasks = []
        for i, task_func in enumerate(action_tasks):
            task = ParallelTask(
                id=f"action_{i}",
                name=f"í–‰ë™ ì‘ì—… {i+1}",
                function=task_func,
                priority=TaskPriority.MEDIUM,
            )
            tasks.append(task)

        return await self.execute_parallel_tasks(tasks)

    async def execute_feedback_parallel(self, feedback_tasks: List[Callable]) -> List[Any]:
        """í”¼ë“œë°± ì‘ì—… ë³‘ë ¬ ì‹¤í–‰"""
        logger.info("ğŸ”„ í”¼ë“œë°± ì‘ì—… ë³‘ë ¬ ì‹¤í–‰")

        tasks = []
        for i, task_func in enumerate(feedback_tasks):
            task = ParallelTask(
                id=f"feedback_{i}",
                name=f"í”¼ë“œë°± ì‘ì—… {i+1}",
                function=task_func,
                priority=TaskPriority.LOW,
            )
            tasks.append(task)

        return await self.execute_parallel_tasks(tasks)

    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        return {
            "metrics": self.performance_metrics,
            "target_improvement": 23.0,  # ëª©í‘œ 23% í–¥ìƒ
            "current_improvement": self.performance_metrics["performance_improvement"],
            "baseline_time": self.baseline_execution_time,
            "target_time": self.target_execution_time,
            "efficiency": self.performance_metrics["parallel_efficiency"],
            "total_completed": len(self.completed_tasks),
            "success_rate": (
                self.performance_metrics["completed_tasks"] / max(self.performance_metrics["total_tasks"], 1)
            )
            * 100,
        }

    def add_task_to_queue(self, task: ParallelTask):
        """ì‘ì—… íì— ì¶”ê°€"""
        self.task_queue.append(task)
        logger.info(f"ğŸ“‹ ì‘ì—… íì— ì¶”ê°€: {task.name}")

    async def process_task_queue(self):
        """ì‘ì—… í ì²˜ë¦¬"""
        if not self.task_queue:
            return []

        # íì—ì„œ ì‘ì—… ê°€ì ¸ì˜¤ê¸°
        tasks_to_execute = self.task_queue[: self.max_concurrent_tasks]
        self.task_queue = self.task_queue[self.max_concurrent_tasks :]

        return await self.execute_parallel_tasks(tasks_to_execute)


# í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ í•¨ìˆ˜ë“¤
async def sample_judgment_task(data: str) -> Dict[str, Any]:
    """ìƒ˜í”Œ íŒë‹¨ ì‘ì—…"""
    await asyncio.sleep(0.02)  # 20ms ì‹œë®¬ë ˆì´ì…˜
    return {
        "type": "judgment",
        "data": data,
        "result": f"íŒë‹¨ ê²°ê³¼: {data}",
        "confidence": 0.85,
    }


async def sample_action_task(action: str) -> Dict[str, Any]:
    """ìƒ˜í”Œ í–‰ë™ ì‘ì—…"""
    await asyncio.sleep(0.03)  # 30ms ì‹œë®¬ë ˆì´ì…˜
    return {
        "type": "action",
        "action": action,
        "result": f"í–‰ë™ ì‹¤í–‰: {action}",
        "status": "success",
    }


async def sample_feedback_task(feedback: str) -> Dict[str, Any]:
    """ìƒ˜í”Œ í”¼ë“œë°± ì‘ì—…"""
    await asyncio.sleep(0.01)  # 10ms ì‹œë®¬ë ˆì´ì…˜
    return {
        "type": "feedback",
        "feedback": feedback,
        "result": f"í”¼ë“œë°± ì²˜ë¦¬: {feedback}",
        "quality": 0.9,
    }


async def test_parallel_processor():
    """ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    processor = ACTRParallelProcessor(max_concurrent_tasks=5)

    # í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„±
    judgment_tasks = [
        lambda: sample_judgment_task("ì‚¬ìš©ì ì…ë ¥ ë¶„ì„"),
        lambda: sample_judgment_task("ì»¨í…ìŠ¤íŠ¸ í‰ê°€"),
        lambda: sample_judgment_task("ìš°ì„ ìˆœìœ„ ê²°ì •"),
    ]

    action_tasks = [
        lambda: sample_action_task("ì‘ë‹µ ìƒì„±"),
        lambda: sample_action_task("ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"),
        lambda: sample_action_task("í•™ìŠµ ì§„í–‰"),
    ]

    feedback_tasks = [
        lambda: sample_feedback_task("ì„±ëŠ¥ í‰ê°€"),
        lambda: sample_feedback_task("ê°œì„ ì  ì‹ë³„"),
        lambda: sample_feedback_task("ë‹¤ìŒ ë‹¨ê³„ ê³„íš"),
    ]

    # ë³‘ë ¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    start_time = time.time()

    judgment_results = await processor.execute_judgment_parallel(judgment_tasks)
    action_results = await processor.execute_action_parallel(action_tasks)
    feedback_results = await processor.execute_feedback_parallel(feedback_tasks)

    total_time = time.time() - start_time

    # ê²°ê³¼ ì¶œë ¥
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    logger.info(f"   ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.3f}ì´ˆ")
    logger.info(f"   íŒë‹¨ ê²°ê³¼: {len(judgment_results)}ê°œ")
    logger.info(f"   í–‰ë™ ê²°ê³¼: {len(action_results)}ê°œ")
    logger.info(f"   í”¼ë“œë°± ê²°ê³¼: {len(feedback_results)}ê°œ")

    # ì„±ëŠ¥ ë¦¬í¬íŠ¸
    report = processor.get_performance_report()
    logger.info("ğŸ“ˆ ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
    logger.info(f"   ì„±ëŠ¥ í–¥ìƒë¥ : {report['current_improvement']:.1f}%")
    logger.info(f"   ë³‘ë ¬ íš¨ìœ¨ì„±: {report['efficiency']:.1f}%")
    logger.info(f"   ì„±ê³µë¥ : {report['success_rate']:.1f}%")

    return report


if __name__ == "__main__":
    asyncio.run(test_parallel_processor())
