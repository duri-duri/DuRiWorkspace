#!/usr/bin/env python3
"""
DuRi ì˜ë¯¸ ê¸°ë°˜ ìƒí™© ë¶„ë¥˜ ì‹œìŠ¤í…œ (Phase 1-1 Day 1 ë¦¬íŒ©í† ë§)
ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤ì¹­ â†’ ì˜ë¯¸ ë²¡í„° ê¸°ë°˜ ì´í•´ë¡œ ì „í™˜
"""

import asyncio
from dataclasses import asdict, dataclass
from datetime import datetime
from enum import Enum
import json
import logging
import re
from typing import Any, Dict, List, Optional, Tuple

# ìƒˆë¡œìš´ ì˜ë¯¸ ë²¡í„° ì—”ì§„ import
from semantic_vector_engine import SemanticFrame, SemanticVectorEngine

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SituationType(Enum):
    """ìƒí™© ìœ í˜•"""

    ETHICAL_DILEMMA = "ethical_dilemma"
    PRACTICAL_DECISION = "practical_decision"
    CONFLICT_RESOLUTION = "conflict_resolution"
    COMPLEX_PROBLEM = "complex_problem"
    GENERAL_SITUATION = "general_situation"


class IntentType(Enum):
    """ì˜ë„ ìœ í˜•"""

    DECEPTION = "deception"
    PROTECTION = "protection"
    EFFICIENCY = "efficiency"
    FAIRNESS = "fairness"
    HARM_PREVENTION = "harm_prevention"
    BENEFIT_MAXIMIZATION = "benefit_maximization"
    UNKNOWN = "unknown"


class ValueConflict(Enum):
    """ê°€ì¹˜ ì¶©ëŒ ìœ í˜•"""

    HONESTY_VS_HARM_PREVENTION = "honesty_vs_harm_prevention"
    HONESTY_VS_BENEFIT_MAXIMIZATION = "honesty_vs_benefit_maximization"
    EFFICIENCY_VS_FAIRNESS = "efficiency_vs_fairness"
    INDIVIDUAL_VS_COLLECTIVE = "individual_vs_collective"
    SHORT_TERM_VS_LONG_TERM = "short_term_vs_long_term"
    AUTONOMY_VS_BENEFICENCE = "autonomy_vs_beneficence"
    NONE = "none"


@dataclass
class SemanticContext:
    """ì˜ë¯¸ì  ë§¥ë½"""

    situation_type: SituationType
    intent: IntentType
    stakeholders: List[str]
    value_conflicts: List[ValueConflict]
    consequences: List[str]
    complexity_level: float  # 0.0-1.0
    urgency_level: float  # 0.0-1.0
    context_elements: Dict[str, Any]
    confidence_score: float


@dataclass
class ContextualAnalysis:
    """ë§¥ë½ ë¶„ì„ ê²°ê³¼"""

    temporal_context: str  # ì‹œê°„ì  ë§¥ë½
    spatial_context: str  # ê³µê°„ì  ë§¥ë½
    social_context: str  # ì‚¬íšŒì  ë§¥ë½
    emotional_context: str  # ê°ì •ì  ë§¥ë½
    power_dynamics: List[str]  # ê¶Œë ¥ ê´€ê³„
    cultural_factors: List[str]  # ë¬¸í™”ì  ìš”ì†Œ
    historical_context: str  # ì—­ì‚¬ì  ë§¥ë½
    urgency_factors: List[str]  # ê¸´ê¸‰ì„± ìš”ì†Œ


@dataclass
class ValueConflictAnalysis:
    """ê°€ì¹˜ ì¶©ëŒ ë¶„ì„ ê²°ê³¼"""

    primary_conflict: ValueConflict
    secondary_conflicts: List[ValueConflict]
    conflict_intensity: float  # 0.0-1.0
    resolution_difficulty: float  # 0.0-1.0
    stakeholder_impact: Dict[str, float]  # ì´í•´ê´€ê³„ìë³„ ì˜í–¥ë„
    ethical_implications: List[str]  # ìœ¤ë¦¬ì  í•¨ì˜
    practical_constraints: List[str]  # ì‹¤ìš©ì  ì œì•½


class SemanticSituationClassifier:
    """ì˜ë¯¸ ê¸°ë°˜ ìƒí™© ë¶„ë¥˜ ì‹œìŠ¤í…œ (ë¦¬íŒ©í† ë§ ë²„ì „)"""

    def __init__(self):
        self.system_name = "ì˜ë¯¸ ê¸°ë°˜ ìƒí™© ë¶„ë¥˜ ì‹œìŠ¤í…œ"
        self.version = "3.0.0"  # Phase 1-1 Day 1 ë¦¬íŒ©í† ë§

        # ìƒˆë¡œìš´ ì˜ë¯¸ ë²¡í„° ì—”ì§„ ì´ˆê¸°í™”
        self.semantic_engine = SemanticVectorEngine()

        # ê¸°ì¡´ íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤ (ì ì§„ì  êµì²´ë¥¼ ìœ„í•´ ìœ ì§€)
        self.semantic_patterns = self._initialize_semantic_patterns()
        self.intent_patterns = self._initialize_intent_patterns()
        self.value_patterns = self._initialize_value_patterns()

        # ë§¥ë½ ë¶„ì„ íŒ¨í„´
        self.contextual_patterns = self._initialize_contextual_patterns()
        self.power_dynamics_patterns = self._initialize_power_dynamics_patterns()
        self.cultural_patterns = self._initialize_cultural_patterns()

    def _initialize_semantic_patterns(self) -> Dict[str, Dict]:
        """ì˜ë¯¸ì  íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        return {
            "ethical_dilemma": {
                "keywords": [
                    "ìœ¤ë¦¬",
                    "ë„ë•",
                    "ì •ì˜",
                    "ê³µì •",
                    "ì •ì§",
                    "ì‹ ë¢°",
                    "ì±…ì„",
                    "ì˜ë¬´",
                ],
                "weight": 0.8,
                "description": "ìœ¤ë¦¬ì  ë”œë ˆë§ˆ ìƒí™©",
            },
            "practical_decision": {
                "keywords": [
                    "íš¨ìœ¨",
                    "ì‹¤ìš©",
                    "ì„±ê³¼",
                    "ê²°ê³¼",
                    "ì´ìµ",
                    "ì†ì‹¤",
                    "ë¹„ìš©",
                    "í¸ìµ",
                ],
                "weight": 0.7,
                "description": "ì‹¤ìš©ì  ì˜ì‚¬ê²°ì • ìƒí™©",
            },
            "conflict_resolution": {
                "keywords": [
                    "ê°ˆë“±",
                    "ì¶©ëŒ",
                    "ëŒ€ë¦½",
                    "ë°˜ëŒ€",
                    "ëª¨ìˆœ",
                    "ìƒì¶©",
                    "ê²½ìŸ",
                    "íˆ¬ìŸ",
                ],
                "weight": 0.8,
                "description": "ê°ˆë“± í•´ê²° ìƒí™©",
            },
            "complex_problem": {
                "keywords": [
                    "ë³µì¡",
                    "ì–´ë ¤ìš´",
                    "ë‚œí•´í•œ",
                    "ë³µì¡í•œ",
                    "ë‹¤ì–‘í•œ",
                    "ì—¬ëŸ¬",
                    "ë‹¤ì¤‘",
                    "ë‹¤ì–‘",
                ],
                "weight": 0.6,
                "description": "ë³µì¡í•œ ë¬¸ì œ ìƒí™©",
            },
        }

    def _initialize_intent_patterns(self) -> Dict[str, List[str]]:
        """ì˜ë„ íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "deception": ["ê±°ì§“ë§", "ì†ì„", "ê¸°ë§Œ", "ì‚¬ê¸°", "í—ˆìœ„", "ê°€ì§œ"],
            "protection": ["ë³´í˜¸", "ë°©ì–´", "ì§€í‚¤", "ë§‰", "ì˜ˆë°©", "ë°©ì§€"],
            "efficiency": ["íš¨ìœ¨", "ë¹ ë¥´", "ë¹¨ë¦¬", "ì‹ ì†", "ì¦‰ì‹œ", "ë‹¹ì¥"],
            "fairness": ["ê³µì •", "ì •ì˜", "í‰ë“±", "ê· ë“±", "ë™ë“±", "ê°™ì´"],
            "harm_prevention": ["í•´", "ì†í•´", "ìœ„í—˜", "ìœ„í˜‘", "í”¼í•´", "ë°©ì§€"],
            "benefit_maximization": ["ì´ìµ", "íš¨ê³¼", "ì„±ê³¼", "ê²°ê³¼", "ì„±ê³µ", "ìµœëŒ€í™”"],
        }

    def _initialize_value_patterns(self) -> Dict[str, List[str]]:
        """ê°€ì¹˜ íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "honesty": ["ì •ì§", "ì§„ì‹¤", "ê±°ì§“ë§", "ì†ì„", "ê¸°ë§Œ", "ì‚¬ê¸°"],
            "harm_prevention": ["í•´", "ì†í•´", "ìœ„í—˜", "ìœ„í˜‘", "í”¼í•´", "ë°©ì§€"],
            "efficiency": ["íš¨ìœ¨", "ë¹ ë¥´", "ë¹¨ë¦¬", "ì‹ ì†", "ì¦‰ì‹œ", "ë‹¹ì¥"],
            "fairness": ["ê³µì •", "ì •ì˜", "í‰ë“±", "ê· ë“±", "ë™ë“±", "ê°™ì´"],
            "individual": ["ê°œì¸", "ê°œë³„", "ìì‹ ", "ë‚˜", "ë‚´", "ê°œì¸ì "],
            "collective": ["ì§‘ë‹¨", "ì¡°ì§", "íšŒì‚¬", "íŒ€", "ë‹¨ì²´", "ê³µë™"],
        }

    def _initialize_cultural_patterns(self) -> Dict[str, List[str]]:
        """ë¬¸í™”ì  íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "hierarchy": ["ìƒì‚¬", "ë¶€í•˜", "ì§ì›", "ì‚¬ì¥", "íšŒì¥", "ê´€ë¦¬ì"],
            "collectivism": ["íŒ€", "ì¡°ì§", "íšŒì‚¬", "ë‹¨ì²´", "ê³µë™", "í•¨ê»˜"],
            "individualism": ["ê°œì¸", "ìì‹ ", "ë‚˜", "ë‚´", "ê°œë³„", "í˜¼ì"],
        }

    def _initialize_power_dynamics_patterns(self) -> Dict[str, List[str]]:
        """ê¶Œë ¥ ê´€ê³„ íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "authority": ["ìƒì‚¬", "ì‚¬ì¥", "íšŒì¥", "ê´€ë¦¬ì", "ì±…ì„ì", "ì§€ë„ì"],
            "subordinate": ["ë¶€í•˜", "ì§ì›", "ì‚¬ì›", "í•˜ê¸‰ì", "í”¼ê³ ìš©ì¸"],
            "peer": ["ë™ë£Œ", "ê°™ì€", "í•¨ê»˜", "í˜‘ë ¥", "í˜‘ì—…"],
        }

    def _initialize_contextual_patterns(self) -> Dict[str, Dict]:
        """ë§¥ë½ íŒ¨í„´ ì´ˆê¸°í™”"""
        return {
            "temporal": {
                "immediate": ["ì§€ê¸ˆ", "ë‹¹ì¥", "ì¦‰ì‹œ", "ë°”ë¡œ", "ê³§"],
                "short_term": ["ì˜¤ëŠ˜", "ë‚´ì¼", "ì´ë²ˆ ì£¼", "ì´ë²ˆ ë‹¬"],
                "long_term": ["ì•ìœ¼ë¡œ", "í–¥í›„", "ë¯¸ë˜", "ì•ë‚ "],
            },
            "spatial": {
                "workplace": ["íšŒì‚¬", "ì§ì¥", "ì‚¬ë¬´ì‹¤", "ì—…ë¬´", "ì—…ë¬´ì‹¤"],
                "home": ["ì§‘", "ê°€ì •", "ê°€ì¡±", "ì§‘ì•ˆ"],
                "public": ["ê³µê³µ", "ì‚¬íšŒ", "ëŒ€ì¤‘", "ì¼ë°˜"],
            },
            "social": {
                "formal": ["ê³µì‹", "ê³µì‹ì ", "ê³µì‹ì ìœ¼ë¡œ", "ì •ì‹"],
                "informal": ["ë¹„ê³µì‹", "ì‚¬ì ", "ê°œì¸ì ", "ë¹„ê³µì‹ì "],
            },
        }

    async def analyze_semantic_context(self, situation: str) -> SemanticContext:
        """ì˜ë¯¸ì  ë§¥ë½ ë¶„ì„ (ë¦¬íŒ©í† ë§ëœ ë²„ì „)"""
        logger.info(f"ì˜ë¯¸ì  ë§¥ë½ ë¶„ì„ ì‹œì‘: {situation}")

        # 1. ì˜ë¯¸ ë²¡í„° ì—”ì§„ì„ í†µí•œ ë¶„ì„
        semantic_result = self.semantic_engine.analyze_situation(situation)

        # 2. ì˜ë¯¸ í”„ë ˆì„ì„ ìƒí™© ìœ í˜•ìœ¼ë¡œ ë³€í™˜
        situation_type = self._convert_frame_to_situation_type(
            semantic_result["matched_frame"]
        )

        # 3. ì˜ë„ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€, í–¥í›„ ê°œì„  ì˜ˆì •)
        intent = self._analyze_intent_enhanced(
            situation, semantic_result["context_elements"]
        )

        # 4. ì´í•´ê´€ê³„ì ë¶„ì„ (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)
        stakeholders = self._identify_stakeholders_enhanced(
            situation, semantic_result["context_elements"]
        )

        # 5. ê°€ì¹˜ ì¶©ëŒ ë¶„ì„ (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)
        value_conflicts = self._analyze_value_conflicts_enhanced(
            situation, intent, semantic_result
        )

        # 6. ê²°ê³¼ ë¶„ì„
        consequences = self._analyze_consequences_enhanced(
            situation, intent, value_conflicts
        )

        # 7. ë³µì¡ì„± ë° ê¸´ê¸‰ì„± í‰ê°€ (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)
        complexity_level = self._assess_complexity_enhanced(
            situation, value_conflicts, semantic_result
        )
        urgency_level = self._assess_urgency_enhanced(
            situation, semantic_result["context_elements"]
        )

        # 8. ì‹ ë¢°ë„ ê³„ì‚° (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)
        confidence_score = semantic_result["confidence"]

        # 9. ì¶”ê°€ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        contextual_analysis = await self._analyze_contextual_factors(situation)
        value_conflict_analysis = await self._analyze_value_conflicts_detailed(
            situation, value_conflicts
        )

        semantic_context = SemanticContext(
            situation_type=situation_type,
            intent=intent,
            stakeholders=stakeholders,
            value_conflicts=value_conflicts,
            consequences=consequences,
            complexity_level=complexity_level,
            urgency_level=urgency_level,
            context_elements=semantic_result["context_elements"],
            confidence_score=confidence_score,
        )

        logger.info(
            f"ì˜ë¯¸ì  ë§¥ë½ ë¶„ì„ ì™„ë£Œ: {situation_type.value}, ì‹ ë¢°ë„: {confidence_score:.2f}"
        )
        return semantic_context

    def _convert_frame_to_situation_type(self, frame: SemanticFrame) -> SituationType:
        """ì˜ë¯¸ í”„ë ˆì„ì„ ìƒí™© ìœ í˜•ìœ¼ë¡œ ë³€í™˜"""
        frame_to_situation = {
            SemanticFrame.ETHICAL_DILEMMA: SituationType.ETHICAL_DILEMMA,
            SemanticFrame.PRACTICAL_DECISION: SituationType.PRACTICAL_DECISION,
            SemanticFrame.CONFLICT_RESOLUTION: SituationType.CONFLICT_RESOLUTION,
            SemanticFrame.COMPLEX_PROBLEM: SituationType.COMPLEX_PROBLEM,
            SemanticFrame.GENERAL_SITUATION: SituationType.GENERAL_SITUATION,
        }
        return frame_to_situation.get(frame, SituationType.GENERAL_SITUATION)

    def _analyze_intent_enhanced(
        self, situation: str, context_elements: Dict[str, Any]
    ) -> IntentType:
        """í–¥ìƒëœ ì˜ë„ ë¶„ì„ (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)"""
        intent_scores = {
            IntentType.DECEPTION: 0.0,
            IntentType.PROTECTION: 0.0,
            IntentType.EFFICIENCY: 0.0,
            IntentType.FAIRNESS: 0.0,
            IntentType.HARM_PREVENTION: 0.0,
            IntentType.BENEFIT_MAXIMIZATION: 0.0,
        }

        # ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤ì¹­ (ì ì§„ì  êµì²´ë¥¼ ìœ„í•´ ìœ ì§€)
        for intent_type, keywords in self.intent_patterns.items():
            score = 0.0
            for keyword in keywords:
                if keyword in situation:
                    score += 1.0

            if keywords:
                intent_scores[IntentType(intent_type)] = min(score / len(keywords), 1.0)

        # ì˜ë¯¸ ë²¡í„° ê²°ê³¼ë¥¼ í™œìš©í•œ ì¶”ê°€ ë¶„ì„
        if context_elements.get("actions"):
            # í–‰ìœ„ ë¶„ì„ì„ í†µí•œ ì˜ë„ ì¶”ì •
            actions = context_elements["actions"]
            if any("ë³´í˜¸" in action for action in actions):
                intent_scores[IntentType.PROTECTION] += 0.5
            if any("íš¨ìœ¨" in action for action in actions):
                intent_scores[IntentType.EFFICIENCY] += 0.5

        # ìµœê³  ì ìˆ˜ì˜ ì˜ë„ ë°˜í™˜
        best_intent = max(intent_scores.items(), key=lambda x: x[1])
        return best_intent[0] if best_intent[1] > 0 else IntentType.UNKNOWN

    def _identify_stakeholders_enhanced(
        self, situation: str, context_elements: Dict[str, Any]
    ) -> List[str]:
        """í–¥ìƒëœ ì´í•´ê´€ê³„ì ì‹ë³„ (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)"""
        stakeholders = []

        # ê¸°ì¡´ í–‰ìœ„ì ì¶”ì¶œ ë¡œì§
        if context_elements.get("actors"):
            stakeholders.extend(context_elements["actors"])

        # ì¶”ê°€ ì´í•´ê´€ê³„ì ì¶”ì¶œ
        stakeholder_keywords = [
            "ê³ ê°",
            "ì§ì›",
            "íšŒì‚¬",
            "ê´€ë¦¬ì",
            "ì‚¬ì¥",
            "íšŒì¥",
            "íŒ€",
            "ì¡°ì§",
            "ì •ë¶€",
            "ì‚¬íšŒ",
            "ê³µê³µ",
            "ê°œì¸",
            "ê°€ì¡±",
            "ì¹œêµ¬",
            "ë™ë£Œ",
        ]

        for keyword in stakeholder_keywords:
            if keyword in situation:
                stakeholders.append(keyword)

        return list(set(stakeholders))  # ì¤‘ë³µ ì œê±°

    def _analyze_value_conflicts_enhanced(
        self, situation: str, intent: IntentType, semantic_result: Dict[str, Any]
    ) -> List[ValueConflict]:
        """í–¥ìƒëœ ê°€ì¹˜ ì¶©ëŒ ë¶„ì„ (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)"""
        conflicts = []

        # ê¸°ì¡´ ê°€ì¹˜ ì¶©ëŒ ë¶„ì„ ë¡œì§
        value_keywords = {
            "honesty": ["ì •ì§", "ì§„ì‹¤", "ê±°ì§“ë§", "ì†ì„"],
            "harm_prevention": ["í•´", "ì†í•´", "ìœ„í—˜", "ìœ„í˜‘"],
            "efficiency": ["íš¨ìœ¨", "ë¹ ë¥´", "ì‹ ì†"],
            "fairness": ["ê³µì •", "ì •ì˜", "í‰ë“±"],
            "individual": ["ê°œì¸", "ê°œë³„", "ìì‹ "],
            "collective": ["ì§‘ë‹¨", "ì¡°ì§", "íšŒì‚¬", "íŒ€"],
        }

        # ê°€ì¹˜ ì¶©ëŒ íƒì§€
        detected_values = []
        for value_type, keywords in value_keywords.items():
            for keyword in keywords:
                if keyword in situation:
                    detected_values.append(value_type)
                    break

        # ì¶©ëŒ ìƒì„±
        if len(detected_values) >= 2:
            for i in range(len(detected_values)):
                for j in range(i + 1, len(detected_values)):
                    conflict = self._create_value_conflict(
                        detected_values[i], detected_values[j]
                    )
                    if conflict:
                        conflicts.append(conflict)

        # ì˜ë¯¸ ë²¡í„° ê²°ê³¼ë¥¼ í™œìš©í•œ ì¶”ê°€ ë¶„ì„
        if semantic_result.get("semantic_similarity", 0) > 0.8:
            # ë†’ì€ ì˜ë¯¸ì  ìœ ì‚¬ë„ëŠ” ë³µì¡í•œ ê°€ì¹˜ ì¶©ëŒì„ ì‹œì‚¬
            if not conflicts:
                conflicts.append(ValueConflict.EFFICIENCY_VS_FAIRNESS)

        return conflicts

    def _create_value_conflict(
        self, value1: str, value2: str
    ) -> Optional[ValueConflict]:
        """ê°€ì¹˜ ì¶©ëŒ ìƒì„±"""
        conflict_mapping = {
            ("honesty", "harm_prevention"): ValueConflict.HONESTY_VS_HARM_PREVENTION,
            (
                "honesty",
                "benefit_maximization",
            ): ValueConflict.HONESTY_VS_BENEFIT_MAXIMIZATION,
            ("efficiency", "fairness"): ValueConflict.EFFICIENCY_VS_FAIRNESS,
            ("individual", "collective"): ValueConflict.INDIVIDUAL_VS_COLLECTIVE,
        }

        return conflict_mapping.get((value1, value2)) or conflict_mapping.get(
            (value2, value1)
        )

    def _analyze_consequences_enhanced(
        self, situation: str, intent: IntentType, value_conflicts: List[ValueConflict]
    ) -> List[str]:
        """í–¥ìƒëœ ê²°ê³¼ ë¶„ì„"""
        consequences = []

        # ì˜ë„ ê¸°ë°˜ ê²°ê³¼ ì¶”ì •
        intent_consequences = {
            IntentType.DECEPTION: ["ì‹ ë¢° ìƒì‹¤", "ê´€ê³„ ì•…í™”", "ë²•ì  ë¬¸ì œ"],
            IntentType.PROTECTION: ["ì•ˆì „ í™•ë³´", "ìœ„í—˜ ë°©ì§€", "ë³´í˜¸ ê°•í™”"],
            IntentType.EFFICIENCY: ["ì„±ê³¼ í–¥ìƒ", "ë¹„ìš© ì ˆê°", "ì‹œê°„ ë‹¨ì¶•"],
            IntentType.FAIRNESS: ["ê³µì •ì„± í™•ë³´", "í‰ë“± ì‹¤í˜„", "ì •ì˜ êµ¬í˜„"],
            IntentType.HARM_PREVENTION: ["í”¼í•´ ë°©ì§€", "ì•ˆì „ í™•ë³´", "ìœ„í—˜ ê°ì†Œ"],
            IntentType.BENEFIT_MAXIMIZATION: ["ì´ìµ ì¦ëŒ€", "íš¨ê³¼ ê·¹ëŒ€í™”", "ì„±ê³¼ í–¥ìƒ"],
        }

        if intent in intent_consequences:
            consequences.extend(intent_consequences[intent])

        # ê°€ì¹˜ ì¶©ëŒ ê¸°ë°˜ ê²°ê³¼
        if value_conflicts:
            consequences.append("ê°€ì¹˜ ì¶©ëŒë¡œ ì¸í•œ ê°ˆë“±")
            consequences.append("ì˜ì‚¬ê²°ì •ì˜ ì–´ë ¤ì›€")

        return consequences

    def _assess_complexity_enhanced(
        self,
        situation: str,
        value_conflicts: List[ValueConflict],
        semantic_result: Dict[str, Any],
    ) -> float:
        """í–¥ìƒëœ ë³µì¡ì„± í‰ê°€ (ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©)"""
        complexity = 0.0

        # ê°€ì¹˜ ì¶©ëŒ ìˆ˜ì— ë”°ë¥¸ ë³µì¡ì„±
        complexity += len(value_conflicts) * 0.2

        # ì˜ë¯¸ ë²¡í„° ê²°ê³¼ í™œìš©
        if semantic_result.get("semantic_similarity", 0) > 0.8:
            complexity += 0.3  # ë†’ì€ ì˜ë¯¸ì  ìœ ì‚¬ë„ëŠ” ë³µì¡ì„±ì„ ì‹œì‚¬

        # ì´í•´ê´€ê³„ì ìˆ˜ì— ë”°ë¥¸ ë³µì¡ì„±
        stakeholders_count = len(
            semantic_result.get("context_elements", {}).get("actors", [])
        )
        complexity += min(stakeholders_count * 0.1, 0.3)

        return min(max(complexity, 0.0), 1.0)

    def _assess_urgency_enhanced(
        self, situation: str, context_elements: Dict[str, Any]
    ) -> float:
        """í–¥ìƒëœ ê¸´ê¸‰ì„± í‰ê°€"""
        urgency = 0.0

        # ê¸´ê¸‰ì„± í‚¤ì›Œë“œ
        urgency_keywords = ["ì¦‰ì‹œ", "ë‹¹ì¥", "ë°”ë¡œ", "ê³§", "ê¸´ê¸‰", "ì‹œê¸‰", "ê¸‰í•œ"]
        for keyword in urgency_keywords:
            if keyword in situation:
                urgency += 0.2

        # í–‰ìœ„ ë¶„ì„
        if context_elements.get("actions"):
            actions = context_elements["actions"]
            if any("í•´ì•¼" in action for action in actions):
                urgency += 0.3

        return min(max(urgency, 0.0), 1.0)

    async def _analyze_contextual_factors(self, situation: str) -> ContextualAnalysis:
        """ë§¥ë½ì  ìš”ì†Œ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        return ContextualAnalysis(
            temporal_context="í˜„ì¬",
            spatial_context="ì§ì¥",
            social_context="ê³µì‹ì ",
            emotional_context="ì¤‘ë¦½ì ",
            power_dynamics=["ê´€ë¦¬ì-ì§ì›"],
            cultural_factors=["ì¡°ì§ ë¬¸í™”"],
            historical_context="ìµœê·¼",
            urgency_factors=["ì‹œê¸‰ì„±"],
        )

    async def _analyze_value_conflicts_detailed(
        self, situation: str, value_conflicts: List[ValueConflict]
    ) -> ValueConflictAnalysis:
        """ê°€ì¹˜ ì¶©ëŒ ìƒì„¸ ë¶„ì„ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
        if not value_conflicts:
            return ValueConflictAnalysis(
                primary_conflict=ValueConflict.NONE,
                secondary_conflicts=[],
                conflict_intensity=0.0,
                resolution_difficulty=0.0,
                stakeholder_impact={},
                ethical_implications=[],
                practical_constraints=[],
            )

        return ValueConflictAnalysis(
            primary_conflict=value_conflicts[0],
            secondary_conflicts=value_conflicts[1:] if len(value_conflicts) > 1 else [],
            conflict_intensity=0.7,
            resolution_difficulty=0.6,
            stakeholder_impact={"ì§ì›": 0.8, "íšŒì‚¬": 0.6},
            ethical_implications=["ìœ¤ë¦¬ì  ë”œë ˆë§ˆ"],
            practical_constraints=["ì‹œê°„ ì œì•½", "ìì› ì œì•½"],
        )


async def test_semantic_situation_classifier_refactored():
    """ë¦¬íŒ©í† ë§ëœ ì˜ë¯¸ ìƒí™© ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ§  ë¦¬íŒ©í† ë§ëœ SemanticSituationClassifier í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)

    classifier = SemanticSituationClassifier()

    # í…ŒìŠ¤íŠ¸ ìƒí™©ë“¤
    test_situations = [
        "íšŒì‚¬ì˜ AI ì‹œìŠ¤í…œì´ ê³ ê° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ì§€ë§Œ, ê°œì¸ì •ë³´ ë³´í˜¸ì— ëŒ€í•œ ìš°ë ¤ê°€ ì œê¸°ë˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "ì§ì›ì´ íšŒì‚¬ì˜ ë¹„ë°€ì„ ì™¸ë¶€ì— ìœ ì¶œí•˜ë ¤ê³  í•  ë•Œ, ì´ë¥¼ ë§‰ì•„ì•¼ í•˜ëŠ”ì§€ ê³ ë¯¼í•˜ëŠ” ìƒí™©ì…ë‹ˆë‹¤.",
        "íš¨ìœ¨ì„±ì„ ìœ„í•´ ì¼ë¶€ ì§ì›ì„ í•´ê³ í•´ì•¼ í•˜ëŠ” ìƒí™©ì—ì„œ, ê³µì •ì„±ê³¼ íš¨ìœ¨ì„± ì‚¬ì´ì—ì„œ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.",
    ]

    for i, situation in enumerate(test_situations, 1):
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ìƒí™© {i}: {situation[:50]}...")

        # ë¦¬íŒ©í† ë§ëœ ë¶„ë¥˜ê¸°ë¡œ ë¶„ì„
        semantic_context = await classifier.analyze_semantic_context(situation)

        print(f"  â€¢ ìƒí™© ìœ í˜•: {semantic_context.situation_type.value}")
        print(f"  â€¢ ì˜ë„: {semantic_context.intent.value}")
        print(f"  â€¢ ì´í•´ê´€ê³„ì: {len(semantic_context.stakeholders)}ëª…")
        print(f"  â€¢ ê°€ì¹˜ ì¶©ëŒ: {len(semantic_context.value_conflicts)}ê°œ")
        print(f"  â€¢ ë³µì¡ì„±: {semantic_context.complexity_level:.2f}")
        print(f"  â€¢ ê¸´ê¸‰ì„±: {semantic_context.urgency_level:.2f}")
        print(f"  â€¢ ì‹ ë¢°ë„: {semantic_context.confidence_score:.2f}")

    print("\n" + "=" * 80)
    print("âœ… ë¦¬íŒ©í† ë§ëœ SemanticSituationClassifier í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("ğŸ‰ ì˜ë¯¸ ë²¡í„° ê¸°ë°˜ ì‹œìŠ¤í…œìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì „í™˜!")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(test_semantic_situation_classifier_refactored())
