#!/usr/bin/env python3
"""
DuRi ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²° ì‹œìŠ¤í…œ - Phase 1-3 Week 3 Day 3
ë™ì  ì¶”ë¡  ê·¸ë˜í”„ì˜ ë¶ˆì¼ì¹˜ë¥¼ íƒì§€í•˜ê³  ìë™ìœ¼ë¡œ í•´ê²°í•˜ëŠ” ì‹œìŠ¤í…œ

ê¸°ëŠ¥:
1. ë¶ˆì¼ì¹˜ íƒì§€ ì‹œìŠ¤í…œ
2. ìë™ í•´ê²° ì‹œìŠ¤í…œ
3. í•´ê²° ì „ëµ ì‹œìŠ¤í…œ
4. ê²€ì¦ ì‹œìŠ¤í…œ
"""

import asyncio
import logging
import re
from collections import defaultdict
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional, Set

import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class InconsistencyType(Enum):
    """ë¶ˆì¼ì¹˜ ìœ í˜•"""

    LOGICAL_CONTRADICTION = "logical_contradiction"
    SEMANTIC_INCONSISTENCY = "semantic_inconsistency"
    STRUCTURAL_INCONSISTENCY = "structural_inconsistency"
    CONFLICTING_EVIDENCE = "conflicting_evidence"
    CIRCULAR_REASONING = "circular_reasoning"
    MISSING_PREMISE = "missing_premise"


class ResolutionStrategy(Enum):
    """í•´ê²° ì „ëµ"""

    NODE_MODIFICATION = "node_modification"
    EDGE_ADJUSTMENT = "edge_adjustment"
    PATH_RECONSTRUCTION = "path_reconstruction"
    EVIDENCE_WEIGHTING = "evidence_weighting"
    CONTRADICTION_RESOLUTION = "contradiction_resolution"


@dataclass
class Inconsistency:
    """ë¶ˆì¼ì¹˜ ì •ë³´"""

    inconsistency_id: str
    inconsistency_type: InconsistencyType
    severity: float  # 0.0-1.0
    description: str
    affected_nodes: List[str] = field(default_factory=list)
    affected_edges: List[str] = field(default_factory=list)
    confidence: float = 0.0
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class ResolutionResult:
    """í•´ê²° ê²°ê³¼"""

    resolution_id: str
    inconsistency_id: str
    strategy: ResolutionStrategy
    success: bool
    confidence: float
    description: str
    modified_nodes: List[str] = field(default_factory=list)
    modified_edges: List[str] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)


class InconsistencyDetector:
    """ë¶ˆì¼ì¹˜ íƒì§€ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.detection_rules = self._initialize_detection_rules()
        self.inconsistency_cache = {}
        self.max_cache_size = 1000

    def _initialize_detection_rules(self) -> Dict[str, Dict[str, Any]]:
        """íƒì§€ ê·œì¹™ ì´ˆê¸°í™”"""
        return {
            "logical_contradiction": {
                "weight": 0.3,
                "threshold": 0.7,
                "description": "ë…¼ë¦¬ì  ëª¨ìˆœ íƒì§€",
            },
            "semantic_inconsistency": {
                "weight": 0.25,
                "threshold": 0.6,
                "description": "ì˜ë¯¸ì  ë¶ˆì¼ì¹˜ íƒì§€",
            },
            "structural_inconsistency": {
                "weight": 0.25,
                "threshold": 0.6,
                "description": "êµ¬ì¡°ì  ë¶ˆì¼ì¹˜ íƒì§€",
            },
            "conflicting_evidence": {
                "weight": 0.2,
                "threshold": 0.5,
                "description": "ìƒì¶©í•˜ëŠ” ì¦ê±° íƒì§€",
            },
        }

    async def detect_inconsistencies(self, graph: "DynamicReasoningGraph") -> List[Inconsistency]:
        """ë¶ˆì¼ì¹˜ íƒì§€"""
        logger.info(f"ë¶ˆì¼ì¹˜ íƒì§€ ì‹œì‘: {len(graph.nodes)} ë…¸ë“œ, {len(graph.edges)} ì—£ì§€")

        inconsistencies = []

        # 1. ë…¼ë¦¬ì  ëª¨ìˆœ íƒì§€
        logical_contradictions = await self._detect_logical_contradictions(graph)
        inconsistencies.extend(logical_contradictions)

        # 2. ì˜ë¯¸ì  ë¶ˆì¼ì¹˜ íƒì§€
        semantic_inconsistencies = await self._detect_semantic_inconsistencies(graph)
        inconsistencies.extend(semantic_inconsistencies)

        # 3. êµ¬ì¡°ì  ë¶ˆì¼ì¹˜ íƒì§€
        structural_inconsistencies = await self._detect_structural_inconsistencies(graph)
        inconsistencies.extend(structural_inconsistencies)

        # 4. ìƒì¶©í•˜ëŠ” ì¦ê±° íƒì§€
        conflicting_evidence = await self._detect_conflicting_evidence(graph)
        inconsistencies.extend(conflicting_evidence)

        # 5. ìˆœí™˜ ì¶”ë¡  íƒì§€
        circular_reasoning = await self._detect_circular_reasoning(graph)
        inconsistencies.extend(circular_reasoning)

        # 6. ëˆ„ë½ëœ ì „ì œ íƒì§€
        missing_premises = await self._detect_missing_premises(graph)
        inconsistencies.extend(missing_premises)

        logger.info(f"ë¶ˆì¼ì¹˜ íƒì§€ ì™„ë£Œ: {len(inconsistencies)}ê°œ ë°œê²¬")
        return inconsistencies

    async def _detect_logical_contradictions(self, graph: "DynamicReasoningGraph") -> List[Inconsistency]:
        """ë…¼ë¦¬ì  ëª¨ìˆœ íƒì§€"""
        contradictions = []

        # ë…¸ë“œ ê°„ ì§ì ‘ì ì¸ ë…¼ë¦¬ì  ëª¨ìˆœ íƒì§€
        for node1_id, node1 in graph.nodes.items():
            for node2_id, node2 in graph.nodes.items():
                if node1_id != node2_id:
                    # ì§ì ‘ì ì¸ ë…¼ë¦¬ì  ëª¨ìˆœ í™•ì¸
                    if self._is_logical_contradiction(node1, node2):
                        contradiction = Inconsistency(
                            inconsistency_id=f"logical_contradiction_{node1_id}_{node2_id}",
                            inconsistency_type=InconsistencyType.LOGICAL_CONTRADICTION,
                            severity=0.8,
                            description=f"ë…¼ë¦¬ì  ëª¨ìˆœ: {node1.content} vs {node2.content}",
                            affected_nodes=[node1_id, node2_id],
                            confidence=0.9,
                        )
                        contradictions.append(contradiction)

        # ì—£ì§€ë¥¼ í†µí•œ ë…¼ë¦¬ì  ëª¨ìˆœ íƒì§€
        for edge in graph.edges.values():
            if edge.edge_type.value in ["contradicts", "challenges"]:
                source_node = graph.nodes.get(edge.source_node)
                target_node = graph.nodes.get(edge.target_node)

                if source_node and target_node:
                    contradiction = Inconsistency(
                        inconsistency_id=f"edge_contradiction_{edge.edge_id}",
                        inconsistency_type=InconsistencyType.LOGICAL_CONTRADICTION,
                        severity=edge.strength,
                        description=f"ì—£ì§€ ê¸°ë°˜ ë…¼ë¦¬ì  ëª¨ìˆœ: {source_node.content} -> {target_node.content}",
                        affected_nodes=[edge.source_node, edge.target_node],
                        affected_edges=[edge.edge_id],
                        confidence=edge.strength,
                    )
                    contradictions.append(contradiction)

        return contradictions

    async def _detect_semantic_inconsistencies(self, graph: "DynamicReasoningGraph") -> List[Inconsistency]:
        """ì˜ë¯¸ì  ë¶ˆì¼ì¹˜ íƒì§€"""
        inconsistencies = []

        # ë…¸ë“œ ê°„ ì˜ë¯¸ì  ë¶ˆì¼ì¹˜ íƒì§€ (ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©)
        for node1_id, node1 in graph.nodes.items():
            for node2_id, node2 in graph.nodes.items():
                if node1_id != node2_id:
                    # ì˜ë¯¸ì  ìœ ì‚¬ë„ê°€ ë‚®ì§€ë§Œ ì—°ê²°ëœ ê²½ìš°
                    similarity = self._calculate_semantic_similarity(node1.content, node2.content)

                    # ì—°ê²°ëœ ë…¸ë“œì¸ì§€ í™•ì¸
                    is_connected = False
                    for edge in graph.edges.values():
                        if (edge.source_node == node1_id and edge.target_node == node2_id) or (
                            edge.source_node == node2_id and edge.target_node == node1_id
                        ):
                            is_connected = True
                            break

                    # ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš© (0.3 â†’ 0.1)
                    if is_connected and similarity < 0.1:
                        inconsistency = Inconsistency(
                            inconsistency_id=f"semantic_inconsistency_{node1_id}_{node2_id}",
                            inconsistency_type=InconsistencyType.SEMANTIC_INCONSISTENCY,
                            severity=0.4,  # ì‹¬ê°ë„ ê°ì†Œ
                            description=f"ì˜ë¯¸ì  ë¶ˆì¼ì¹˜: {node1.content} vs {node2.content} (ìœ ì‚¬ë„: {similarity:.2f})",
                            affected_nodes=[node1_id, node2_id],
                            confidence=0.5,  # ì‹ ë¢°ë„ ê°ì†Œ
                        )
                        inconsistencies.append(inconsistency)

        return inconsistencies

    async def _detect_structural_inconsistencies(self, graph: "DynamicReasoningGraph") -> List[Inconsistency]:
        """êµ¬ì¡°ì  ë¶ˆì¼ì¹˜ íƒì§€"""
        inconsistencies = []

        # ê³ ë¦½ëœ ë…¸ë“œ íƒì§€
        isolated_nodes = []
        for node_id in graph.nodes:
            has_connection = False
            for edge in graph.edges.values():
                if edge.source_node == node_id or edge.target_node == node_id:
                    has_connection = True
                    break

            if not has_connection:
                isolated_nodes.append(node_id)

        if isolated_nodes:
            inconsistency = Inconsistency(
                inconsistency_id="structural_inconsistency_isolated_nodes",
                inconsistency_type=InconsistencyType.STRUCTURAL_INCONSISTENCY,
                severity=0.5,
                description=f"ê³ ë¦½ëœ ë…¸ë“œ ë°œê²¬: {isolated_nodes}",
                affected_nodes=isolated_nodes,
                confidence=0.8,
            )
            inconsistencies.append(inconsistency)

        # ë¶ˆê· í˜•í•œ ê·¸ë˜í”„ êµ¬ì¡° íƒì§€
        node_types = defaultdict(int)
        for node in graph.nodes.values():
            node_types[node.node_type] += 1

        # íŠ¹ì • ìœ í˜•ì˜ ë…¸ë“œê°€ ë„ˆë¬´ ë§ê±°ë‚˜ ì ì€ ê²½ìš°
        total_nodes = len(graph.nodes)
        for node_type, count in node_types.items():
            ratio = count / total_nodes
            if ratio > 0.7 or (ratio < 0.1 and total_nodes > 5):
                inconsistency = Inconsistency(
                    inconsistency_id=f"structural_inconsistency_node_type_{node_type.value}",
                    inconsistency_type=InconsistencyType.STRUCTURAL_INCONSISTENCY,
                    severity=0.4,
                    description=f"ë¶ˆê· í˜•í•œ ë…¸ë“œ ìœ í˜•: {node_type.value} ({count}/{total_nodes})",
                    affected_nodes=[n.node_id for n in graph.nodes.values() if n.node_type == node_type],
                    confidence=0.6,
                )
                inconsistencies.append(inconsistency)

        return inconsistencies

    async def _detect_conflicting_evidence(self, graph: "DynamicReasoningGraph") -> List[Inconsistency]:
        """ìƒì¶©í•˜ëŠ” ì¦ê±° íƒì§€"""
        conflicts = []

        # ì¦ê±° ë…¸ë“œë“¤ ì°¾ê¸°
        evidence_nodes = [n for n in graph.nodes.values() if n.node_type.value == "evidence"]

        # ì¦ê±° ê°„ ìƒì¶© ê´€ê³„ íƒì§€
        for i, evidence1 in enumerate(evidence_nodes):
            for j, evidence2 in enumerate(evidence_nodes[i + 1 :], i + 1):
                # ì¦ê±° ê°„ ì˜ë¯¸ì  ìƒì¶© í™•ì¸
                if self._is_conflicting_evidence(evidence1, evidence2):
                    conflict = Inconsistency(
                        inconsistency_id=f"conflicting_evidence_{evidence1.node_id}_{evidence2.node_id}",
                        inconsistency_type=InconsistencyType.CONFLICTING_EVIDENCE,
                        severity=0.7,
                        description=f"ìƒì¶©í•˜ëŠ” ì¦ê±°: {evidence1.content} vs {evidence2.content}",
                        affected_nodes=[evidence1.node_id, evidence2.node_id],
                        confidence=0.8,
                    )
                    conflicts.append(conflict)

        return conflicts

    async def _detect_circular_reasoning(self, graph: "DynamicReasoningGraph") -> List[Inconsistency]:
        """ìˆœí™˜ ì¶”ë¡  íƒì§€"""
        circular_reasoning = []

        # ì‹¤ì œ ìˆœí™˜ë§Œ íƒì§€í•˜ë„ë¡ ê°œì„ 
        def has_cycle(start_node: str, visited: set, rec_stack: set, path: list) -> Optional[list]:
            """ì‹¤ì œ ìˆœí™˜ íƒì§€"""
            if start_node in rec_stack:
                # ìˆœí™˜ ë°œê²¬
                cycle_start = path.index(start_node)
                cycle = path[cycle_start:]
                if len(cycle) > 2:  # ìµœì†Œ 3ê°œ ë…¸ë“œ ì´ìƒì˜ ìˆœí™˜ë§Œ ê³ ë ¤
                    return cycle
                return None

            if start_node in visited:
                return None

            visited.add(start_node)
            rec_stack.add(start_node)
            path.append(start_node)

            # ì¸ì ‘ ë…¸ë“œ íƒìƒ‰ (ë°©í–¥ì„± ê³ ë ¤)
            for edge in graph.edges.values():
                if edge.source_node == start_node:
                    cycle = has_cycle(edge.target_node, visited.copy(), rec_stack.copy(), path.copy())
                    if cycle:
                        return cycle

            rec_stack.remove(start_node)
            return None

        # ëª¨ë“  ë…¸ë“œì—ì„œ ìˆœí™˜ íƒì§€
        all_visited = set()
        for node_id in graph.nodes:
            if node_id not in all_visited:
                cycle = has_cycle(node_id, set(), set(), [])
                if cycle:
                    circular_reasoning.append(
                        Inconsistency(
                            inconsistency_id=f"circular_reasoning_{len(circular_reasoning)}",
                            inconsistency_type=InconsistencyType.CIRCULAR_REASONING,
                            severity=0.6,
                            description=f"ìˆœí™˜ ì¶”ë¡  ë°œê²¬: {' -> '.join(cycle)}",
                            affected_nodes=cycle,
                            confidence=0.9,
                        )
                    )
                    all_visited.update(cycle)

        return circular_reasoning

    async def _detect_missing_premises(self, graph: "DynamicReasoningGraph") -> List[Inconsistency]:
        """ëˆ„ë½ëœ ì „ì œ íƒì§€"""
        missing_premises = []

        # ê²°ë¡  ë…¸ë“œë“¤ ì°¾ê¸°
        conclusion_nodes = [n for n in graph.nodes.values() if n.node_type.value == "conclusion"]

        for conclusion in conclusion_nodes:
            # ê²°ë¡ ì„ ì§€ì›í•˜ëŠ” ì „ì œë“¤ ì°¾ê¸°
            supporting_premises = []
            for edge in graph.edges.values():
                if edge.target_node == conclusion.node_id and edge.edge_type.value in [
                    "supports",
                    "infers",
                ]:
                    source_node = graph.nodes.get(edge.source_node)
                    if source_node and source_node.node_type.value == "premise":
                        supporting_premises.append(source_node)

            # ì „ì œê°€ ë¶€ì¡±í•œ ê²½ìš°
            if len(supporting_premises) < 2:
                missing_premises.append(
                    Inconsistency(
                        inconsistency_id=f"missing_premise_{conclusion.node_id}",
                        inconsistency_type=InconsistencyType.MISSING_PREMISE,
                        severity=0.5,
                        description=f"ëˆ„ë½ëœ ì „ì œ: {conclusion.content} (ì§€ì› ì „ì œ: {len(supporting_premises)}ê°œ)",
                        affected_nodes=[conclusion.node_id],
                        confidence=0.7,
                    )
                )

        return missing_premises

    def _is_logical_contradiction(self, node1: "DynamicReasoningNode", node2: "DynamicReasoningNode") -> bool:
        """ë…¼ë¦¬ì  ëª¨ìˆœ ì—¬ë¶€ í™•ì¸"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ëª¨ìˆœ íƒì§€
        contradiction_keywords = {
            "ì°¬ì„±": "ë°˜ëŒ€",
            "ì˜³ë‹¤": "í‹€ë¦¬ë‹¤",
            "ì°¸": "ê±°ì§“",
            "ìˆìŒ": "ì—†ìŒ",
            "ê°€ëŠ¥": "ë¶ˆê°€ëŠ¥",
            "í•„ìš”": "ë¶ˆí•„ìš”",
            "ì¤‘ìš”": "ì¤‘ìš”í•˜ì§€ ì•ŠìŒ",
        }

        content1 = node1.content.lower()
        content2 = node2.content.lower()

        for keyword1, keyword2 in contradiction_keywords.items():
            if keyword1 in content1 and keyword2 in content2:
                return True
            if keyword2 in content1 and keyword1 in content2:
                return True

        return False

    def _calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
        keywords1 = set(re.findall(r"\w+", text1.lower()))
        keywords2 = set(re.findall(r"\w+", text2.lower()))

        if not keywords1 or not keywords2:
            return 0.0

        intersection = len(keywords1.intersection(keywords2))
        union = len(keywords1.union(keywords2))

        return intersection / union if union > 0 else 0.0

    def _is_conflicting_evidence(self, evidence1: "DynamicReasoningNode", evidence2: "DynamicReasoningNode") -> bool:
        """ìƒì¶©í•˜ëŠ” ì¦ê±° ì—¬ë¶€ í™•ì¸"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ìƒì¶© íƒì§€
        conflict_keywords = {
            "ì¦ê°€": "ê°ì†Œ",
            "ìƒìŠ¹": "í•˜ë½",
            "ê°œì„ ": "ì•…í™”",
            "ì„±ê³µ": "ì‹¤íŒ¨",
        }

        content1 = evidence1.content.lower()
        content2 = evidence2.content.lower()

        for keyword1, keyword2 in conflict_keywords.items():
            if keyword1 in content1 and keyword2 in content2:
                return True
            if keyword2 in content1 and keyword1 in content2:
                return True

        return False


class InconsistencyResolver:
    """ë¶ˆì¼ì¹˜ í•´ê²° ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.resolution_strategies = self._initialize_resolution_strategies()
        self.resolution_cache = {}
        self.max_cache_size = 1000

    def _initialize_resolution_strategies(self) -> Dict[str, Dict[str, Any]]:
        """í•´ê²° ì „ëµ ì´ˆê¸°í™”"""
        return {
            "node_modification": {"weight": 0.3, "description": "ë…¸ë“œ ìˆ˜ì • ì „ëµ"},
            "edge_adjustment": {"weight": 0.25, "description": "ì—£ì§€ ì¡°ì • ì „ëµ"},
            "path_reconstruction": {"weight": 0.25, "description": "ê²½ë¡œ ì¬êµ¬ì„± ì „ëµ"},
            "evidence_weighting": {
                "weight": 0.2,
                "description": "ì¦ê±° ê°€ì¤‘ì¹˜ ì¡°ì • ì „ëµ",
            },
        }

    async def resolve_inconsistencies(
        self, graph: "DynamicReasoningGraph", inconsistencies: List[Inconsistency]
    ) -> List[ResolutionResult]:
        """ë¶ˆì¼ì¹˜ í•´ê²°"""
        logger.info(f"ë¶ˆì¼ì¹˜ í•´ê²° ì‹œì‘: {len(inconsistencies)}ê°œ ë¶ˆì¼ì¹˜")

        resolution_results = []
        modified_nodes = set()  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€
        modified_edges = set()  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€

        for inconsistency in inconsistencies:
            # ë¶ˆì¼ì¹˜ ìœ í˜•ì— ë”°ë¥¸ í•´ê²° ì „ëµ ì„ íƒ
            strategy = self._select_resolution_strategy(inconsistency)

            # í•´ê²° ì‹¤í–‰ (ì¤‘ë³µ ìˆ˜ì • ë°©ì§€)
            resolution_result = await self._execute_resolution_strategy(
                graph, inconsistency, strategy, modified_nodes, modified_edges
            )

            if resolution_result:
                resolution_results.append(resolution_result)
                # ìˆ˜ì •ëœ ë…¸ë“œì™€ ì—£ì§€ ê¸°ë¡
                modified_nodes.update(resolution_result.modified_nodes)
                modified_edges.update(resolution_result.modified_edges)

        logger.info(f"ë¶ˆì¼ì¹˜ í•´ê²° ì™„ë£Œ: {len(resolution_results)}ê°œ í•´ê²°ë¨")
        return resolution_results

    def _select_resolution_strategy(self, inconsistency: Inconsistency) -> ResolutionStrategy:
        """í•´ê²° ì „ëµ ì„ íƒ"""
        if inconsistency.inconsistency_type == InconsistencyType.LOGICAL_CONTRADICTION:
            return ResolutionStrategy.CONTRADICTION_RESOLUTION
        elif inconsistency.inconsistency_type == InconsistencyType.SEMANTIC_INCONSISTENCY:
            return ResolutionStrategy.NODE_MODIFICATION
        elif inconsistency.inconsistency_type == InconsistencyType.STRUCTURAL_INCONSISTENCY:
            return ResolutionStrategy.PATH_RECONSTRUCTION
        elif inconsistency.inconsistency_type == InconsistencyType.CONFLICTING_EVIDENCE:
            return ResolutionStrategy.EVIDENCE_WEIGHTING
        else:
            return ResolutionStrategy.EDGE_ADJUSTMENT

    async def _execute_resolution_strategy(
        self,
        graph: "DynamicReasoningGraph",
        inconsistency: Inconsistency,
        strategy: ResolutionStrategy,
        modified_nodes: Set[str],
        modified_edges: Set[str],
    ) -> Optional[ResolutionResult]:
        """í•´ê²° ì „ëµ ì‹¤í–‰"""
        try:
            if strategy == ResolutionStrategy.NODE_MODIFICATION:
                return await self._resolve_node_modification(graph, inconsistency, modified_nodes)
            elif strategy == ResolutionStrategy.EDGE_ADJUSTMENT:
                return await self._resolve_edge_adjustment(graph, inconsistency, modified_edges)
            elif strategy == ResolutionStrategy.PATH_RECONSTRUCTION:
                return await self._resolve_path_reconstruction(graph, inconsistency, modified_nodes)
            elif strategy == ResolutionStrategy.EVIDENCE_WEIGHTING:
                return await self._resolve_evidence_weighting(graph, inconsistency, modified_nodes)
            elif strategy == ResolutionStrategy.CONTRADICTION_RESOLUTION:
                return await self._resolve_contradiction_resolution(
                    graph, inconsistency, modified_nodes, modified_edges
                )
            else:
                return None
        except Exception as e:
            logger.error(f"í•´ê²° ì „ëµ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None

    async def _resolve_node_modification(
        self,
        graph: "DynamicReasoningGraph",
        inconsistency: Inconsistency,
        modified_nodes: Set[str],
    ) -> ResolutionResult:
        """ë…¸ë“œ ìˆ˜ì • ì „ëµ"""
        nodes_to_modify = []

        for node_id in inconsistency.affected_nodes:
            node = graph.nodes.get(node_id)
            if node:
                # ë…¸ë“œ ì‹ ë¢°ë„ ì¡°ì •
                original_confidence = node.confidence  # noqa: F841
                node.confidence = max(0.1, node.confidence * 0.8)  # ì‹ ë¢°ë„ ê°ì†Œ
                modified_nodes.add(node_id)  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€
                nodes_to_modify.append(node_id)

        return ResolutionResult(
            resolution_id=f"node_modification_{inconsistency.inconsistency_id}",
            inconsistency_id=inconsistency.inconsistency_id,
            strategy=ResolutionStrategy.NODE_MODIFICATION,
            success=len(nodes_to_modify) > 0,
            confidence=0.7,
            description=f"ë…¸ë“œ ìˆ˜ì •: {len(nodes_to_modify)}ê°œ ë…¸ë“œ ì‹ ë¢°ë„ ì¡°ì •",
            modified_nodes=nodes_to_modify,
        )

    async def _resolve_edge_adjustment(
        self,
        graph: "DynamicReasoningGraph",
        inconsistency: Inconsistency,
        modified_edges: Set[str],
    ) -> ResolutionResult:
        """ì—£ì§€ ì¡°ì • ì „ëµ"""
        edges_to_modify = []

        for edge_id in inconsistency.affected_edges:
            edge = graph.edges.get(edge_id)
            if edge:
                # ì—£ì§€ ê°•ë„ ì¡°ì •
                original_strength = edge.strength  # noqa: F841
                edge.strength = max(0.1, edge.strength * 0.7)  # ê°•ë„ ê°ì†Œ
                modified_edges.add(edge_id)  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€
                edges_to_modify.append(edge_id)

        return ResolutionResult(
            resolution_id=f"edge_adjustment_{inconsistency.inconsistency_id}",
            inconsistency_id=inconsistency.inconsistency_id,
            strategy=ResolutionStrategy.EDGE_ADJUSTMENT,
            success=len(edges_to_modify) > 0,
            confidence=0.6,
            description=f"ì—£ì§€ ì¡°ì •: {len(edges_to_modify)}ê°œ ì—£ì§€ ê°•ë„ ì¡°ì •",
            modified_edges=edges_to_modify,
        )

    async def _resolve_path_reconstruction(
        self,
        graph: "DynamicReasoningGraph",
        inconsistency: Inconsistency,
        modified_nodes: Set[str],
    ) -> ResolutionResult:
        """ê²½ë¡œ ì¬êµ¬ì„± ì „ëµ"""
        # ê³ ë¦½ëœ ë…¸ë“œë“¤ì„ ë‹¤ë¥¸ ë…¸ë“œì™€ ì—°ê²°
        new_edges = []

        for node_id in inconsistency.affected_nodes:
            node = graph.nodes.get(node_id)
            if node:
                # ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë“œ ì°¾ê¸°
                best_similarity = 0.0
                best_target = None

                for target_id, target_node in graph.nodes.items():
                    if target_id != node_id:
                        similarity = self._calculate_semantic_similarity(node.content, target_node.content)
                        if similarity > best_similarity:
                            best_similarity = similarity
                            best_target = target_id

                # ìƒˆë¡œìš´ ì—£ì§€ ìƒì„±
                if best_target and best_similarity > 0.3:
                    new_edge_id = f"reconstructed_edge_{node_id}_{best_target}"
                    new_edge = DynamicReasoningEdge(
                        edge_id=new_edge_id,
                        source_node=node_id,
                        target_node=best_target,
                        edge_type=EdgeType.SUPPORTS,
                        strength=best_similarity,
                        reasoning="ê²½ë¡œ ì¬êµ¬ì„±ì„ í†µí•œ ì—°ê²°",
                    )
                    graph.edges[new_edge_id] = new_edge
                    new_edges.append(new_edge_id)
                    modified_nodes.add(node_id)  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€

        return ResolutionResult(
            resolution_id=f"path_reconstruction_{inconsistency.inconsistency_id}",
            inconsistency_id=inconsistency.inconsistency_id,
            strategy=ResolutionStrategy.PATH_RECONSTRUCTION,
            success=len(new_edges) > 0,
            confidence=0.5,
            description=f"ê²½ë¡œ ì¬êµ¬ì„±: {len(new_edges)}ê°œ ìƒˆ ì—£ì§€ ìƒì„±",
            modified_nodes=list(modified_nodes),  # Set to List for JSON serialization
        )

    async def _resolve_evidence_weighting(
        self,
        graph: "DynamicReasoningGraph",
        inconsistency: Inconsistency,
        modified_nodes: Set[str],
    ) -> ResolutionResult:
        """ì¦ê±° ê°€ì¤‘ì¹˜ ì¡°ì • ì „ëµ"""
        nodes_to_modify = []

        for node_id in inconsistency.affected_nodes:
            node = graph.nodes.get(node_id)
            if node and node.node_type.value == "evidence":
                # ì¦ê±° ë…¸ë“œì˜ ì¤‘ìš”ë„ ì¡°ì •
                original_importance = node.importance_score  # noqa: F841
                node.importance_score = max(0.1, node.importance_score * 0.6)  # ì¤‘ìš”ë„ ê°ì†Œ
                modified_nodes.add(node_id)  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€
                nodes_to_modify.append(node_id)

        return ResolutionResult(
            resolution_id=f"evidence_weighting_{inconsistency.inconsistency_id}",
            inconsistency_id=inconsistency.inconsistency_id,
            strategy=ResolutionStrategy.EVIDENCE_WEIGHTING,
            success=len(nodes_to_modify) > 0,
            confidence=0.6,
            description=f"ì¦ê±° ê°€ì¤‘ì¹˜ ì¡°ì •: {len(nodes_to_modify)}ê°œ ì¦ê±° ë…¸ë“œ ì¤‘ìš”ë„ ì¡°ì •",
            modified_nodes=nodes_to_modify,
        )

    async def _resolve_contradiction_resolution(
        self,
        graph: "DynamicReasoningGraph",
        inconsistency: Inconsistency,
        modified_nodes: Set[str],
        modified_edges: Set[str],
    ) -> ResolutionResult:
        """ëª¨ìˆœ í•´ê²° ì „ëµ"""
        nodes_to_modify = []
        edges_to_modify = []

        # ëª¨ìˆœëœ ë…¸ë“œë“¤ì˜ ì‹ ë¢°ë„ ì¡°ì •
        for node_id in inconsistency.affected_nodes:
            node = graph.nodes.get(node_id)
            if node:
                # ëª¨ìˆœëœ ë…¸ë“œì˜ ì‹ ë¢°ë„ ê°ì†Œ
                node.confidence = max(0.1, node.confidence * 0.5)
                modified_nodes.add(node_id)  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€
                nodes_to_modify.append(node_id)

        # ëª¨ìˆœì„ ë‚˜íƒ€ë‚´ëŠ” ì—£ì§€ë“¤ì˜ ê°•ë„ ì¡°ì •
        for edge_id in inconsistency.affected_edges:
            edge = graph.edges.get(edge_id)
            if edge:
                edge.strength = max(0.1, edge.strength * 0.3)
                modified_edges.add(edge_id)  # ì¤‘ë³µ ìˆ˜ì • ë°©ì§€
                edges_to_modify.append(edge_id)

        return ResolutionResult(
            resolution_id=f"contradiction_resolution_{inconsistency.inconsistency_id}",
            inconsistency_id=inconsistency.inconsistency_id,
            strategy=ResolutionStrategy.CONTRADICTION_RESOLUTION,
            success=len(nodes_to_modify) > 0 or len(edges_to_modify) > 0,
            confidence=0.8,
            description=f"ëª¨ìˆœ í•´ê²°: {len(nodes_to_modify)}ê°œ ë…¸ë“œ, {len(edges_to_modify)}ê°œ ì—£ì§€ ì¡°ì •",
            modified_nodes=nodes_to_modify,
            modified_edges=edges_to_modify,
        )

    def _calculate_semantic_similarity(self, text1: str, text2: str) -> float:
        """ì˜ë¯¸ì  ìœ ì‚¬ë„ ê³„ì‚°"""
        keywords1 = set(re.findall(r"\w+", text1.lower()))
        keywords2 = set(re.findall(r"\w+", text2.lower()))

        if not keywords1 or not keywords2:
            return 0.0

        intersection = len(keywords1.intersection(keywords2))
        union = len(keywords1.union(keywords2))

        return intersection / union if union > 0 else 0.0


class InconsistencyValidator:
    """ë¶ˆì¼ì¹˜ í•´ê²° ê²€ì¦ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.validation_criteria = self._initialize_validation_criteria()

    def _initialize_validation_criteria(self) -> Dict[str, Dict[str, Any]]:
        """ê²€ì¦ ê¸°ì¤€ ì´ˆê¸°í™”"""
        return {
            "resolution_success": {"weight": 0.4, "description": "í•´ê²° ì„±ê³µë¥ "},
            "system_stability": {"weight": 0.3, "description": "ì‹œìŠ¤í…œ ì•ˆì •ì„±"},
            "quality_improvement": {"weight": 0.3, "description": "í’ˆì§ˆ í–¥ìƒë„"},
        }

    async def validate_resolution_results(
        self,
        graph: "DynamicReasoningGraph",
        inconsistencies: List[Inconsistency],
        resolution_results: List[ResolutionResult],
    ) -> Dict[str, Any]:
        """í•´ê²° ê²°ê³¼ ê²€ì¦"""
        logger.info(f"í•´ê²° ê²°ê³¼ ê²€ì¦ ì‹œì‘: {len(resolution_results)}ê°œ í•´ê²° ê²°ê³¼")

        # 1. í•´ê²° ì„±ê³µë¥  ê³„ì‚°
        resolution_success_rate = self._calculate_resolution_success_rate(resolution_results)

        # 2. ì‹œìŠ¤í…œ ì•ˆì •ì„± í‰ê°€
        system_stability = await self._evaluate_system_stability(graph)

        # 3. í’ˆì§ˆ í–¥ìƒë„ í‰ê°€
        quality_improvement = await self._evaluate_quality_improvement(graph, inconsistencies)

        # ì¢…í•© ê²€ì¦ ê²°ê³¼
        overall_validation_score = (
            resolution_success_rate * self.validation_criteria["resolution_success"]["weight"]
            + system_stability * self.validation_criteria["system_stability"]["weight"]
            + quality_improvement * self.validation_criteria["quality_improvement"]["weight"]
        )

        return {
            "overall_validation_score": overall_validation_score,
            "resolution_success_rate": resolution_success_rate,
            "system_stability": system_stability,
            "quality_improvement": quality_improvement,
            "validation_details": {
                "total_inconsistencies": len(inconsistencies),
                "resolved_inconsistencies": len([r for r in resolution_results if r.success]),
                "failed_resolutions": len([r for r in resolution_results if not r.success]),
                "modified_nodes": len(set([n for r in resolution_results for n in r.modified_nodes])),
                "modified_edges": len(set([e for r in resolution_results for e in r.modified_edges])),
            },
        }

    def _calculate_resolution_success_rate(self, resolution_results: List[ResolutionResult]) -> float:
        """í•´ê²° ì„±ê³µë¥  ê³„ì‚°"""
        if not resolution_results:
            return 0.0

        successful_resolutions = len([r for r in resolution_results if r.success])
        return successful_resolutions / len(resolution_results)

    async def _evaluate_system_stability(self, graph: "DynamicReasoningGraph") -> float:
        """ì‹œìŠ¤í…œ ì•ˆì •ì„± í‰ê°€"""
        # ë…¸ë“œ ì‹ ë¢°ë„ì˜ í‰ê· 
        node_confidences = [node.confidence for node in graph.nodes.values()]
        avg_node_confidence = sum(node_confidences) / len(node_confidences) if node_confidences else 0.0

        # ì—£ì§€ ê°•ë„ì˜ í‰ê· 
        edge_strengths = [edge.strength for edge in graph.edges.values()]
        avg_edge_strength = sum(edge_strengths) / len(edge_strengths) if edge_strengths else 0.0

        # ì‹œìŠ¤í…œ ì•ˆì •ì„± (ì‹ ë¢°ë„ì™€ ê°•ë„ì˜ í‰ê· )
        system_stability = (avg_node_confidence + avg_edge_strength) / 2.0
        return system_stability

    async def _evaluate_quality_improvement(
        self, graph: "DynamicReasoningGraph", inconsistencies: List[Inconsistency]
    ) -> float:
        """í’ˆì§ˆ í–¥ìƒë„ í‰ê°€"""
        # ë¶ˆì¼ì¹˜ ìˆ˜ì— ë”°ë¥¸ í’ˆì§ˆ ì ìˆ˜ (ë” ê´€ëŒ€í•œ ê¸°ì¤€ ì ìš©)
        total_nodes = len(graph.nodes)
        inconsistency_ratio = len(inconsistencies) / total_nodes if total_nodes > 0 else 0.0

        # ë¶ˆì¼ì¹˜ ë¹„ìœ¨ì´ ë‚®ì„ìˆ˜ë¡ í’ˆì§ˆì´ ë†’ìŒ (ë” ê´€ëŒ€í•œ ê¸°ì¤€)
        quality_score = max(0.0, 1.0 - inconsistency_ratio * 2)  # ê°€ì¤‘ì¹˜ ì¡°ì •

        # ë…¸ë“œ ê°„ ì—°ê²°ì„± ê³ ë ¤
        total_possible_connections = total_nodes * (total_nodes - 1) / 2
        actual_connections = len(graph.edges)
        connectivity_ratio = actual_connections / total_possible_connections if total_possible_connections > 0 else 0.0

        # ë…¸ë“œ ì‹ ë¢°ë„ í‰ê·  ê³ ë ¤
        node_confidences = [node.confidence for node in graph.nodes.values()]
        avg_confidence = sum(node_confidences) / len(node_confidences) if node_confidences else 0.0

        # ì—£ì§€ ê°•ë„ í‰ê·  ê³ ë ¤
        edge_strengths = [edge.strength for edge in graph.edges.values()]
        avg_strength = sum(edge_strengths) / len(edge_strengths) if edge_strengths else 0.0

        # ì¢…í•© í’ˆì§ˆ ì ìˆ˜ (ë” ê· í˜•ì¡íŒ ê°€ì¤‘ì¹˜)
        overall_quality = quality_score * 0.4 + connectivity_ratio * 0.2 + avg_confidence * 0.2 + avg_strength * 0.2

        return overall_quality


# í…ŒìŠ¤íŠ¸ìš© í´ë˜ìŠ¤ë“¤ (reasoning_path_validator.pyì—ì„œ ê°€ì ¸ì˜´)
class NodeType(Enum):
    """ë…¸ë“œ ìœ í˜• - í™•ì¥ëœ ë²„ì „"""

    PREMISE = "premise"
    INFERENCE = "inference"
    CONCLUSION = "conclusion"
    COUNTER_ARGUMENT = "counter_argument"
    EVIDENCE = "evidence"
    ASSUMPTION = "assumption"
    HYPOTHESIS = "hypothesis"
    CONSTRAINT = "constraint"
    ALTERNATIVE = "alternative"
    INTEGRATION = "integration"


class EdgeType(Enum):
    """ì—£ì§€ ìœ í˜• - í™•ì¥ëœ ë²„ì „"""

    SUPPORTS = "supports"
    CONTRADICTS = "contradicts"
    INFERS = "infers"
    ASSUMES = "assumes"
    EVIDENCES = "evidences"
    CONSTRAINS = "constrains"
    ALTERNATES = "alternates"
    INTEGRATES = "integrates"
    CHALLENGES = "challenges"
    REFINES = "refines"


@dataclass
class DynamicReasoningNode:
    """ë™ì  ì¶”ë¡  ë…¸ë“œ (í…ŒìŠ¤íŠ¸ìš©)"""

    node_id: str
    node_type: NodeType
    content: str
    confidence: float
    source: str
    metadata: Dict[str, Any] = field(default_factory=dict)
    semantic_vector: Optional[np.ndarray] = None
    activation_level: float = 1.0
    importance_score: float = 0.5


@dataclass
class DynamicReasoningEdge:
    """ë™ì  ì¶”ë¡  ì—£ì§€ (í…ŒìŠ¤íŠ¸ìš©)"""

    edge_id: str
    source_node: str
    target_node: str
    edge_type: EdgeType
    strength: float
    reasoning: str
    semantic_similarity: float = 0.0
    logical_validity: float = 0.0


@dataclass
class DynamicReasoningGraph:
    """ë™ì  ì¶”ë¡  ê·¸ë˜í”„ (í…ŒìŠ¤íŠ¸ìš©)"""

    graph_id: str
    nodes: Dict[str, DynamicReasoningNode] = field(default_factory=dict)
    edges: Dict[str, DynamicReasoningEdge] = field(default_factory=dict)


async def test_inconsistency_detector():
    """ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=== ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Phase 1-3 Week 3 Day 3) ===")

    # í…ŒìŠ¤íŠ¸ ê·¸ë˜í”„ ìƒì„±
    graph = DynamicReasoningGraph(graph_id="test_graph")

    # í…ŒìŠ¤íŠ¸ ë…¸ë“œë“¤ ìƒì„± (ì˜ë„ì ìœ¼ë¡œ ë¶ˆì¼ì¹˜ í¬í•¨)
    nodes = {
        "node1": DynamicReasoningNode("node1", NodeType.PREMISE, "ìœ¤ë¦¬ì  í–‰ë™ì€ ì˜³ë‹¤", 0.8, "test"),
        "node2": DynamicReasoningNode("node2", NodeType.PREMISE, "ìœ¤ë¦¬ì  í–‰ë™ì€ í‹€ë¦¬ë‹¤", 0.7, "test"),  # ëª¨ìˆœ
        "node3": DynamicReasoningNode("node3", NodeType.INFERENCE, "ì¹¸íŠ¸ì  ë¶„ì„", 0.6, "test"),
        "node4": DynamicReasoningNode("node4", NodeType.CONCLUSION, "ìµœì¢… íŒë‹¨", 0.9, "test"),
        "node5": DynamicReasoningNode("node5", NodeType.EVIDENCE, "ì¦ê±° A: ê¸ì •ì  ê²°ê³¼", 0.8, "test"),
        "node6": DynamicReasoningNode("node6", NodeType.EVIDENCE, "ì¦ê±° B: ë¶€ì •ì  ê²°ê³¼", 0.7, "test"),  # ìƒì¶©
        "node7": DynamicReasoningNode("node7", NodeType.COUNTER_ARGUMENT, "ë°˜ë¡ ", 0.5, "test"),
        "node8": DynamicReasoningNode("node8", NodeType.ASSUMPTION, "ê°€ì •", 0.6, "test"),
    }

    graph.nodes = nodes

    # í…ŒìŠ¤íŠ¸ ì—£ì§€ë“¤ ìƒì„±
    edges = {
        "edge1": DynamicReasoningEdge("edge1", "node1", "node3", EdgeType.SUPPORTS, 0.8, "ì§€ì›"),
        "edge2": DynamicReasoningEdge("edge2", "node2", "node3", EdgeType.CONTRADICTS, 0.7, "ëª¨ìˆœ"),  # ëª¨ìˆœ ì—£ì§€
        "edge3": DynamicReasoningEdge("edge3", "node3", "node4", EdgeType.INFERS, 0.9, "ì¶”ë¡ "),
        "edge4": DynamicReasoningEdge("edge4", "node5", "node4", EdgeType.EVIDENCES, 0.8, "ì¦ê±°"),
        "edge5": DynamicReasoningEdge("edge5", "node6", "node4", EdgeType.EVIDENCES, 0.7, "ì¦ê±°"),
        "edge6": DynamicReasoningEdge("edge6", "node7", "node4", EdgeType.CHALLENGES, 0.6, "ë„ì „"),
    }

    graph.edges = edges

    # 1. ë¶ˆì¼ì¹˜ íƒì§€ í…ŒìŠ¤íŠ¸
    detector = InconsistencyDetector()
    inconsistencies = await detector.detect_inconsistencies(graph)

    print("\nğŸ” ë¶ˆì¼ì¹˜ íƒì§€ ê²°ê³¼:")
    print(f"  â€¢ ë°œê²¬ëœ ë¶ˆì¼ì¹˜ ìˆ˜: {len(inconsistencies)}")
    for i, inconsistency in enumerate(inconsistencies):
        print(f"  â€¢ ë¶ˆì¼ì¹˜ {i+1}: {inconsistency.inconsistency_type.value} (ì‹¬ê°ë„: {inconsistency.severity:.2f})")
        print(f"    - ì„¤ëª…: {inconsistency.description}")
        print(f"    - ì˜í–¥ë°›ëŠ” ë…¸ë“œ: {inconsistency.affected_nodes}")

    # 2. ë¶ˆì¼ì¹˜ í•´ê²° í…ŒìŠ¤íŠ¸
    resolver = InconsistencyResolver()
    resolution_results = await resolver.resolve_inconsistencies(graph, inconsistencies)

    print("\nğŸ”§ ë¶ˆì¼ì¹˜ í•´ê²° ê²°ê³¼:")
    print(f"  â€¢ í•´ê²°ëœ ë¶ˆì¼ì¹˜ ìˆ˜: {len([r for r in resolution_results if r.success])}")
    for i, result in enumerate(resolution_results):
        print(f"  â€¢ í•´ê²° ê²°ê³¼ {i+1}: {result.strategy.value} (ì„±ê³µ: {result.success})")
        print(f"    - ì„¤ëª…: {result.description}")
        print(f"    - ìˆ˜ì •ëœ ë…¸ë“œ: {result.modified_nodes}")
        print(f"    - ìˆ˜ì •ëœ ì—£ì§€: {result.modified_edges}")

    # 3. í•´ê²° ê²°ê³¼ ê²€ì¦ í…ŒìŠ¤íŠ¸
    validator = InconsistencyValidator()
    validation_results = await validator.validate_resolution_results(graph, inconsistencies, resolution_results)

    print("\nğŸ“Š í•´ê²° ê²°ê³¼ ê²€ì¦:")
    print(f"  â€¢ ì¢…í•© ê²€ì¦ ì ìˆ˜: {validation_results['overall_validation_score']:.2f}")
    print(f"  â€¢ í•´ê²° ì„±ê³µë¥ : {validation_results['resolution_success_rate']:.2f}")
    print(f"  â€¢ ì‹œìŠ¤í…œ ì•ˆì •ì„±: {validation_results['system_stability']:.2f}")
    print(f"  â€¢ í’ˆì§ˆ í–¥ìƒë„: {validation_results['quality_improvement']:.2f}")
    print("  â€¢ ê²€ì¦ ì„¸ë¶€ì‚¬í•­:")
    print(f"    - ì´ ë¶ˆì¼ì¹˜ ìˆ˜: {validation_results['validation_details']['total_inconsistencies']}")
    print(f"    - í•´ê²°ëœ ë¶ˆì¼ì¹˜ ìˆ˜: {validation_results['validation_details']['resolved_inconsistencies']}")
    print(f"    - ì‹¤íŒ¨í•œ í•´ê²° ìˆ˜: {validation_results['validation_details']['failed_resolutions']}")
    print(f"    - ìˆ˜ì •ëœ ë…¸ë“œ ìˆ˜: {validation_results['validation_details']['modified_nodes']}")
    print(f"    - ìˆ˜ì •ëœ ì—£ì§€ ìˆ˜: {validation_results['validation_details']['modified_edges']}")

    print(f"\n{'='*70}")
    print("=== ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²° ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Phase 1-3 Week 3 Day 3) ===")
    print("âœ… Day 3 ëª©í‘œ ë‹¬ì„±: ë¶ˆì¼ì¹˜ íƒì§€ ë° í•´ê²° ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ë¶ˆì¼ì¹˜ íƒì§€ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ìë™ í•´ê²° ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… í•´ê²° ì „ëµ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„")


if __name__ == "__main__":
    asyncio.run(test_inconsistency_detector())
