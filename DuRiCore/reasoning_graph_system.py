#!/usr/bin/env python3
"""
DuRi ì‚¬ê³  ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ (Day 5)
ëª…ì‹œì  ì‚¬ê³  ê³¼ì • êµ¬ì¡°í™”
"""

import asyncio
import logging
import re
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NodeType(Enum):
    """ë…¸ë“œ ìœ í˜•"""

    PREMISE = "premise"
    INFERENCE = "inference"
    CONCLUSION = "conclusion"
    COUNTER_ARGUMENT = "counter_argument"
    EVIDENCE = "evidence"
    ASSUMPTION = "assumption"


class EdgeType(Enum):
    """ì—£ì§€ ìœ í˜•"""

    SUPPORTS = "supports"
    CONTRADICTS = "contradicts"
    INFERS = "infers"
    ASSUMES = "assumes"
    EVIDENCES = "evidences"


@dataclass
class ReasoningNode:
    """ì¶”ë¡  ë…¸ë“œ"""

    node_id: str
    node_type: NodeType
    content: str
    confidence: float  # 0.0-1.0
    source: str
    metadata: Dict[str, Any]


@dataclass
class ReasoningEdge:
    """ì¶”ë¡  ì—£ì§€"""

    edge_id: str
    source_node: str
    target_node: str
    edge_type: EdgeType
    strength: float  # 0.0-1.0
    reasoning: str


@dataclass
class ReasoningGraph:
    """ì¶”ë¡  ê·¸ë˜í”„"""

    graph_id: str
    nodes: Dict[str, ReasoningNode]
    edges: Dict[str, ReasoningEdge]
    root_nodes: List[str]
    leaf_nodes: List[str]
    confidence_score: float
    complexity_score: float


class ReasoningGraphBuilder:
    """ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶• ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.graph_counter = 0
        self.node_counter = 0
        self.edge_counter = 0

    def build_reasoning_chain(
        self,
        situation: str,
        semantic_context: Dict[str, Any],
        philosophical_arguments: Dict[str, Any],
    ) -> ReasoningGraph:
        """ì¶”ë¡  ì²´ì¸ êµ¬ì¶•"""
        logger.info(f"ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶• ì‹œì‘: {situation}")

        # ê·¸ë˜í”„ ì´ˆê¸°í™”
        graph_id = f"reasoning_graph_{self.graph_counter}"
        self.graph_counter += 1

        nodes = {}
        edges = {}
        root_nodes = []
        leaf_nodes = []

        # 1. ìƒí™© ë¶„ì„ ë…¸ë“œ ì¶”ê°€
        situation_nodes = self._create_situation_nodes(situation, semantic_context)
        nodes.update(situation_nodes)
        root_nodes.extend(situation_nodes.keys())

        # 2. ì² í•™ì  ë…¼ì¦ ë…¸ë“œ ì¶”ê°€
        philosophical_nodes = self._create_philosophical_nodes(philosophical_arguments)
        nodes.update(philosophical_nodes)

        # 3. ì¶”ë¡  ì—£ì§€ ìƒì„±
        reasoning_edges = self._create_reasoning_edges(nodes, situation, philosophical_arguments)
        edges.update(reasoning_edges)

        # 4. ê²°ë¡  ë…¸ë“œ ì¶”ê°€
        conclusion_nodes = self._create_conclusion_nodes(nodes, edges)
        nodes.update(conclusion_nodes)
        leaf_nodes.extend(conclusion_nodes.keys())

        # 5. ê·¸ë˜í”„ ë©”íŠ¸ë¦­ ê³„ì‚°
        confidence_score = self._calculate_graph_confidence(nodes, edges)
        complexity_score = self._calculate_graph_complexity(nodes, edges)

        reasoning_graph = ReasoningGraph(
            graph_id=graph_id,
            nodes=nodes,
            edges=edges,
            root_nodes=root_nodes,
            leaf_nodes=leaf_nodes,
            confidence_score=confidence_score,
            complexity_score=complexity_score,
        )

        logger.info(f"ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶• ì™„ë£Œ: {len(nodes)} ë…¸ë“œ, {len(edges)} ì—£ì§€")
        return reasoning_graph

    def _create_situation_nodes(self, situation: str, semantic_context) -> Dict[str, ReasoningNode]:
        """ìƒí™© ë¶„ì„ ë…¸ë“œ ìƒì„±"""
        nodes = {}

        # ìƒí™© ìœ í˜• ë…¸ë“œ
        situation_type_node = ReasoningNode(
            node_id=f"node_{self.node_counter}",
            node_type=NodeType.PREMISE,
            content=f"ìƒí™© ìœ í˜•: {semantic_context.situation_type.value if hasattr(semantic_context, 'situation_type') else 'unknown'}",  # noqa: E501
            confidence=(semantic_context.confidence_score if hasattr(semantic_context, "confidence_score") else 0.5),
            source="Semantic Analysis",
            metadata={
                "situation_type": (
                    semantic_context.situation_type.value if hasattr(semantic_context, "situation_type") else "unknown"
                )
            },
        )
        nodes[situation_type_node.node_id] = situation_type_node
        self.node_counter += 1

        # ì˜ë„ ë…¸ë“œ
        intent_node = ReasoningNode(
            node_id=f"node_{self.node_counter}",
            node_type=NodeType.PREMISE,
            content=f"ì˜ë„: {semantic_context.intent.value if hasattr(semantic_context, 'intent') else 'unknown'}",
            confidence=(semantic_context.confidence_score if hasattr(semantic_context, "confidence_score") else 0.5),
            source="Intent Analysis",
            metadata={"intent": (semantic_context.intent.value if hasattr(semantic_context, "intent") else "unknown")},
        )
        nodes[intent_node.node_id] = intent_node
        self.node_counter += 1

        # ê°€ì¹˜ ì¶©ëŒ ë…¸ë“œë“¤
        value_conflicts = semantic_context.value_conflicts if hasattr(semantic_context, "value_conflicts") else []
        for i, conflict in enumerate(value_conflicts):
            conflict_node = ReasoningNode(
                node_id=f"node_{self.node_counter}",
                node_type=NodeType.PREMISE,
                content=f"ê°€ì¹˜ ì¶©ëŒ {i+1}: {conflict.value if hasattr(conflict, 'value') else conflict}",
                confidence=0.7,
                source="Value Conflict Analysis",
                metadata={"conflict_type": (conflict.value if hasattr(conflict, "value") else conflict)},
            )
            nodes[conflict_node.node_id] = conflict_node
            self.node_counter += 1

        return nodes

    def _create_philosophical_nodes(self, philosophical_arguments: Dict[str, Any]) -> Dict[str, ReasoningNode]:
        """ì² í•™ì  ë…¼ì¦ ë…¸ë“œ ìƒì„±"""
        nodes = {}

        # ì¹¸íŠ¸ì  ë¶„ì„ ë…¸ë“œ
        if "kantian" in philosophical_arguments:
            kantian = philosophical_arguments["kantian"]
            kantian_node = ReasoningNode(
                node_id=f"node_{self.node_counter}",
                node_type=NodeType.INFERENCE,
                content=f"ì¹¸íŠ¸ì  ë¶„ì„: {kantian.final_conclusion if hasattr(kantian, 'final_conclusion') else 'ë¶„ì„ ì—†ìŒ'}",  # noqa: E501
                confidence=kantian.strength if hasattr(kantian, "strength") else 0.5,
                source="Kantian Reasoning",
                metadata={
                    "reasoning_type": "kantian",
                    "strength": (kantian.strength if hasattr(kantian, "strength") else 0.5),
                },
            )
            nodes[kantian_node.node_id] = kantian_node
            self.node_counter += 1

        # ê³µë¦¬ì£¼ì˜ ë¶„ì„ ë…¸ë“œ
        if "utilitarian" in philosophical_arguments:
            utilitarian = philosophical_arguments["utilitarian"]
            utilitarian_node = ReasoningNode(
                node_id=f"node_{self.node_counter}",
                node_type=NodeType.INFERENCE,
                content=f"ê³µë¦¬ì£¼ì˜ ë¶„ì„: {utilitarian.final_conclusion if hasattr(utilitarian, 'final_conclusion') else 'ë¶„ì„ ì—†ìŒ'}",  # noqa: E501
                confidence=(utilitarian.strength if hasattr(utilitarian, "strength") else 0.5),
                source="Utilitarian Reasoning",
                metadata={
                    "reasoning_type": "utilitarian",
                    "strength": (utilitarian.strength if hasattr(utilitarian, "strength") else 0.5),
                },
            )
            nodes[utilitarian_node.node_id] = utilitarian_node
            self.node_counter += 1

        # í†µí•© ë¶„ì„ ë…¸ë“œ
        if "integrated" in philosophical_arguments:
            integrated = philosophical_arguments["integrated"]
            integrated_node = ReasoningNode(
                node_id=f"node_{self.node_counter}",
                node_type=NodeType.INFERENCE,
                content=f"í†µí•© ë¶„ì„: {integrated.get('recommendation', 'ë¶„ì„ ì—†ìŒ')}",
                confidence=integrated.get("strength", 0.5),
                source="Multi-Perspective Analysis",
                metadata={
                    "reasoning_type": "integrated",
                    "strength": integrated.get("strength"),
                },
            )
            nodes[integrated_node.node_id] = integrated_node
            self.node_counter += 1

        return nodes

    def _create_reasoning_edges(
        self,
        nodes: Dict[str, ReasoningNode],
        situation: str,
        philosophical_arguments: Dict[str, Any],
    ) -> Dict[str, ReasoningEdge]:
        """ì¶”ë¡  ì—£ì§€ ìƒì„±"""
        edges = {}

        # ìƒí™© ë¶„ì„ â†’ ì² í•™ì  ë¶„ì„ ì—°ê²°
        situation_nodes = [n for n in nodes.values() if n.node_type == NodeType.PREMISE]
        philosophical_nodes = [n for n in nodes.values() if n.node_type == NodeType.INFERENCE]

        for situation_node in situation_nodes:
            for philosophical_node in philosophical_nodes:
                edge = ReasoningEdge(
                    edge_id=f"edge_{self.edge_counter}",
                    source_node=situation_node.node_id,
                    target_node=philosophical_node.node_id,
                    edge_type=EdgeType.SUPPORTS,
                    strength=0.6,
                    reasoning=f"{situation_node.content}ì´ {philosophical_node.content}ë¥¼ ì§€ì›í•¨",
                )
                edges[edge.edge_id] = edge
                self.edge_counter += 1

        # ì² í•™ì  ë¶„ì„ ê°„ ì—°ê²°
        if len(philosophical_nodes) > 1:
            for i, node1 in enumerate(philosophical_nodes):
                for node2 in philosophical_nodes[i + 1 :]:
                    edge = ReasoningEdge(
                        edge_id=f"edge_{self.edge_counter}",
                        source_node=node1.node_id,
                        target_node=node2.node_id,
                        edge_type=EdgeType.INFERS,
                        strength=0.5,
                        reasoning=f"{node1.content}ê³¼ {node2.content} ê°„ì˜ ë…¼ë¦¬ì  ê´€ê³„",
                    )
                    edges[edge.edge_id] = edge
                    self.edge_counter += 1

        return edges

    def _create_conclusion_nodes(
        self, nodes: Dict[str, ReasoningNode], edges: Dict[str, ReasoningEdge]
    ) -> Dict[str, ReasoningNode]:
        """ê²°ë¡  ë…¸ë“œ ìƒì„±"""
        conclusion_nodes = {}

        # ìµœì¢… ê²°ë¡  ë…¸ë“œ
        final_conclusion_node = ReasoningNode(
            node_id=f"node_{self.node_counter}",
            node_type=NodeType.CONCLUSION,
            content="ìµœì¢… ë„ë•ì  íŒë‹¨",
            confidence=0.7,
            source="Final Reasoning",
            metadata={"conclusion_type": "final_judgment"},
        )
        conclusion_nodes[final_conclusion_node.node_id] = final_conclusion_node
        self.node_counter += 1

        # ë°˜ë¡  ë…¸ë“œ
        counter_argument_node = ReasoningNode(
            node_id=f"node_{self.node_counter}",
            node_type=NodeType.COUNTER_ARGUMENT,
            content="ëŒ€ì•ˆì  ê´€ì  ë° ë°˜ë¡ ",
            confidence=0.6,
            source="Counter Analysis",
            metadata={"counter_type": "alternative_perspectives"},
        )
        conclusion_nodes[counter_argument_node.node_id] = counter_argument_node
        self.node_counter += 1

        return conclusion_nodes

    def _calculate_graph_confidence(self, nodes: Dict[str, ReasoningNode], edges: Dict[str, ReasoningEdge]) -> float:
        """ê·¸ë˜í”„ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not nodes:
            return 0.0

        # ë…¸ë“œ ì‹ ë¢°ë„ì˜ í‰ê· 
        node_confidences = [node.confidence for node in nodes.values()]
        avg_node_confidence = sum(node_confidences) / len(node_confidences)

        # ì—£ì§€ ê°•ë„ì˜ í‰ê· 
        if edges:
            edge_strengths = [edge.strength for edge in edges.values()]
            avg_edge_strength = sum(edge_strengths) / len(edge_strengths)
        else:
            avg_edge_strength = 0.5

        # ì¢…í•© ì‹ ë¢°ë„
        overall_confidence = (avg_node_confidence + avg_edge_strength) / 2
        return min(max(overall_confidence, 0.0), 1.0)

    def _calculate_graph_complexity(self, nodes: Dict[str, ReasoningNode], edges: Dict[str, ReasoningEdge]) -> float:
        """ê·¸ë˜í”„ ë³µì¡ë„ ê³„ì‚°"""
        complexity = 0.0

        # ë…¸ë“œ ìˆ˜ì— ë”°ë¥¸ ë³µì¡ë„
        node_complexity = min(len(nodes) / 10.0, 1.0)
        complexity += node_complexity * 0.3

        # ì—£ì§€ ìˆ˜ì— ë”°ë¥¸ ë³µì¡ë„
        edge_complexity = min(len(edges) / 15.0, 1.0)
        complexity += edge_complexity * 0.3

        # ë…¸ë“œ ìœ í˜• ë‹¤ì–‘ì„±ì— ë”°ë¥¸ ë³µì¡ë„
        node_types = set(node.node_type for node in nodes.values())
        type_diversity = len(node_types) / 6.0  # ìµœëŒ€ 6ê°œ ìœ í˜•
        complexity += type_diversity * 0.2

        # ì—£ì§€ ìœ í˜• ë‹¤ì–‘ì„±ì— ë”°ë¥¸ ë³µì¡ë„
        edge_types = set(edge.edge_type for edge in edges.values())
        edge_diversity = len(edge_types) / 5.0  # ìµœëŒ€ 5ê°œ ìœ í˜•
        complexity += edge_diversity * 0.2

        return min(complexity, 1.0)


class LogicalInferenceEngine:
    """ë…¼ë¦¬ì  ì¶”ë¡  ì—”ì§„"""

    def __init__(self):
        self.inference_rules = self._initialize_inference_rules()
        self.logical_operators = self._initialize_logical_operators()

    def _initialize_inference_rules(self) -> Dict[str, str]:
        """ì¶”ë¡  ê·œì¹™ ì´ˆê¸°í™”"""
        return {
            "modus_ponens": "P â†’ Q, P âŠ¢ Q",
            "modus_tollens": "P â†’ Q, Â¬Q âŠ¢ Â¬P",
            "hypothetical_syllogism": "P â†’ Q, Q â†’ R âŠ¢ P â†’ R",
            "disjunctive_syllogism": "P âˆ¨ Q, Â¬P âŠ¢ Q",
            "constructive_dilemma": "(P â†’ Q) âˆ§ (R â†’ S), P âˆ¨ R âŠ¢ Q âˆ¨ S",
        }

    def _initialize_logical_operators(self) -> Dict[str, str]:
        """ë…¼ë¦¬ ì—°ì‚°ì ì´ˆê¸°í™”"""
        return {"and": "âˆ§", "or": "âˆ¨", "not": "Â¬", "implies": "â†’", "iff": "â†”"}

    async def apply_logical_inference(self, premises: List[str], conclusion: str) -> Dict[str, Any]:
        """ë…¼ë¦¬ì  ì¶”ë¡  ì ìš©"""
        logger.info(f"ë…¼ë¦¬ì  ì¶”ë¡  ì‹œì‘: {len(premises)} ì „ì œ")

        # ì¶”ë¡  ìœ íš¨ì„± ê²€ì‚¬
        validity_check = self._check_inference_validity(premises, conclusion)

        # ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬
        consistency_check = self._check_logical_consistency(premises)

        # ì¶”ë¡  ê°•ë„ ê³„ì‚°
        inference_strength = self._calculate_inference_strength(premises, conclusion)

        return {
            "is_valid": validity_check["is_valid"],
            "is_consistent": consistency_check["is_consistent"],
            "inference_strength": inference_strength,
            "reasoning": validity_check["reasoning"],
            "counter_examples": validity_check["counter_examples"],
        }

    def _check_inference_validity(self, premises: List[str], conclusion: str) -> Dict[str, Any]:
        """ì¶”ë¡  ìœ íš¨ì„± ê²€ì‚¬"""
        validity_result = {"is_valid": True, "reasoning": "", "counter_examples": []}

        # ê¸°ë³¸ì ì¸ ë…¼ë¦¬ì  ê²€ì‚¬
        if not premises:
            validity_result.update(
                {
                    "is_valid": False,
                    "reasoning": "ì „ì œê°€ ì—†ìœ¼ë©´ ìœ íš¨í•œ ì¶”ë¡ ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤",
                }
            )
            return validity_result

        # ê²°ë¡ ì´ ì „ì œì—ì„œ ë…¼ë¦¬ì ìœ¼ë¡œ ë„ì¶œë˜ëŠ”ì§€ ê²€ì‚¬
        conclusion_keywords = set(re.findall(r"\w+", conclusion.lower()))
        premise_keywords = set()
        for premise in premises:
            premise_keywords.update(re.findall(r"\w+", premise.lower()))

        # ê²°ë¡ ì˜ ì£¼ìš” ê°œë…ì´ ì „ì œì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì‚¬
        if not conclusion_keywords.issubset(premise_keywords):
            validity_result.update(
                {
                    "is_valid": False,
                    "reasoning": "ê²°ë¡ ì— ì „ì œì— ì—†ëŠ” ìƒˆë¡œìš´ ê°œë…ì´ í¬í•¨ë˜ì–´ ìˆë‹¤",
                }
            )

        return validity_result

    def _check_logical_consistency(self, premises: List[str]) -> Dict[str, Any]:
        """ë…¼ë¦¬ì  ì¼ê´€ì„± ê²€ì‚¬"""
        consistency_result = {"is_consistent": True, "contradictions": []}

        # ëª¨ìˆœë˜ëŠ” ì „ì œ ê²€ì‚¬
        for i, premise1 in enumerate(premises):
            for premise2 in premises[i + 1 :]:
                if self._are_contradictory(premise1, premise2):
                    consistency_result["contradictions"].append({"premise1": premise1, "premise2": premise2})
                    consistency_result["is_consistent"] = False

        return consistency_result

    def _are_contradictory(self, premise1: str, premise2: str) -> bool:
        """ë‘ ì „ì œê°€ ëª¨ìˆœë˜ëŠ”ì§€ ê²€ì‚¬"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ëª¨ìˆœ ê²€ì‚¬
        contradiction_patterns = [
            (["í—ˆìš©", "ê¸ˆì§€"], ["ê¸ˆì§€", "í—ˆìš©"]),
            (["ì˜³ë‹¤", "í‹€ë¦¬ë‹¤"], ["í‹€ë¦¬ë‹¤", "ì˜³ë‹¤"]),
            (["ì°¸", "ê±°ì§“"], ["ê±°ì§“", "ì°¸"]),
        ]

        for pattern1, pattern2 in contradiction_patterns:
            if any(word in premise1 for word in pattern1) and any(word in premise2 for word in pattern2):
                return True

        return False

    def _calculate_inference_strength(self, premises: List[str], conclusion: str) -> float:
        """ì¶”ë¡  ê°•ë„ ê³„ì‚°"""
        strength = 0.5  # ê¸°ë³¸ê°’

        # ì „ì œ ìˆ˜ì— ë”°ë¥¸ ê°•ë„
        if len(premises) >= 3:
            strength += 0.2
        elif len(premises) >= 2:
            strength += 0.1

        # ì „ì œì™€ ê²°ë¡ ì˜ ê´€ë ¨ì„±
        premise_keywords = set()
        for premise in premises:
            premise_keywords.update(re.findall(r"\w+", premise.lower()))

        conclusion_keywords = set(re.findall(r"\w+", conclusion.lower()))

        overlap = len(premise_keywords.intersection(conclusion_keywords))
        total = len(premise_keywords.union(conclusion_keywords))

        if total > 0:
            relevance = overlap / total
            strength += relevance * 0.3

        return min(max(strength, 0.0), 1.0)


class ReasoningGraphAnalyzer:
    """ì¶”ë¡  ê·¸ë˜í”„ ë¶„ì„ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.graph_builder = ReasoningGraphBuilder()
        self.inference_engine = LogicalInferenceEngine()

    async def analyze_reasoning_process(
        self,
        situation: str,
        semantic_context: Dict[str, Any],
        philosophical_arguments: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ì¶”ë¡  ê³¼ì • ë¶„ì„"""
        logger.info(f"ì¶”ë¡  ê³¼ì • ë¶„ì„ ì‹œì‘: {situation}")

        # 1. ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶•
        reasoning_graph = self.graph_builder.build_reasoning_chain(situation, semantic_context, philosophical_arguments)

        # 2. ë…¼ë¦¬ì  ì¶”ë¡  ì ìš©
        premises = [node.content for node in reasoning_graph.nodes.values() if node.node_type == NodeType.PREMISE]
        conclusions = [node.content for node in reasoning_graph.nodes.values() if node.node_type == NodeType.CONCLUSION]

        inference_results = []
        for conclusion in conclusions:
            inference_result = await self.inference_engine.apply_logical_inference(premises, conclusion)
            inference_results.append(inference_result)

        # 3. ê·¸ë˜í”„ ë¶„ì„
        graph_analysis = self._analyze_graph_structure(reasoning_graph)

        # 4. ì¶”ë¡  í’ˆì§ˆ í‰ê°€
        quality_assessment = self._assess_reasoning_quality(reasoning_graph, inference_results)

        return {
            "reasoning_graph": reasoning_graph,
            "inference_results": inference_results,
            "graph_analysis": graph_analysis,
            "quality_assessment": quality_assessment,
        }

    def _analyze_graph_structure(self, graph: ReasoningGraph) -> Dict[str, Any]:
        """ê·¸ë˜í”„ êµ¬ì¡° ë¶„ì„"""
        analysis = {
            "node_count": len(graph.nodes),
            "edge_count": len(graph.edges),
            "node_types": {},
            "edge_types": {},
            "connectivity": 0.0,
            "depth": 0,
        }

        # ë…¸ë“œ ìœ í˜• ë¶„í¬
        for node in graph.nodes.values():
            node_type = node.node_type.value
            analysis["node_types"][node_type] = analysis["node_types"].get(node_type, 0) + 1

        # ì—£ì§€ ìœ í˜• ë¶„í¬
        for edge in graph.edges.values():
            edge_type = edge.edge_type.value
            analysis["edge_types"][edge_type] = analysis["edge_types"].get(edge_type, 0) + 1

        # ì—°ê²°ì„± ê³„ì‚°
        if len(graph.nodes) > 1:
            analysis["connectivity"] = len(graph.edges) / (len(graph.nodes) * (len(graph.nodes) - 1))

        # ê¹Šì´ ê³„ì‚° (ê°„ë‹¨í•œ ì¶”ì •)
        analysis["depth"] = min(len(graph.nodes) // 3, 5)

        return analysis

    def _assess_reasoning_quality(
        self, graph: ReasoningGraph, inference_results: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ì¶”ë¡  í’ˆì§ˆ í‰ê°€"""
        quality = {
            "overall_quality": 0.0,
            "logical_consistency": 0.0,
            "completeness": 0.0,
            "clarity": 0.0,
            "strength": 0.0,
        }

        # ë…¼ë¦¬ì  ì¼ê´€ì„±
        valid_inferences = sum(1 for result in inference_results if result["is_valid"])
        quality["logical_consistency"] = valid_inferences / len(inference_results) if inference_results else 0.0

        # ì™„ì „ì„± (ëª¨ë“  ë…¸ë“œ ìœ í˜•ì´ í¬í•¨ë˜ì—ˆëŠ”ì§€)
        node_types = set(node.node_type for node in graph.nodes.values())
        quality["completeness"] = len(node_types) / 6.0  # ìµœëŒ€ 6ê°œ ìœ í˜•

        # ëª…í™•ì„± (ë…¸ë“œì˜ í‰ê·  ì‹ ë¢°ë„)
        node_confidences = [node.confidence for node in graph.nodes.values()]
        quality["clarity"] = sum(node_confidences) / len(node_confidences) if node_confidences else 0.0

        # ê°•ë„ (ì—£ì§€ì˜ í‰ê·  ê°•ë„)
        edge_strengths = [edge.strength for edge in graph.edges.values()]
        quality["strength"] = sum(edge_strengths) / len(edge_strengths) if edge_strengths else 0.0

        # ì¢…í•© í’ˆì§ˆ
        quality["overall_quality"] = (
            quality["logical_consistency"] * 0.3
            + quality["completeness"] * 0.2
            + quality["clarity"] * 0.25
            + quality["strength"] * 0.25
        )

        return quality


async def test_reasoning_graph_system():
    """ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    print("=== ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘ (Day 5) ===")

    analyzer = ReasoningGraphAnalyzer()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_situation = "ê±°ì§“ë§ì„ í•´ì•¼ í•˜ëŠ” ìƒí™©"
    test_semantic_context = {
        "situation_type": "ethical_dilemma",
        "intent": "deception",
        "value_conflicts": ["honesty_vs_harm_prevention"],
        "confidence_score": 0.9,
    }
    test_philosophical_arguments = {
        "kantian": {
            "final_conclusion": "ê±°ì§“ë§ì€ ë„ë•ì ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠëŠ”ë‹¤",
            "strength": 0.8,
        },
        "utilitarian": {
            "final_conclusion": "ê±°ì§“ë§ì€ ë„ë•ì ìœ¼ë¡œ í—ˆìš©ë˜ì§€ ì•ŠëŠ”ë‹¤",
            "strength": 0.7,
        },
        "integrated": {
            "recommendation": "ë‘ ê´€ì  ëª¨ë‘ ê±°ì§“ë§ì„ ê¸ˆì§€í•œë‹¤",
            "strength": 0.75,
        },
    }

    # ì¶”ë¡  ê³¼ì • ë¶„ì„
    analysis_result = await analyzer.analyze_reasoning_process(
        test_situation, test_semantic_context, test_philosophical_arguments
    )

    # ê²°ê³¼ ì¶œë ¥
    reasoning_graph = analysis_result["reasoning_graph"]
    graph_analysis = analysis_result["graph_analysis"]
    quality_assessment = analysis_result["quality_assessment"]

    print("\nğŸ“Š ì¶”ë¡  ê·¸ë˜í”„ ë¶„ì„:")
    print(f"  â€¢ ë…¸ë“œ ìˆ˜: {graph_analysis['node_count']}")
    print(f"  â€¢ ì—£ì§€ ìˆ˜: {graph_analysis['edge_count']}")
    print(f"  â€¢ ë…¸ë“œ ìœ í˜•: {graph_analysis['node_types']}")
    print(f"  â€¢ ì—£ì§€ ìœ í˜•: {graph_analysis['edge_types']}")
    print(f"  â€¢ ì—°ê²°ì„±: {graph_analysis['connectivity']:.2f}")
    print(f"  â€¢ ê¹Šì´: {graph_analysis['depth']}")

    print("\nğŸ¯ ì¶”ë¡  í’ˆì§ˆ í‰ê°€:")
    print(f"  â€¢ ì¢…í•© í’ˆì§ˆ: {quality_assessment['overall_quality']:.2f}")
    print(f"  â€¢ ë…¼ë¦¬ì  ì¼ê´€ì„±: {quality_assessment['logical_consistency']:.2f}")
    print(f"  â€¢ ì™„ì „ì„±: {quality_assessment['completeness']:.2f}")
    print(f"  â€¢ ëª…í™•ì„±: {quality_assessment['clarity']:.2f}")
    print(f"  â€¢ ê°•ë„: {quality_assessment['strength']:.2f}")

    print("\nğŸ” ì¶”ë¡  ë…¸ë“œ ìƒì„¸:")
    for node_id, node in reasoning_graph.nodes.items():
        print(f"  â€¢ {node_id}: {node.content} (ì‹ ë¢°ë„: {node.confidence:.2f})")

    print("\nğŸ”— ì¶”ë¡  ì—£ì§€ ìƒì„¸:")
    for edge_id, edge in reasoning_graph.edges.items():
        print(f"  â€¢ {edge_id}: {edge.source_node} â†’ {edge.target_node} (ê°•ë„: {edge.strength:.2f})")

    print(f"\n{'='*70}")
    print("=== ì¶”ë¡  ê·¸ë˜í”„ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ (Day 5) ===")
    print("âœ… Day 5 ëª©í‘œ ë‹¬ì„±: ëª…ì‹œì  ì‚¬ê³  ê³¼ì • êµ¬ì¡°í™”")
    print("âœ… ì¶”ë¡  ê·¸ë˜í”„ êµ¬ì¶• ë° ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„")
    print("âœ… ë…¼ë¦¬ì  ì¶”ë¡  ì—”ì§„ ë° í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ êµ¬í˜„")


if __name__ == "__main__":
    asyncio.run(test_reasoning_graph_system())
