#!/usr/bin/env python3
"""
í–¥ìƒëœ ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
DuRi Phase 6.1 - í†µí•© ì„±ëŠ¥ ìµœì í™”

ê¸°ëŠ¥:
1. ACT-R ë³‘ë ¬ ì²˜ë¦¬ + ê¸°ì¡´ ì„±ëŠ¥ ìµœì í™” í†µí•©
2. ìºì‹± ì‹œìŠ¤í…œ + ë³‘ë ¬ ì²˜ë¦¬
3. ë¡œë“œ ë°¸ëŸ°ì‹± + ì‘ì—… ìš°ì„ ìˆœìœ„
4. í†µí•© ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import asyncio
import hashlib
import json
import logging
import statistics
import time
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Callable, Dict, List, Optional

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class TaskPriority(Enum):
    """ì‘ì—… ìš°ì„ ìˆœìœ„"""

    CRITICAL = 1
    HIGH = 2
    MEDIUM = 3
    LOW = 4


class TaskStatus(Enum):
    """ì‘ì—… ìƒíƒœ"""

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class ParallelTask:
    """ë³‘ë ¬ ì‘ì—… ì •ë³´"""

    id: str
    name: str
    function: Callable
    args: tuple = ()
    kwargs: dict = None
    priority: TaskPriority = TaskPriority.MEDIUM
    status: TaskStatus = TaskStatus.PENDING
    created_at: datetime = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Any = None
    error: Optional[str] = None
    execution_time: float = 0.0

    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
        if self.kwargs is None:
            self.kwargs = {}


class EnhancedACTRParallelProcessor:
    """í–¥ìƒëœ ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ (í†µí•© ë²„ì „)"""

    def __init__(self, max_concurrent_tasks: int = 10):
        # ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ
        self.max_concurrent_tasks = max_concurrent_tasks
        self.active_tasks: Dict[str, ParallelTask] = {}
        self.completed_tasks: List[ParallelTask] = []
        self.task_queue: List[ParallelTask] = []

        # ìºì‹± ì‹œìŠ¤í…œ (ê¸°ì¡´ ì„±ëŠ¥ ìµœì í™”ì—ì„œ í†µí•©)
        self.cache = {}
        self.cache_ttl = 300  # 5ë¶„ ìºì‹œ
        self.cache_max_size = 1000

        # ë¡œë“œ ë°¸ëŸ°ì‹± ì‹œìŠ¤í…œ
        self.node_status = {
            "brain_node": {"status": "active", "response_time": 0.0, "load": 0},
            "evolution_node": {"status": "active", "response_time": 0.0, "load": 0},
            "judgment_node": {"status": "active", "response_time": 0.0, "load": 0},
            "action_node": {"status": "active", "response_time": 0.0, "load": 0},
            "feedback_node": {"status": "active", "response_time": 0.0, "load": 0},
        }

        # í†µí•© ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.performance_metrics = {
            "total_tasks": 0,
            "completed_tasks": 0,
            "failed_tasks": 0,
            "average_execution_time": 0.0,
            "parallel_efficiency": 0.0,
            "performance_improvement": 0.0,
            "cache_hits": 0,
            "cache_misses": 0,
            "cache_hit_rate": 0.0,
            "total_requests": 0,
            "error_count": 0,
        }

        self.execution_history = []
        self.request_history = defaultdict(list)

        # ì„±ëŠ¥ ì¸¡ì •ìš©
        self.baseline_execution_time = 0.104  # í˜„ì¬ ê¸°ì¤€ ì‹œê°„
        self.target_execution_time = 0.08  # ëª©í‘œ ì‹œê°„ (23% í–¥ìƒ)

        # ThreadPoolExecutor
        self.executor = ThreadPoolExecutor(max_workers=10)

        logger.info("ğŸš€ í–¥ìƒëœ ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def execute_parallel_tasks(self, tasks: List[ParallelTask]) -> List[Any]:
        """ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ (ìºì‹± í¬í•¨)"""
        logger.info(f"âš¡ {len(tasks)}ê°œ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ ì‹œì‘")

        start_time = time.time()

        try:
            # ì‘ì—…ì„ ìš°ì„ ìˆœìœ„ë³„ë¡œ ì •ë ¬
            sorted_tasks = sorted(tasks, key=lambda x: x.priority.value)

            # ìºì‹œ í™•ì¸ ë° ë³‘ë ¬ ì‹¤í–‰
            coroutines = []
            for task in sorted_tasks:
                coroutine = self._execute_single_task_with_cache(task)
                coroutines.append(coroutine)

            # asyncio.gatherë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì‹¤í–‰
            results = await asyncio.gather(*coroutines, return_exceptions=True)

            execution_time = time.time() - start_time

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self._update_performance_metrics(execution_time, len(tasks))

            logger.info(f"âœ… ë³‘ë ¬ ì‹¤í–‰ ì™„ë£Œ: {execution_time:.3f}ì´ˆ")
            return results

        except Exception as e:
            logger.error(f"âŒ ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []

    async def _execute_single_task_with_cache(self, task: ParallelTask) -> Any:
        """ìºì‹±ì´ í¬í•¨ëœ ë‹¨ì¼ ì‘ì—… ì‹¤í–‰"""
        # ìºì‹œ í‚¤ ìƒì„±
        cache_key = self._generate_task_cache_key(task)

        # ìºì‹œ í™•ì¸
        cached_result = self._get_from_cache(cache_key)
        if cached_result:
            self.performance_metrics["cache_hits"] += 1
            logger.info(f"âš¡ ìºì‹œ íˆíŠ¸: {task.name}")
            return cached_result

        self.performance_metrics["cache_misses"] += 1

        # ì‹¤ì œ ì‘ì—… ì‹¤í–‰
        task.status = TaskStatus.RUNNING
        task.started_at = datetime.now()

        try:
            # ì‘ì—… ì‹¤í–‰
            if asyncio.iscoroutinefunction(task.function):
                result = await task.function(*task.args, **task.kwargs)
            else:
                # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(None, task.function, *task.args, **task.kwargs)

            task.status = TaskStatus.COMPLETED
            task.result = result
            task.completed_at = datetime.now()
            task.execution_time = (task.completed_at - task.started_at).total_seconds()

            # ê²°ê³¼ ìºì‹±
            self._cache_result(cache_key, result)

            logger.info(f"âœ… ì‘ì—… ì™„ë£Œ: {task.name} ({task.execution_time:.3f}ì´ˆ)")
            return result

        except Exception as e:
            task.status = TaskStatus.FAILED
            task.error = str(e)
            task.completed_at = datetime.now()
            task.execution_time = (task.completed_at - task.started_at).total_seconds()

            logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨: {task.name} - {e}")
            return None

    def _generate_task_cache_key(self, task: ParallelTask) -> str:
        """ì‘ì—…ë³„ ìºì‹œ í‚¤ ìƒì„±"""
        content = f"{task.name}:{task.args}:{json.dumps(task.kwargs, sort_keys=True)}"
        return hashlib.md5(content.encode()).hexdigest()

    def _get_from_cache(self, cache_key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê²°ê³¼ ì¡°íšŒ"""
        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            if time.time() - cached_item["timestamp"] < self.cache_ttl:
                return cached_item["data"]
            else:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                del self.cache[cache_key]
        return None

    def _cache_result(self, cache_key: str, result: Any):
        """ê²°ê³¼ ìºì‹±"""
        self.cache[cache_key] = {"data": result, "timestamp": time.time()}

        # ìºì‹œ í¬ê¸° ì œí•œ
        if len(self.cache) > self.cache_max_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì‚­ì œ
            oldest_key = min(self.cache.keys(), key=lambda k: self.cache[k]["timestamp"])
            del self.cache[oldest_key]

    def _update_performance_metrics(self, execution_time: float, task_count: int):
        """í†µí•© ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.performance_metrics["total_tasks"] += task_count
        self.performance_metrics["completed_tasks"] += task_count

        # í‰ê·  ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        if self.completed_tasks:
            avg_time = statistics.mean([task.execution_time for task in self.completed_tasks])
            self.performance_metrics["average_execution_time"] = avg_time

        # ë³‘ë ¬ íš¨ìœ¨ì„± ê³„ì‚°
        if self.baseline_execution_time > 0:
            efficiency = (self.baseline_execution_time / execution_time) * 100
            self.performance_metrics["parallel_efficiency"] = efficiency

        # ì„±ëŠ¥ í–¥ìƒë¥  ê³„ì‚°
        if self.baseline_execution_time > 0:
            improvement = ((self.baseline_execution_time - execution_time) / self.baseline_execution_time) * 100
            self.performance_metrics["performance_improvement"] = improvement

        # ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°
        total_cache_requests = self.performance_metrics["cache_hits"] + self.performance_metrics["cache_misses"]
        if total_cache_requests > 0:
            self.performance_metrics["cache_hit_rate"] = (
                self.performance_metrics["cache_hits"] / total_cache_requests
            ) * 100

    async def execute_judgment_parallel(self, judgment_tasks: List[Callable]) -> List[Any]:
        """íŒë‹¨ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ (ë¡œë“œ ë°¸ëŸ°ì‹± í¬í•¨)"""
        logger.info("ğŸ§  íŒë‹¨ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰")

        # ìµœì  ë…¸ë“œ ì„ íƒ
        optimal_node = self._get_optimal_node("judgment")

        tasks = []
        for i, task_func in enumerate(judgment_tasks):
            task = ParallelTask(
                id=f"judgment_{i}",
                name=f"íŒë‹¨ ì‘ì—… {i+1} ({optimal_node})",
                function=task_func,
                priority=TaskPriority.HIGH,
            )
            tasks.append(task)

        return await self.execute_parallel_tasks(tasks)

    async def execute_action_parallel(self, action_tasks: List[Callable]) -> List[Any]:
        """í–‰ë™ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ (ë¡œë“œ ë°¸ëŸ°ì‹± í¬í•¨)"""
        logger.info("âš¡ í–‰ë™ ì‘ì—… ë³‘ë ¬ ì‹¤í–‰")

        # ìµœì  ë…¸ë“œ ì„ íƒ
        optimal_node = self._get_optimal_node("action")

        tasks = []
        for i, task_func in enumerate(action_tasks):
            task = ParallelTask(
                id=f"action_{i}",
                name=f"í–‰ë™ ì‘ì—… {i+1} ({optimal_node})",
                function=task_func,
                priority=TaskPriority.MEDIUM,
            )
            tasks.append(task)

        return await self.execute_parallel_tasks(tasks)

    async def execute_feedback_parallel(self, feedback_tasks: List[Callable]) -> List[Any]:
        """í”¼ë“œë°± ì‘ì—… ë³‘ë ¬ ì‹¤í–‰ (ë¡œë“œ ë°¸ëŸ°ì‹± í¬í•¨)"""
        logger.info("ğŸ”„ í”¼ë“œë°± ì‘ì—… ë³‘ë ¬ ì‹¤í–‰")

        # ìµœì  ë…¸ë“œ ì„ íƒ
        optimal_node = self._get_optimal_node("feedback")

        tasks = []
        for i, task_func in enumerate(feedback_tasks):
            task = ParallelTask(
                id=f"feedback_{i}",
                name=f"í”¼ë“œë°± ì‘ì—… {i+1} ({optimal_node})",
                function=task_func,
                priority=TaskPriority.LOW,
            )
            tasks.append(task)

        return await self.execute_parallel_tasks(tasks)

    def _get_optimal_node(self, operation_type: str) -> str:
        """ìµœì  ë…¸ë“œ ì„ íƒ (ë¡œë“œ ë°¸ëŸ°ì‹±)"""
        available_nodes = []

        for node_name, node_info in self.node_status.items():
            if node_info["status"] == "active":
                # ì‘ë‹µ ì‹œê°„ê³¼ ë¶€í•˜ë¥¼ ê³ ë ¤í•œ ì ìˆ˜ ê³„ì‚°
                score = 1.0 / (node_info["response_time"] + 0.001) * (1.0 - node_info["load"])
                available_nodes.append((node_name, score))

        if available_nodes:
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë…¸ë“œ ì„ íƒ
            optimal_node = max(available_nodes, key=lambda x: x[1])[0]

            # ì„ íƒëœ ë…¸ë“œì˜ ë¶€í•˜ ì¦ê°€
            self.node_status[optimal_node]["load"] = min(1.0, self.node_status[optimal_node]["load"] + 0.1)

            return optimal_node
        else:
            return "default_node"

    def get_integrated_performance_report(self) -> Dict[str, Any]:
        """í†µí•© ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        return {
            "metrics": self.performance_metrics,
            "target_improvement": 23.0,  # ëª©í‘œ 23% í–¥ìƒ
            "current_improvement": self.performance_metrics["performance_improvement"],
            "baseline_time": self.baseline_execution_time,
            "target_time": self.target_execution_time,
            "efficiency": self.performance_metrics["parallel_efficiency"],
            "total_completed": len(self.completed_tasks),
            "success_rate": (
                self.performance_metrics["completed_tasks"] / max(self.performance_metrics["total_tasks"], 1)
            )
            * 100,
            "cache_stats": {
                "hit_rate": self.performance_metrics["cache_hit_rate"],
                "hits": self.performance_metrics["cache_hits"],
                "misses": self.performance_metrics["cache_misses"],
                "cache_size": len(self.cache),
            },
            "node_status": self.node_status,
        }

    def clear_cache(self):
        """ìºì‹œ í´ë¦¬ì–´"""
        self.cache.clear()
        logger.info("ğŸ—‘ï¸  ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ")

    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„"""
        return {
            "cache_size": len(self.cache),
            "cache_hit_rate": self.performance_metrics["cache_hit_rate"],
            "cache_hits": self.performance_metrics["cache_hits"],
            "cache_misses": self.performance_metrics["cache_misses"],
        }


# í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ í•¨ìˆ˜ë“¤
async def sample_judgment_task(data: str) -> Dict[str, Any]:
    """ìƒ˜í”Œ íŒë‹¨ ì‘ì—…"""
    await asyncio.sleep(0.02)  # 20ms ì‹œë®¬ë ˆì´ì…˜
    return {
        "type": "judgment",
        "data": data,
        "result": f"íŒë‹¨ ê²°ê³¼: {data}",
        "confidence": 0.85,
    }


async def sample_action_task(action: str) -> Dict[str, Any]:
    """ìƒ˜í”Œ í–‰ë™ ì‘ì—…"""
    await asyncio.sleep(0.03)  # 30ms ì‹œë®¬ë ˆì´ì…˜
    return {
        "type": "action",
        "action": action,
        "result": f"í–‰ë™ ì‹¤í–‰: {action}",
        "status": "success",
    }


async def sample_feedback_task(feedback: str) -> Dict[str, Any]:
    """ìƒ˜í”Œ í”¼ë“œë°± ì‘ì—…"""
    await asyncio.sleep(0.01)  # 10ms ì‹œë®¬ë ˆì´ì…˜
    return {
        "type": "feedback",
        "feedback": feedback,
        "result": f"í”¼ë“œë°± ì²˜ë¦¬: {feedback}",
        "quality": 0.9,
    }


async def test_enhanced_parallel_processor():
    """í–¥ìƒëœ ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª í–¥ìƒëœ ACT-R ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    processor = EnhancedACTRParallelProcessor(max_concurrent_tasks=5)

    # í…ŒìŠ¤íŠ¸ ì‘ì—… ìƒì„±
    judgment_tasks = [
        lambda: sample_judgment_task("ì‚¬ìš©ì ì…ë ¥ ë¶„ì„"),
        lambda: sample_judgment_task("ì»¨í…ìŠ¤íŠ¸ í‰ê°€"),
        lambda: sample_judgment_task("ìš°ì„ ìˆœìœ„ ê²°ì •"),
    ]

    action_tasks = [
        lambda: sample_action_task("ì‘ë‹µ ìƒì„±"),
        lambda: sample_action_task("ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"),
        lambda: sample_action_task("í•™ìŠµ ì§„í–‰"),
    ]

    feedback_tasks = [
        lambda: sample_feedback_task("ì„±ëŠ¥ í‰ê°€"),
        lambda: sample_feedback_task("ê°œì„ ì  ì‹ë³„"),
        lambda: sample_feedback_task("ë‹¤ìŒ ë‹¨ê³„ ê³„íš"),
    ]

    # ë³‘ë ¬ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
    start_time = time.time()

    judgment_results = await processor.execute_judgment_parallel(judgment_tasks)
    action_results = await processor.execute_action_parallel(action_tasks)
    feedback_results = await processor.execute_feedback_parallel(feedback_tasks)

    total_time = time.time() - start_time

    # ê²°ê³¼ ì¶œë ¥
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    logger.info(f"   ì´ ì‹¤í–‰ ì‹œê°„: {total_time:.3f}ì´ˆ")
    logger.info(f"   íŒë‹¨ ê²°ê³¼: {len(judgment_results)}ê°œ")
    logger.info(f"   í–‰ë™ ê²°ê³¼: {len(action_results)}ê°œ")
    logger.info(f"   í”¼ë“œë°± ê²°ê³¼: {len(feedback_results)}ê°œ")

    # í†µí•© ì„±ëŠ¥ ë¦¬í¬íŠ¸
    report = processor.get_integrated_performance_report()
    logger.info("ğŸ“ˆ í†µí•© ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
    logger.info(f"   ì„±ëŠ¥ í–¥ìƒë¥ : {report['current_improvement']:.1f}%")
    logger.info(f"   ë³‘ë ¬ íš¨ìœ¨ì„±: {report['efficiency']:.1f}%")
    logger.info(f"   ì„±ê³µë¥ : {report['success_rate']:.1f}%")
    logger.info(f"   ìºì‹œ íˆíŠ¸ìœ¨: {report['cache_stats']['hit_rate']:.1f}%")

    return report


if __name__ == "__main__":
    asyncio.run(test_enhanced_parallel_processor())
