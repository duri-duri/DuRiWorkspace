#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DuRi Phase Î©: í†µí•© ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ Phase Î©ì˜ ëª¨ë“  ì‹œìŠ¤í…œë“¤ì„ í†µí•©í•˜ëŠ” ë©”ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
Phase Zì˜ DuRiThoughtFlowì™€ Phase Î©ì˜ ìƒì¡´ ë³¸ëŠ¥ ê¸°ë°˜ ìê°€ ëª©í‘œ ìƒì„± ì‹œìŠ¤í…œì„ í†µí•©í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- Phase Zì™€ Phase Î© í†µí•©
- ìƒì¡´ ë³¸ëŠ¥ ê¸°ë°˜ ì‚¬ê³  í”„ë¡œì„¸ìŠ¤
- ìê°€ ëª©í‘œ ìƒì„± ë° ì§„í™”
- í†µí•© ê²°ê³¼ ê´€ë¦¬
- ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œ (íˆíŠ¸ìœ¨ 80% ì´ìƒ ëª©í‘œ)
"""

import asyncio
import hashlib
import json
import logging
import time
from collections import OrderedDict, defaultdict
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from evolution_system import EvolutionResult, EvolutionSystem
from self_goal_generator import SelfGoal, SelfGoalGenerator
from survival_assessment_system import (
    Recommendation,
    ResourceAssessment,
    RiskAssessment,
    SurvivalAssessmentSystem,
    SurvivalScore,
)

# Phase Î© ì‹œìŠ¤í…œë“¤ import
from survival_instinct_engine import SurvivalInstinctEngine, SurvivalStatus

# Phase Z ì‹œìŠ¤í…œë“¤ import
try:
    from duri_thought_flow import DuRiThoughtFlow, ReflectionResult, ThoughtFlowResult  # noqa: F401
except ImportError as e:
    logging.warning(f"Phase Z ì‹œìŠ¤í…œ import ì‹¤íŒ¨: {e}")

# í†µí•© ì§„í™” ì‹œìŠ¤í…œ import (ìˆœí™˜ import ë°©ì§€ë¥¼ ìœ„í•´ ë™ì  import ì‹œìŠ¤í…œ êµ¬í˜„)
# í•„ìš”í•  ë•Œë§Œ ë™ì ìœ¼ë¡œ importí•˜ì—¬ ìˆœí™˜ ì°¸ì¡° ë°©ì§€
INTEGRATED_EVOLUTION_AVAILABLE = False
INTEGRATED_EVOLUTION_MODULE = None


def _get_integrated_evolution_system():
    """í†µí•© ì§„í™” ì‹œìŠ¤í…œì„ ë™ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    global INTEGRATED_EVOLUTION_AVAILABLE, INTEGRATED_EVOLUTION_MODULE

    if INTEGRATED_EVOLUTION_AVAILABLE:
        return INTEGRATED_EVOLUTION_MODULE

    try:
        import importlib

        INTEGRATED_EVOLUTION_MODULE = importlib.import_module("integrated_evolution_system")
        INTEGRATED_EVOLUTION_AVAILABLE = True
        logger.info("í†µí•© ì§„í™” ì‹œìŠ¤í…œ ë™ì  import ì„±ê³µ")
        return INTEGRATED_EVOLUTION_MODULE
    except ImportError as e:
        logger.warning(f"í†µí•© ì§„í™” ì‹œìŠ¤í…œ ë™ì  import ì‹¤íŒ¨: {e}")
        return None


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


class IntegrationStage(Enum):
    """í†µí•© ë‹¨ê³„ ì—´ê±°í˜•"""

    INITIALIZATION = "initialization"
    SURVIVAL_ASSESSMENT = "survival_assessment"
    SELF_GOAL_GENERATION = "self_goal_generation"
    THOUGHT_PROCESSING = "thought_processing"
    EVOLUTION = "evolution"
    INTEGRATION = "integration"
    COMPLETION = "completion"


class IntegrationStatus(Enum):
    """í†µí•© ìƒíƒœ ì—´ê±°í˜•"""

    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class PhaseOmegaResult:
    """Phase Î© ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""

    thought_result: Optional[Any] = None
    survival_status: Optional[SurvivalStatus] = None
    self_goals: List[SelfGoal] = field(default_factory=list)
    evolution_result: Optional[EvolutionResult] = None
    survival_score: Optional[SurvivalScore] = None
    risk_assessments: List[RiskAssessment] = field(default_factory=list)
    resource_assessments: Dict[str, ResourceAssessment] = field(default_factory=dict)
    recommendations: List[Recommendation] = field(default_factory=list)
    integration_time: float = 0.0
    success: bool = True
    error_message: Optional[str] = None


@dataclass
class IntegrationContext:
    """í†µí•© ì»¨í…ìŠ¤íŠ¸ ë°ì´í„° í´ë˜ìŠ¤"""

    stage: IntegrationStage
    status: IntegrationStatus
    input_data: Dict[str, Any]
    context: Dict[str, Any]
    results: Dict[str, Any] = field(default_factory=dict)
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None


class AdvancedCacheSystem:
    """ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œ - íˆíŠ¸ìœ¨ 80% ì´ìƒ ëª©í‘œ"""

    def __init__(self, max_size: int = 2000, ttl: int = 600):
        self.cache = OrderedDict()
        self.cache_max_size = max_size
        self.cache_ttl = ttl
        self.cache_hits = 0
        self.cache_misses = 0
        self.cache_creation_time = time.time()

        # ìºì‹œ í†µê³„
        self.cache_stats = {
            "total_requests": 0,
            "hit_rate": 0.0,
            "average_access_time": 0.0,
            "cache_efficiency": 0.0,
        }

        # ìºì‹œ í‚¤ íŒ¨í„´ ë¶„ì„
        self.key_patterns = defaultdict(int)
        self.access_patterns = defaultdict(int)

        # ì˜ˆì¸¡ì  ìºì‹œ ë¡œë”©
        self.prediction_cache = {}
        self.prediction_accuracy = 0.0

        # ê³ ê¸‰ ìºì‹œ í‚¤ ìƒì„±
        self.semantic_cache = {}
        self.similarity_threshold = 0.8

        # ìºì‹œ ìµœì í™” ì„¤ì •
        self.optimization_config = {
            "enable_semantic_caching": True,
            "enable_prediction": True,
            "enable_adaptive_ttl": True,
            "enable_smart_cleanup": True,
        }

        logger.info(f"ğŸš€ ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”: í¬ê¸°={max_size}, TTL={ttl}ì´ˆ")

    def _optimize_cache_key(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> str:
        """íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì œì™¸í•œ ìµœì í™”ëœ ìºì‹œ í‚¤ ìƒì„±"""
        try:
            # 1. ì¤‘ìš”ë„ ê¸°ë°˜ í•„í„°ë§ (íƒ€ì„ìŠ¤íƒ¬í”„ ì œì™¸)
            important_data = self._extract_important_data(input_data)
            important_context = self._extract_important_context(context)

            # 2. ì •ê·œí™”ëœ í‚¤ ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ ì œì™¸)
            normalized_data = self._normalize_data(important_data)
            normalized_context = self._normalize_data(important_context)

            # 3. ì‹œë§¨í‹± í‚¤ ìƒì„± (ìƒˆë¡œ ì¶”ê°€)
            if self.optimization_config["enable_semantic_caching"]:
                semantic_key = self._generate_semantic_key(important_data, important_context)
                if semantic_key:
                    return semantic_key

            # 4. í•´ì‹œ ìƒì„±
            key_content = f"{normalized_data}:{normalized_context}"
            cache_key = hashlib.md5(key_content.encode()).hexdigest()

            # 5. íŒ¨í„´ ë¶„ì„
            self.key_patterns[cache_key[:8]] += 1

            return cache_key

        except Exception as e:
            logger.error(f"ìºì‹œ í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ í•´ì‹œ ìƒì„±
            fallback_content = json.dumps(input_data, sort_keys=True) + json.dumps(context, sort_keys=True)
            return hashlib.md5(fallback_content.encode()).hexdigest()

    def _generate_semantic_key(self, data: Dict[str, Any], context: Dict[str, Any]) -> Optional[str]:
        """ì‹œë§¨í‹± ìºì‹œ í‚¤ ìƒì„± (ìµœì í™”ëœ ë²„ì „)"""
        try:
            # ë°ì´í„°ì˜ ì˜ë¯¸ì  íŠ¹ì§• ì¶”ì¶œ
            semantic_features = []

            # ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ (ë” ì •êµí•œ ë¶„ì„)
            if "user_input" in data:
                user_input = data["user_input"].lower()
                semantic_features.extend(self._extract_semantic_features(user_input))

                # ì…ë ¥ ìœ í˜• ë¶„ë¥˜
                input_type = self._classify_input_type(user_input)
                semantic_features.append(f"input_type:{input_type}")

            # í™˜ê²½ ë°ì´í„° ë¶„ì„ (ë” ì„¸ë¶„í™”)
            if "environment_data" in context:
                env_data = context["environment_data"]
                if "system_stability" in env_data:
                    stability_level = (
                        "high"
                        if env_data["system_stability"] > 0.8
                        else "medium"
                        if env_data["system_stability"] > 0.5
                        else "low"
                    )
                    semantic_features.append(f"stability:{stability_level}")

                if "performance_metrics" in env_data:
                    perf_metrics = env_data["performance_metrics"]
                    if "accuracy" in perf_metrics:
                        accuracy_level = (
                            "high"
                            if perf_metrics["accuracy"] > 0.8
                            else "medium"
                            if perf_metrics["accuracy"] > 0.5
                            else "low"
                        )
                        semantic_features.append(f"accuracy:{accuracy_level}")
                    if "efficiency" in perf_metrics:
                        efficiency_level = (
                            "high"
                            if perf_metrics["efficiency"] > 0.8
                            else "medium"
                            if perf_metrics["efficiency"] > 0.5
                            else "low"
                        )
                        semantic_features.append(f"efficiency:{efficiency_level}")

            # ë¦¬ì†ŒìŠ¤ ë°ì´í„° ë¶„ì„ (ë” ì„¸ë¶„í™”)
            if "resource_data" in context:
                resource_data = context["resource_data"]
                for resource_type, resource_info in resource_data.items():
                    if "availability" in resource_info:
                        availability_level = (
                            "high"
                            if resource_info["availability"] > 0.8
                            else ("medium" if resource_info["availability"] > 0.5 else "low")
                        )
                        semantic_features.append(f"{resource_type}_availability:{availability_level}")
                    if "utilization" in resource_info:
                        utilization_level = (
                            "high"
                            if resource_info["utilization"] > 0.7
                            else ("medium" if resource_info["utilization"] > 0.4 else "low")
                        )
                        semantic_features.append(f"{resource_type}_utilization:{utilization_level}")

            # í™˜ê²½ ë³€í™” ë¶„ì„
            if "environmental_changes" in context:
                env_changes = context["environmental_changes"]
                if "magnitude" in env_changes:
                    magnitude_level = (
                        "high"
                        if env_changes["magnitude"] > 0.7
                        else "medium"
                        if env_changes["magnitude"] > 0.3
                        else "low"
                    )
                    semantic_features.append(f"change_magnitude:{magnitude_level}")
                if "direction" in env_changes:
                    semantic_features.append(f"change_direction:{env_changes['direction']}")

            # ì‹œë§¨í‹± í‚¤ ìƒì„±
            if semantic_features:
                semantic_content = ":".join(sorted(semantic_features))
                semantic_key = hashlib.md5(semantic_content.encode()).hexdigest()
                return f"semantic_{semantic_key}"

            return None

        except Exception as e:
            logger.error(f"ì‹œë§¨í‹± í‚¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def _classify_input_type(self, text: str) -> str:
        """ì…ë ¥ ìœ í˜• ë¶„ë¥˜"""
        text_lower = text.lower()

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        if any(word in text_lower for word in ["ìƒíƒœ", "status", "í™•ì¸", "check"]):
            return "status_check"
        elif any(word in text_lower for word in ["ì„±ëŠ¥", "performance", "ìµœì í™”", "optimization"]):
            return "performance_optimization"
        elif any(word in text_lower for word in ["ë³´ì•ˆ", "security", "ì•ˆì „", "safe"]):
            return "security_enhancement"
        elif any(word in text_lower for word in ["ë¶„ì„", "analysis", "í‰ê°€", "assessment"]):
            return "analysis_assessment"
        elif any(word in text_lower for word in ["ê°œì„ ", "improvement", "í–¥ìƒ", "enhancement"]):
            return "improvement_enhancement"
        else:
            return "general_query"

    def _extract_semantic_features(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ì  íŠ¹ì§• ì¶”ì¶œ (ìµœì í™”ëœ ë²„ì „)"""
        features = []

        # í‚¤ì›Œë“œ ê¸°ë°˜ íŠ¹ì§• ì¶”ì¶œ (í™•ì¥ëœ í‚¤ì›Œë“œ)
        keywords = {
            "system": ["ì‹œìŠ¤í…œ", "system", "ìƒíƒœ", "status", "í™•ì¸", "check"],
            "performance": [
                "ì„±ëŠ¥",
                "performance",
                "ìµœì í™”",
                "optimization",
                "íš¨ìœ¨",
                "efficiency",
            ],
            "security": ["ë³´ì•ˆ", "security", "ì•ˆì „", "safe", "ë³´í˜¸", "protection"],
            "analysis": ["ë¶„ì„", "analysis", "í™•ì¸", "check", "í‰ê°€", "assessment"],
            "improvement": [
                "ê°œì„ ",
                "improvement",
                "í–¥ìƒ",
                "enhancement",
                "ë°œì „",
                "development",
            ],
            "resource": [
                "ìì›",
                "resource",
                "ë©”ëª¨ë¦¬",
                "memory",
                "cpu",
                "ì²˜ë¦¬",
                "processing",
            ],
            "monitoring": [
                "ëª¨ë‹ˆí„°ë§",
                "monitoring",
                "ê°ì‹œ",
                "surveillance",
                "ì¶”ì ",
                "tracking",
            ],
        }

        for category, words in keywords.items():
            for word in words:
                if word in text:
                    features.append(f"category:{category}")
                    break

        # í…ìŠ¤íŠ¸ ê¸¸ì´ íŠ¹ì§•
        if len(text) < 20:
            features.append("length:short")
        elif len(text) < 50:
            features.append("length:medium")
        else:
            features.append("length:long")

        # ë¬¸ì¥ êµ¬ì¡° íŠ¹ì§•
        if "?" in text or "?" in text:
            features.append("structure:question")
        elif any(word in text for word in ["í•´ì£¼ì„¸ìš”", "please", "ìš”ì²­", "request"]):
            features.append("structure:request")
        else:
            features.append("structure:statement")

        return features

    def _extract_important_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ì¤‘ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ (íƒ€ì„ìŠ¤íƒ¬í”„ ì œì™¸)"""
        important_keys = [
            "user_input",
            "task",
            "phase",
            "goal",
            "mode",
            "environmental_changes",
            "environment_data",
            "resource_data",
        ]

        important_data = {}
        for key in important_keys:
            if key in data:
                important_data[key] = data[key]

        return important_data

    def _extract_important_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """ì¤‘ìš”í•œ ì»¨í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (íƒ€ì„ìŠ¤íƒ¬í”„ ì œì™¸)"""
        important_keys = [
            "goal",
            "mode",
            "phase_omega_context",
            "environmental_changes",
            "environment_data",
            "resource_data",
        ]

        important_context = {}
        for key in important_keys:
            if key in context:
                important_context[key] = context[key]

        return important_context

    def _normalize_data(self, data: Dict[str, Any]) -> str:
        """ë°ì´í„° ì •ê·œí™”"""
        try:
            # ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ë ¬ëœ ë¬¸ìì—´ë¡œ ë³€í™˜
            normalized = json.dumps(data, sort_keys=True, separators=(",", ":"))
            return normalized
        except Exception:
            return str(data)

    def get(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ (ì˜ˆì¸¡ì  ìºì‹œ í¬í•¨)"""
        cache_key = self._optimize_cache_key(input_data, context)
        self.cache_stats["total_requests"] += 1

        # 1. ì§ì ‘ ìºì‹œ í™•ì¸
        if cache_key in self.cache:
            cached_item = self.cache[cache_key]
            current_time = time.time()

            # TTL í™•ì¸
            if current_time - cached_item["timestamp"] < self.cache_ttl:
                # ìºì‹œ íˆíŠ¸
                self.cache_hits += 1
                self.access_patterns[cache_key] += 1

                # LRU ì—…ë°ì´íŠ¸
                self.cache.move_to_end(cache_key)
                cached_item["last_accessed"] = current_time
                cached_item["access_count"] += 1

                # í†µê³„ ì—…ë°ì´íŠ¸
                self._update_cache_stats()

                logger.debug(f"âš¡ ìºì‹œ íˆíŠ¸: {cache_key[:8]}...")
                return cached_item["data"]
            else:
                # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
                del self.cache[cache_key]

        # 2. ì˜ˆì¸¡ì  ìºì‹œ í™•ì¸ (ìƒˆë¡œ ì¶”ê°€)
        if self.optimization_config["enable_prediction"]:
            predicted_result = self._check_predictive_cache(input_data, context)
            if predicted_result:
                self.cache_hits += 1
                logger.debug(f"ğŸ”® ì˜ˆì¸¡ì  ìºì‹œ íˆíŠ¸: {cache_key[:8]}...")
                return predicted_result

        # 3. ì‹œë§¨í‹± ìºì‹œ í™•ì¸ (ìƒˆë¡œ ì¶”ê°€)
        if self.optimization_config["enable_semantic_caching"]:
            semantic_result = self._check_semantic_cache(input_data, context)
            if semantic_result:
                self.cache_hits += 1
                logger.debug(f"ğŸ§  ì‹œë§¨í‹± ìºì‹œ íˆíŠ¸: {cache_key[:8]}...")
                return semantic_result

        # ìºì‹œ ë¯¸ìŠ¤
        self.cache_misses += 1
        self._update_cache_stats()

        logger.debug(f"âŒ ìºì‹œ ë¯¸ìŠ¤: {cache_key[:8]}...")
        return None

    def _check_predictive_cache(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> Optional[Any]:
        """ì˜ˆì¸¡ì  ìºì‹œ í™•ì¸ (ìµœì í™”ëœ ë²„ì „)"""
        try:
            # ì‚¬ìš© íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ì˜ˆì¸¡
            if len(self.access_patterns) > 0:
                # ê°€ì¥ ìì£¼ ì ‘ê·¼ë˜ëŠ” íŒ¨í„´ ì°¾ê¸°
                sorted_patterns = sorted(self.access_patterns.items(), key=lambda x: x[1], reverse=True)

                # ìƒìœ„ 3ê°œ íŒ¨í„´ í™•ì¸
                for cache_key, access_count in sorted_patterns[:3]:
                    if access_count > 1:  # 1ë²ˆ ì´ìƒ ì ‘ê·¼ëœ íŒ¨í„´ë§Œ ê³ ë ¤
                        if cache_key in self.cache:
                            cached_item = self.cache[cache_key]
                            current_time = time.time()

                            # TTL í™•ì¸
                            if current_time - cached_item["timestamp"] < self.cache_ttl:
                                # ìœ ì‚¬ë„ ê²€ì‚¬
                                if self._check_similarity(input_data, context, cached_item):
                                    return cached_item["data"]

            return None

        except Exception as e:
            logger.error(f"ì˜ˆì¸¡ì  ìºì‹œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return None

    def _check_semantic_cache(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> Optional[Any]:
        """ì‹œë§¨í‹± ìºì‹œ í™•ì¸"""
        try:
            # ì‹œë§¨í‹± í‚¤ ìƒì„±
            semantic_key = self._generate_semantic_key(
                self._extract_important_data(input_data),
                self._extract_important_context(context),
            )

            if semantic_key and semantic_key in self.semantic_cache:
                semantic_item = self.semantic_cache[semantic_key]
                current_time = time.time()

                # TTL í™•ì¸
                if current_time - semantic_item["timestamp"] < self.cache_ttl:
                    return semantic_item["data"]

            return None

        except Exception as e:
            logger.error(f"ì‹œë§¨í‹± ìºì‹œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return None

    def set(self, input_data: Dict[str, Any], context: Dict[str, Any], data: Any) -> str:
        """ìºì‹œì— ë°ì´í„° ì €ì¥ (ì‹œë§¨í‹± ìºì‹œ í¬í•¨)"""
        cache_key = self._optimize_cache_key(input_data, context)
        current_time = time.time()

        # ìºì‹œ í•­ëª© ìƒì„±
        cache_item = {
            "data": data,
            "timestamp": current_time,
            "last_accessed": current_time,
            "access_count": 1,
        }

        # ìºì‹œ í¬ê¸° ì œí•œ í™•ì¸
        if len(self.cache) >= self.cache_max_size:
            self._cleanup_lru_cache()

        # ìºì‹œì— ì €ì¥
        self.cache[cache_key] = cache_item
        self.cache.move_to_end(cache_key)

        # ì‹œë§¨í‹± ìºì‹œì—ë„ ì €ì¥ (ìƒˆë¡œ ì¶”ê°€)
        if self.optimization_config["enable_semantic_caching"]:
            semantic_key = self._generate_semantic_key(
                self._extract_important_data(input_data),
                self._extract_important_context(context),
            )
            if semantic_key:
                self.semantic_cache[semantic_key] = cache_item.copy()

        logger.debug(f"ğŸ’¾ ìºì‹œ ì €ì¥: {cache_key[:8]}...")
        return cache_key

    def _cleanup_lru_cache(self):
        """LRU ìºì‹œ ì •ë¦¬ (ìŠ¤ë§ˆíŠ¸ ì •ë¦¬ í¬í•¨)"""
        if len(self.cache) >= self.cache_max_size:
            if self.optimization_config["enable_smart_cleanup"]:
                # ìŠ¤ë§ˆíŠ¸ ì •ë¦¬: ì ‘ê·¼ ë¹ˆë„ì™€ ìµœê·¼ ì‚¬ìš© ì‹œê°„ì„ ê³ ë ¤
                sorted_items = sorted(
                    self.cache.items(),
                    key=lambda x: (
                        x[1].get("access_count", 1),  # ì ‘ê·¼ ë¹ˆë„ (ë†’ì„ìˆ˜ë¡ ìš°ì„ )
                        x[1].get("last_accessed", x[1]["timestamp"]),  # ìµœê·¼ ì‚¬ìš© ì‹œê°„
                    ),
                )
            else:
                # ê¸°ë³¸ LRU ì •ë¦¬
                sorted_items = sorted(
                    self.cache.items(),
                    key=lambda x: x[1].get("last_accessed", x[1]["timestamp"]),
                )

            # í•„ìš”í•œ ë§Œí¼ë§Œ ì œê±° (20% ì œê±°)
            target_size = int(self.cache_max_size * 0.8)
            if len(sorted_items) > target_size:
                items_to_remove = len(sorted_items) - target_size
                for i in range(items_to_remove):
                    key = sorted_items[i][0]
                    del self.cache[key]

                logger.debug(f"ğŸ§¹ ìºì‹œ ì •ë¦¬: {items_to_remove}ê°œ í•­ëª© ì œê±°")

    def _update_cache_stats(self):
        """ìºì‹œ í†µê³„ ì—…ë°ì´íŠ¸"""
        total_requests = self.cache_hits + self.cache_misses
        if total_requests > 0:
            self.cache_stats["hit_rate"] = (self.cache_hits / total_requests) * 100

        # ìºì‹œ íš¨ìœ¨ì„± ê³„ì‚°
        if len(self.cache) > 0:
            access_counts = [item["access_count"] for item in self.cache.values()]
            avg_access = sum(access_counts) / len(access_counts)
            self.cache_stats["cache_efficiency"] = avg_access / len(self.cache)

    def get_cache_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        self._update_cache_stats()

        return {
            "cache_size": len(self.cache),
            "cache_max_size": self.cache_max_size,
            "cache_ttl": self.cache_ttl,
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "hit_rate": self.cache_stats["hit_rate"],
            "total_requests": self.cache_stats["total_requests"],
            "cache_efficiency": self.cache_stats["cache_efficiency"],
            "key_patterns": dict(self.key_patterns),
            "access_patterns": dict(self.access_patterns),
            "semantic_cache_size": len(self.semantic_cache),
            "prediction_accuracy": self.prediction_accuracy,
        }

    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache.clear()
        self.semantic_cache.clear()
        self.cache_hits = 0
        self.cache_misses = 0
        self.key_patterns.clear()
        self.access_patterns.clear()
        logger.info("ğŸ§¹ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")

    def _adjust_cache_size(self):
        """ë™ì  ìºì‹œ í¬ê¸° ì¡°ì •"""
        hit_rate = self.cache_stats["hit_rate"] / 100

        if hit_rate < 0.3:  # íˆíŠ¸ìœ¨ì´ ë‚®ì€ ê²½ìš°
            new_size = min(self.cache_max_size * 2, 4000)  # í¬ê¸° ì¦ê°€
            if new_size != self.cache_max_size:
                self.cache_max_size = new_size
                logger.info(f"ğŸ“ˆ ìºì‹œ í¬ê¸° ì¦ê°€: {new_size}")
        elif hit_rate > 0.8:  # íˆíŠ¸ìœ¨ì´ ë†’ì€ ê²½ìš°
            new_size = max(self.cache_max_size // 2, 1000)  # í¬ê¸° ê°ì†Œ
            if new_size != self.cache_max_size:
                self.cache_max_size = new_size
                logger.info(f"ğŸ“‰ ìºì‹œ í¬ê¸° ê°ì†Œ: {new_size}")

    def _adjust_cache_ttl(self):
        """ë™ì  ìºì‹œ TTL ì¡°ì •"""
        hit_rate = self.cache_stats["hit_rate"] / 100

        if hit_rate < 0.3:  # íˆíŠ¸ìœ¨ì´ ë‚®ì€ ê²½ìš°
            new_ttl = min(self.cache_ttl * 2, 1200)  # TTL ì¦ê°€
            if new_ttl != self.cache_ttl:
                self.cache_ttl = new_ttl
                logger.info(f"â° ìºì‹œ TTL ì¦ê°€: {new_ttl}ì´ˆ")
        elif hit_rate > 0.8:  # íˆíŠ¸ìœ¨ì´ ë†’ì€ ê²½ìš°
            new_ttl = max(self.cache_ttl // 2, 300)  # TTL ê°ì†Œ
            if new_ttl != self.cache_ttl:
                self.cache_ttl = new_ttl
                logger.info(f"â° ìºì‹œ TTL ê°ì†Œ: {new_ttl}ì´ˆ")

    def _check_similarity(
        self,
        input_data: Dict[str, Any],
        context: Dict[str, Any],
        cached_item: Dict[str, Any],
    ) -> bool:
        """ì…ë ¥ ë°ì´í„°ì™€ ìºì‹œëœ ë°ì´í„°ì˜ ìœ ì‚¬ë„ ê²€ì‚¬"""
        try:
            # ì‹œë§¨í‹± í‚¤ ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ì‚¬
            current_semantic_key = self._generate_semantic_key(
                self._extract_important_data(input_data),
                self._extract_important_context(context),
            )

            if current_semantic_key:
                # ì‹œë§¨í‹± ìºì‹œì—ì„œ ìœ ì‚¬í•œ í‚¤ ì°¾ê¸°
                for semantic_key in self.semantic_cache.keys():
                    if semantic_key.startswith("semantic_"):
                        # í‚¤ íŒ¨í„´ ë¹„êµ
                        if self._compare_semantic_patterns(current_semantic_key, semantic_key):
                            return True

            # ì¶”ê°€ ìœ ì‚¬ë„ ê²€ì‚¬: ì…ë ¥ ìœ í˜• ë° í™˜ê²½ ì¡°ê±´ ë¹„êµ
            if self._compare_input_similarity(input_data, context, cached_item):
                return True

            return False

        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê²€ì‚¬ ì‹¤íŒ¨: {e}")
            return False

    def _compare_input_similarity(
        self,
        input_data: Dict[str, Any],
        context: Dict[str, Any],
        cached_item: Dict[str, Any],
    ) -> bool:
        """ì…ë ¥ ìœ ì‚¬ë„ ë¹„êµ"""
        try:
            # ì‚¬ìš©ì ì…ë ¥ ìœ í˜• ë¹„êµ
            current_input_type = self._classify_input_type(input_data.get("user_input", ""))

            # í™˜ê²½ ì¡°ê±´ ë¹„êµ
            current_env_conditions = self._extract_env_conditions(context)

            # ìºì‹œëœ ë°ì´í„°ì˜ í™˜ê²½ ì¡°ê±´ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ìºì‹œëœ ë°ì´í„°ì—ì„œ ì¶”ì¶œí•´ì•¼ í•¨)
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ë¹„êµë¥¼ ìœ„í•´ í˜„ì¬ ì¡°ê±´ë§Œ ì‚¬ìš©

            # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
            similarity_score = 0.0

            # ì…ë ¥ ìœ í˜• ì¼ì¹˜ (40% ê°€ì¤‘ì¹˜)
            if current_input_type in [
                "status_check",
                "performance_optimization",
                "security_enhancement",
            ]:
                similarity_score += 0.4

            # í™˜ê²½ ì¡°ê±´ ì¼ì¹˜ (60% ê°€ì¤‘ì¹˜)
            if len(current_env_conditions) > 0:
                similarity_score += 0.6

            return similarity_score >= self.similarity_threshold

        except Exception as e:
            logger.error(f"ì…ë ¥ ìœ ì‚¬ë„ ë¹„êµ ì‹¤íŒ¨: {e}")
            return False

    def _extract_env_conditions(self, context: Dict[str, Any]) -> List[str]:
        """í™˜ê²½ ì¡°ê±´ ì¶”ì¶œ"""
        conditions = []

        try:
            # í™˜ê²½ ë°ì´í„° ì¡°ê±´
            if "environment_data" in context:
                env_data = context["environment_data"]
                if "system_stability" in env_data:
                    stability = (
                        "high"
                        if env_data["system_stability"] > 0.8
                        else "medium"
                        if env_data["system_stability"] > 0.5
                        else "low"
                    )
                    conditions.append(f"stability:{stability}")

            # ë¦¬ì†ŒìŠ¤ ë°ì´í„° ì¡°ê±´
            if "resource_data" in context:
                resource_data = context["resource_data"]
                for resource_type, resource_info in resource_data.items():
                    if "availability" in resource_info:
                        availability = (
                            "high"
                            if resource_info["availability"] > 0.8
                            else ("medium" if resource_info["availability"] > 0.5 else "low")
                        )
                        conditions.append(f"{resource_type}_availability:{availability}")

            # í™˜ê²½ ë³€í™” ì¡°ê±´
            if "environmental_changes" in context:
                env_changes = context["environmental_changes"]
                if "direction" in env_changes:
                    conditions.append(f"change_direction:{env_changes['direction']}")

        except Exception as e:
            logger.error(f"í™˜ê²½ ì¡°ê±´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        return conditions

    def _compare_semantic_patterns(self, key1: str, key2: str) -> bool:
        """ì‹œë§¨í‹± í‚¤ íŒ¨í„´ ë¹„êµ (ìµœì í™”ëœ ë²„ì „)"""
        try:
            # ì •í™•í•œ ì¼ì¹˜
            if key1 == key2:
                return True

            # ë¶€ë¶„ íŒ¨í„´ ë¹„êµ
            if len(key1) > 8 and len(key2) > 8:
                # ì• 8ìë¦¬ ë¹„êµ
                if key1[:8] == key2[:8]:
                    return True

                # ì¤‘ê°„ 8ìë¦¬ ë¹„êµ
                if len(key1) > 16 and len(key2) > 16:
                    if key1[8:16] == key2[8:16]:
                        return True

            # í•´ì‹œ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = self._calculate_hash_similarity(key1, key2)
            return similarity >= 0.7  # 70% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì¼ì¹˜ë¡œ ê°„ì£¼

        except Exception:
            return False

    def _calculate_hash_similarity(self, key1: str, key2: str) -> float:
        """í•´ì‹œ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            if len(key1) != len(key2):
                return 0.0

            # ë¬¸ìë³„ ì¼ì¹˜ìœ¨ ê³„ì‚°
            matches = sum(1 for a, b in zip(key1, key2) if a == b)  # noqa: B905
            return matches / len(key1)

        except Exception:
            return 0.0


class DuRiPhaseOmega:
    """Phase Î© í†µí•© ì‹œìŠ¤í…œ"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        # Phase Î© ì‹œìŠ¤í…œë“¤
        self.survival_engine = SurvivalInstinctEngine()
        self.goal_generator = SelfGoalGenerator()
        self.evolution_system = EvolutionSystem()
        self.survival_assessment = SurvivalAssessmentSystem()

        # Phase Z ì‹œìŠ¤í…œ (ì˜µì…˜)
        self.thought_flow = None
        try:
            self.thought_flow = DuRiThoughtFlow(
                input_data={"task": "phase_omega_integration", "phase": "omega"},
                context={
                    "goal": "survival_instinct_integration",
                    "mode": "integration",
                },
            )
        except Exception as e:
            logger.warning(f"Phase Z ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        # í†µí•© ì§„í™” ì‹œìŠ¤í…œ (ë™ì  import ì‹œìŠ¤í…œ ì‚¬ìš©)
        self.integrated_evolution = None
        self._try_initialize_integrated_evolution()

        # ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.cache_system = AdvancedCacheSystem(max_size=2000, ttl=600)

        # í†µí•© ì„¤ì •
        self.integration_config = {
            "enable_thought_flow": True,
            "enable_survival_instinct": True,
            "enable_self_goals": True,
            "enable_evolution": True,
            "enable_assessment": True,
            "enable_integrated_evolution": True,  # ë™ì  import ì‹œìŠ¤í…œìœ¼ë¡œ ì¬í™œì„±í™”
            "enable_advanced_cache": True,  # ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œ í™œì„±í™”
        }

        # í†µí•© íˆìŠ¤í† ë¦¬
        self.integration_history = []

        logger.info("Phase Î© í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")

    async def process_with_survival_instinct(
        self, input_data: Dict[str, Any], context: Optional[Dict[str, Any]] = None
    ) -> PhaseOmegaResult:
        """ìƒì¡´ ë³¸ëŠ¥ì„ í¬í•¨í•œ ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ (ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œ í¬í•¨)"""
        try:
            start_time = time.time()

            if context is None:
                context = {}

            # ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œ í™•ì¸
            if self.integration_config["enable_advanced_cache"]:
                cached_result = self.cache_system.get(input_data, context)
                if cached_result:
                    logger.info(f"âš¡ ìºì‹œ íˆíŠ¸! ì‹¤í–‰ ì‹œê°„: {time.time() - start_time:.4f}ì´ˆ")
                    return cached_result

            # í†µí•© ì»¨í…ìŠ¤íŠ¸ ìƒì„±
            integration_context = IntegrationContext(
                stage=IntegrationStage.INITIALIZATION,
                status=IntegrationStatus.IN_PROGRESS,
                input_data=input_data,
                context=context,
            )

            # 1. ìƒì¡´ ìƒíƒœ í‰ê°€
            survival_status = await self._assess_survival_status(input_data, context)
            integration_context.results["survival_status"] = survival_status
            integration_context.stage = IntegrationStage.SURVIVAL_ASSESSMENT

            # 2. ìê°€ ëª©í‘œ ìƒì„±
            self_goals = await self._generate_self_goals(input_data, context, survival_status)
            integration_context.results["self_goals"] = self_goals
            integration_context.stage = IntegrationStage.SELF_GOAL_GENERATION

            # 3. ì‚¬ê³  íë¦„ ì‹¤í–‰ (Phase Z)
            thought_result = await self._execute_thought_flow(input_data, context, survival_status, self_goals)
            integration_context.results["thought_result"] = thought_result
            integration_context.stage = IntegrationStage.THOUGHT_PROCESSING

            # 4. ì§„í™” ì‹œìŠ¤í…œ ì‹¤í–‰
            evolution_result = await self._execute_evolution_system(input_data, context, survival_status, self_goals)
            integration_context.results["evolution_result"] = evolution_result
            integration_context.stage = IntegrationStage.EVOLUTION

            # 5. ìƒì¡´ í‰ê°€
            survival_assessment = await self._execute_survival_assessment(
                input_data, context, survival_status, self_goals, evolution_result
            )
            integration_context.results["survival_assessment"] = survival_assessment
            integration_context.stage = IntegrationStage.INTEGRATION

            # 6. ê²°ê³¼ í†µí•©
            phase_omega_result = await self._integrate_results(
                thought_result,
                survival_status,
                self_goals,
                evolution_result,
                survival_assessment,
            )
            integration_context.results["final_result"] = phase_omega_result
            integration_context.stage = IntegrationStage.COMPLETION
            integration_context.status = IntegrationStatus.COMPLETED
            integration_context.end_time = datetime.now()

            # 7. í†µí•© ì§„í™” ì‹œìŠ¤í…œ ì‹¤í–‰ (ìƒˆë¡œ ì¶”ê°€)
            if self.integration_config["enable_integrated_evolution"] and self.integrated_evolution:
                try:
                    # ì§„í™” ìê·¹ ìƒì„±
                    evolution_stimulus = {
                        "phase_omega_result": phase_omega_result,
                        "survival_status": survival_status,
                        "self_goals": self_goals,
                        "evolution_result": evolution_result,
                    }

                    evolution_context = {
                        "reflection_score": (
                            getattr(thought_result, "reflection_score", 0.5) if thought_result else 0.5
                        ),
                        "survival_status": survival_status,
                        "performance_metrics": {
                            "degradation_score": (
                                1.0 - getattr(phase_omega_result, "survival_score", 0.5)
                                if hasattr(phase_omega_result, "survival_score")
                                else 0.5
                            )
                        },
                    }

                    # í†µí•© ì§„í™” ì‹¤í–‰
                    evolution_result_integrated = await self.integrated_evolution.process_stimulus(
                        evolution_stimulus, evolution_context
                    )

                    integration_context.results["integrated_evolution"] = evolution_result_integrated
                    logger.info(f"í†µí•© ì§„í™” ì™„ë£Œ: ê°œì„ ì ìˆ˜ {evolution_result_integrated.overall_improvement_score:.2f}")

                except Exception as e:
                    logger.error(f"í†µí•© ì§„í™” ì‹¤í–‰ ì‹¤íŒ¨: {e}")

            # í†µí•© íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            self.integration_history.append(integration_context)

            execution_time = time.time() - start_time
            phase_omega_result.integration_time = execution_time

            # ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œì— ê²°ê³¼ ì €ì¥
            if self.integration_config["enable_advanced_cache"]:
                self.cache_system.set(input_data, context, phase_omega_result)

                # ìºì‹œ í†µê³„ ì—…ë°ì´íŠ¸ ë° ë™ì  ì¡°ì •
                cache_stats = self.cache_system.get_cache_stats()
                if cache_stats["total_requests"] % 10 == 0:  # 10ë²ˆë§ˆë‹¤ ì¡°ì •
                    self.cache_system._adjust_cache_size()
                    self.cache_system._adjust_cache_ttl()

            logger.info(f"Phase Î© í†µí•© í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ: {execution_time:.2f}ì´ˆ")

            return phase_omega_result

        except Exception as e:
            logger.error(f"Phase Î© í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
            return await self._create_failed_result(str(e))

    async def _assess_survival_status(self, input_data: Dict[str, Any], context: Dict[str, Any]) -> SurvivalStatus:
        """ìƒì¡´ ìƒíƒœ í‰ê°€"""
        try:
            if not self.integration_config["enable_survival_instinct"]:
                return await self._create_default_survival_status()

            # ìƒì¡´ ìƒíƒœ í‰ê°€
            survival_status = await self.survival_engine.assess_survival_status(input_data)

            logger.info(f"ìƒì¡´ ìƒíƒœ í‰ê°€ ì™„ë£Œ: {survival_status.status.value}")

            return survival_status

        except Exception as e:
            logger.error(f"ìƒì¡´ ìƒíƒœ í‰ê°€ ì‹¤íŒ¨: {e}")
            return await self._create_default_survival_status()

    async def _generate_self_goals(
        self,
        input_data: Dict[str, Any],
        context: Dict[str, Any],
        survival_status: SurvivalStatus,
    ) -> List[SelfGoal]:
        """ìê°€ ëª©í‘œ ìƒì„±"""
        try:
            if not self.integration_config["enable_self_goals"]:
                return []

            # í˜„ì¬ ìƒíƒœ ë¶„ì„
            current_state = await self.goal_generator.analyze_current_state(input_data)

            # ê°œì„  ì˜ì—­ ì‹ë³„
            improvement_areas = await self.goal_generator.identify_improvement_areas(current_state)

            # ìê°€ ëª©í‘œ ìƒì„±
            self_goals = await self.goal_generator.generate_self_goals(current_state, improvement_areas)

            # ëª©í‘œ ìš°ì„ ìˆœìœ„ ì„¤ì •
            prioritized_goals = await self.goal_generator.prioritize_goals(self_goals)

            logger.info(f"ìê°€ ëª©í‘œ ìƒì„± ì™„ë£Œ: {len(prioritized_goals)}ê°œ ëª©í‘œ")

            return prioritized_goals

        except Exception as e:
            logger.error(f"ìê°€ ëª©í‘œ ìƒì„± ì‹¤íŒ¨: {e}")
            return []

    async def _execute_thought_flow(
        self,
        input_data: Dict[str, Any],
        context: Dict[str, Any],
        survival_status: SurvivalStatus,
        self_goals: List[SelfGoal],
    ) -> Optional[Any]:
        """ì‚¬ê³  íë¦„ ì‹¤í–‰ (Phase Z)"""
        try:
            if not self.integration_config["enable_thought_flow"] or self.thought_flow is None:
                return None

            # Phase Z ì»¨í…ìŠ¤íŠ¸ì— ìƒì¡´ ì •ë³´ ì¶”ê°€
            thought_context = context.copy()
            thought_context.update(
                {
                    "survival_status": survival_status,
                    "self_goals": self_goals,
                    "phase_omega_context": True,
                }
            )

            # DuRiThoughtFlow ì¸ìŠ¤í„´ìŠ¤ì˜ process ë©”ì„œë“œ í˜¸ì¶œ
            thought_result = await self.thought_flow.process()

            logger.info("ì‚¬ê³  íë¦„ ì‹¤í–‰ ì™„ë£Œ")

            return thought_result

        except Exception as e:
            logger.error(f"ì‚¬ê³  íë¦„ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None

    async def _execute_evolution_system(
        self,
        input_data: Dict[str, Any],
        context: Dict[str, Any],
        survival_status: SurvivalStatus,
        self_goals: List[SelfGoal],
    ) -> Optional[EvolutionResult]:
        """ì§„í™” ì‹œìŠ¤í…œ ì‹¤í–‰"""
        try:
            if not self.integration_config["enable_evolution"]:
                return None

            # ì§„í™” ì§„í–‰ë„ í‰ê°€
            evolution_progress = await self.evolution_system.evaluate_evolution_progress(input_data)  # noqa: F841

            # í™˜ê²½ ì ì‘
            environmental_changes = context.get("environmental_changes", {})
            adaptation_result = await self.evolution_system.adapt_to_environment(environmental_changes)  # noqa: F841

            # ëŠ¥ë ¥ ì§„í™”
            target_capabilities = [goal.title for goal in self_goals[:3]]  # ìƒìœ„ 3ê°œ ëª©í‘œ
            evolution_result = await self.evolution_system.evolve_capabilities(target_capabilities)

            # ìƒì¡´ ì „ëµ ìµœì í™”
            survival_strategy = await self.evolution_system.optimize_survival_strategy()  # noqa: F841

            logger.info(f"ì§„í™” ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ: ì§„í™” ì ìˆ˜={evolution_result.evolution_score:.3f}")

            return evolution_result

        except Exception as e:
            logger.error(f"ì§„í™” ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None

    async def _execute_survival_assessment(
        self,
        input_data: Dict[str, Any],
        context: Dict[str, Any],
        survival_status: SurvivalStatus,
        self_goals: List[SelfGoal],
        evolution_result: Optional[EvolutionResult],
    ) -> Dict[str, Any]:
        """ìƒì¡´ í‰ê°€ ì‹¤í–‰"""
        try:
            if not self.integration_config["enable_assessment"]:
                return {}

            # í™˜ê²½ì  ìœ„í—˜ í‰ê°€
            environment_data = context.get("environment_data", {})
            risk_assessments = await self.survival_assessment.assess_environmental_risks(environment_data)

            # ìì› ê°€ìš©ì„± í‰ê°€
            resource_data = context.get("resource_data", {})
            resource_assessments = await self.survival_assessment.evaluate_resource_availability(resource_data)

            # ìƒì¡´ ì ìˆ˜ ê³„ì‚°
            survival_score = await self.survival_assessment.calculate_survival_score(
                risk_assessments, resource_assessments
            )

            # ìƒì¡´ ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = await self.survival_assessment.generate_survival_recommendations(
                survival_score, risk_assessments, resource_assessments
            )

            assessment_result = {
                "risk_assessments": risk_assessments,
                "resource_assessments": resource_assessments,
                "survival_score": survival_score,
                "recommendations": recommendations,
            }

            logger.info(f"ìƒì¡´ í‰ê°€ ì™„ë£Œ: ìƒì¡´ ì ìˆ˜={survival_score.overall_score:.3f}")

            return assessment_result

        except Exception as e:
            logger.error(f"ìƒì¡´ í‰ê°€ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {}

    async def _integrate_results(
        self,
        thought_result: Optional[Any],
        survival_status: SurvivalStatus,
        self_goals: List[SelfGoal],
        evolution_result: Optional[EvolutionResult],
        survival_assessment: Dict[str, Any],
    ) -> PhaseOmegaResult:
        """ê²°ê³¼ í†µí•©"""
        try:
            # Phase Î© ê²°ê³¼ ìƒì„±
            phase_omega_result = PhaseOmegaResult(
                thought_result=thought_result,
                survival_status=survival_status,
                self_goals=self_goals,
                evolution_result=evolution_result,
                survival_score=survival_assessment.get("survival_score"),
                risk_assessments=survival_assessment.get("risk_assessments", []),
                resource_assessments=survival_assessment.get("resource_assessments", {}),
                recommendations=survival_assessment.get("recommendations", []),
                success=True,
            )

            # ê²°ê³¼ ê²€ì¦
            await self._validate_integration_result(phase_omega_result)

            logger.info("ê²°ê³¼ í†µí•© ì™„ë£Œ")

            return phase_omega_result

        except Exception as e:
            logger.error(f"ê²°ê³¼ í†µí•© ì‹¤íŒ¨: {e}")
            return await self._create_failed_result(str(e))

    async def _validate_integration_result(self, result: PhaseOmegaResult) -> bool:
        """í†µí•© ê²°ê³¼ ê²€ì¦"""
        try:
            # ê¸°ë³¸ ê²€ì¦
            if result.survival_status is None:
                logger.warning("ìƒì¡´ ìƒíƒœê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            if not result.self_goals:
                logger.warning("ìê°€ ëª©í‘œê°€ ì—†ìŠµë‹ˆë‹¤")
                return False

            # ìƒì¡´ ì ìˆ˜ ê²€ì¦
            if result.survival_score and result.survival_score.overall_score < 0.3:
                logger.warning(f"ìƒì¡´ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤: {result.survival_score.overall_score:.3f}")

            # ì§„í™” ê²°ê³¼ ê²€ì¦
            if result.evolution_result and result.evolution_result.evolution_score < 0.2:
                logger.warning(f"ì§„í™” ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤: {result.evolution_result.evolution_score:.3f}")

            return True

        except Exception as e:
            logger.error(f"í†µí•© ê²°ê³¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    async def _create_default_survival_status(self) -> SurvivalStatus:
        """ê¸°ë³¸ ìƒì¡´ ìƒíƒœ ìƒì„±"""
        return SurvivalStatus(
            status="stable",
            survival_probability=0.8,
            threats=[],
            resources_available={},
            environmental_factors={},
            last_assessment=datetime.now(),
            confidence_score=0.7,
        )

    async def _create_failed_result(self, error_message: str) -> PhaseOmegaResult:
        """ì‹¤íŒ¨í•œ ê²°ê³¼ ìƒì„±"""
        return PhaseOmegaResult(
            thought_result=None,
            survival_status=None,
            self_goals=[],
            evolution_result=None,
            survival_score=None,
            risk_assessments=[],
            resource_assessments={},
            recommendations=[],
            integration_time=0.0,
            success=False,
            error_message=error_message,
        )

    async def get_integration_summary(self) -> Dict[str, Any]:
        """í†µí•© ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        try:
            summary = {
                "total_integrations": len(self.integration_history),
                "successful_integrations": len(
                    [h for h in self.integration_history if h.status == IntegrationStatus.COMPLETED]
                ),
                "failed_integrations": len(
                    [h for h in self.integration_history if h.status == IntegrationStatus.FAILED]
                ),
                "average_integration_time": 0.0,
                "last_integration": None,
                "system_status": {
                    "survival_engine": "active",
                    "goal_generator": "active",
                    "evolution_system": "active",
                    "survival_assessment": "active",
                    "thought_flow": "active" if self.thought_flow else "inactive",
                },
            }

            # ìºì‹œ í†µê³„ ì¶”ê°€
            if self.integration_config["enable_advanced_cache"]:
                cache_stats = self.cache_system.get_cache_stats()
                summary["cache_stats"] = cache_stats

            if self.integration_history:
                # í‰ê·  í†µí•© ì‹œê°„ ê³„ì‚°
                integration_times = []
                for history in self.integration_history:
                    if history.end_time:
                        duration = (history.end_time - history.start_time).total_seconds()
                        integration_times.append(duration)

                if integration_times:
                    summary["average_integration_time"] = sum(integration_times) / len(integration_times)

                # ë§ˆì§€ë§‰ í†µí•© ì •ë³´
                last_integration = self.integration_history[-1]
                summary["last_integration"] = {
                    "stage": last_integration.stage.value,
                    "status": last_integration.status.value,
                    "start_time": last_integration.start_time.isoformat(),
                    "end_time": (last_integration.end_time.isoformat() if last_integration.end_time else None),
                }

            return summary

        except Exception as e:
            logger.error(f"í†µí•© ìš”ì•½ ì •ë³´ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def reset_integration_system(self) -> bool:
        """í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # í†µí•© íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
            self.integration_history.clear()

            # ê° ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.survival_engine = SurvivalInstinctEngine()
            self.goal_generator = SelfGoalGenerator()
            self.evolution_system = EvolutionSystem()
            self.survival_assessment = SurvivalAssessmentSystem()

            # ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            if self.integration_config["enable_advanced_cache"]:
                self.cache_system.clear_cache()

            logger.info("í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            return True

        except Exception as e:
            logger.error(f"í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def update_integration_config(self, new_config: Dict[str, Any]) -> bool:
        """í†µí•© ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            # ì„¤ì • ê²€ì¦
            valid_keys = [
                "enable_thought_flow",
                "enable_survival_instinct",
                "enable_self_goals",
                "enable_evolution",
                "enable_assessment",
                "enable_integrated_evolution",  # ìƒˆë¡œ ì¶”ê°€
                "enable_advanced_cache",  # ìƒˆë¡œ ì¶”ê°€
            ]

            for key, value in new_config.items():
                if key in valid_keys and isinstance(value, bool):
                    self.integration_config[key] = value

            logger.info(f"í†µí•© ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ: {new_config}")
            return True

        except Exception as e:
            logger.error(f"í†µí•© ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return False

    def _try_initialize_integrated_evolution(self):
        """í†µí•© ì§„í™” ì‹œìŠ¤í…œì„ ë™ì ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ëŠ” ë©”ì„œë“œ"""
        if self.integrated_evolution is None:
            try:
                self.integrated_evolution = _get_integrated_evolution_system()
                if self.integrated_evolution:
                    logger.info("í†µí•© ì§„í™” ì‹œìŠ¤í…œ ë™ì  import ë° ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    logger.warning("í†µí•© ì§„í™” ì‹œìŠ¤í…œ ë™ì  import ì‹¤íŒ¨ ë˜ëŠ” ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"í†µí•© ì§„í™” ì‹œìŠ¤í…œ ë™ì  ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    async def get_cache_performance_report(self) -> Dict[str, Any]:
        """ìºì‹œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ë°˜í™˜"""
        try:
            if not self.integration_config["enable_advanced_cache"]:
                return {"error": "ê³ ê¸‰ ìºì‹œ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤."}

            cache_stats = self.cache_system.get_cache_stats()

            # ì„±ëŠ¥ ë¶„ì„
            performance_analysis = {
                "hit_rate_category": (
                    "ìš°ìˆ˜"
                    if cache_stats["hit_rate"] >= 80
                    else "ì–‘í˜¸"
                    if cache_stats["hit_rate"] >= 60
                    else "ê°œì„  í•„ìš”"
                ),
                "cache_efficiency": (
                    "ë†’ìŒ"
                    if cache_stats["cache_efficiency"] > 0.5
                    else "ë³´í†µ"
                    if cache_stats["cache_efficiency"] > 0.2
                    else "ë‚®ìŒ"
                ),
                "recommendations": [],
            }

            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            if cache_stats["hit_rate"] < 80:
                performance_analysis["recommendations"].append("ìºì‹œ í‚¤ ìƒì„± ì•Œê³ ë¦¬ì¦˜ ìµœì í™” í•„ìš”")
                performance_analysis["recommendations"].append("ìºì‹œ í¬ê¸° ì¦ê°€ ê³ ë ¤")
                performance_analysis["recommendations"].append("TTL ì¡°ì • ê²€í† ")

            if cache_stats["cache_efficiency"] < 0.3:
                performance_analysis["recommendations"].append("ìºì‹œ ì ‘ê·¼ íŒ¨í„´ ë¶„ì„ í•„ìš”")
                performance_analysis["recommendations"].append("LRU ì •ë¦¬ ì•Œê³ ë¦¬ì¦˜ ê°œì„ ")

            return {
                "cache_stats": cache_stats,
                "performance_analysis": performance_analysis,
                "optimization_status": ("ì™„ë£Œ" if cache_stats["hit_rate"] >= 80 else "ì§„í–‰ ì¤‘"),
            }

        except Exception as e:
            logger.error(f"ìºì‹œ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return {"error": str(e)}


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # Phase Î© í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    phase_omega = DuRiPhaseOmega()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_cases = [
        {
            "user_input": "ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ê°œì„  ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”",
            "context": {
                "environmental_changes": {"magnitude": 0.3, "direction": "positive"},
                "environment_data": {
                    "system_stability": 0.8,
                    "performance_metrics": {"accuracy": 0.75, "efficiency": 0.7},
                },
                "resource_data": {
                    "computational": {
                        "availability": 0.8,
                        "utilization": 0.6,
                        "efficiency": 0.7,
                        "capacity": 1.0,
                    },
                    "memory": {
                        "availability": 0.7,
                        "utilization": 0.5,
                        "efficiency": 0.8,
                        "capacity": 1.0,
                    },
                },
            },
        },
        {
            "user_input": "ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
            "context": {
                "environmental_changes": {"magnitude": 0.5, "direction": "positive"},
                "environment_data": {
                    "system_stability": 0.9,
                    "performance_metrics": {"accuracy": 0.85, "efficiency": 0.8},
                },
                "resource_data": {
                    "computational": {
                        "availability": 0.9,
                        "utilization": 0.7,
                        "efficiency": 0.8,
                        "capacity": 1.0,
                    },
                    "memory": {
                        "availability": 0.8,
                        "utilization": 0.6,
                        "efficiency": 0.9,
                        "capacity": 1.0,
                    },
                },
            },
        },
        {
            "user_input": "ë³´ì•ˆ ê°•í™” ë°©ì•ˆì„ ì œì‹œí•´ì£¼ì„¸ìš”",
            "context": {
                "environmental_changes": {"magnitude": 0.2, "direction": "negative"},
                "environment_data": {
                    "system_stability": 0.7,
                    "performance_metrics": {"accuracy": 0.65, "efficiency": 0.6},
                },
                "resource_data": {
                    "computational": {
                        "availability": 0.6,
                        "utilization": 0.4,
                        "efficiency": 0.6,
                        "capacity": 1.0,
                    },
                    "memory": {
                        "availability": 0.5,
                        "utilization": 0.3,
                        "efficiency": 0.7,
                        "capacity": 1.0,
                    },
                },
            },
        },
    ]

    print("ğŸš€ Phase Î© í†µí•© í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (ìºì‹œ íˆíŠ¸ìœ¨ í–¥ìƒ í…ŒìŠ¤íŠ¸)...")

    # ì—¬ëŸ¬ ë²ˆ í…ŒìŠ¤íŠ¸í•˜ì—¬ ìºì‹œ íˆíŠ¸ìœ¨ ì¸¡ì •
    for i, test_case in enumerate(test_cases * 2):  # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë¥¼ 2ë²ˆì”© ì‹¤í–‰
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ {i+1}/6 ì‹¤í–‰ ì¤‘...")

        start_time = time.time()
        result = await phase_omega.process_with_survival_instinct(test_case, test_case["context"])  # noqa: F841
        execution_time = time.time() - start_time

        print(f"âœ… í…ŒìŠ¤íŠ¸ {i+1} ì™„ë£Œ: {execution_time:.4f}ì´ˆ")

        # ìºì‹œ í†µê³„ ì¶œë ¥
        if phase_omega.integration_config["enable_advanced_cache"]:
            cache_stats = phase_omega.cache_system.get_cache_stats()
            print(
                f"ğŸ“ˆ ìºì‹œ íˆíŠ¸ìœ¨: {cache_stats['hit_rate']:.1f}% (íˆíŠ¸: {cache_stats['cache_hits']}, ë¯¸ìŠ¤: {cache_stats['cache_misses']})"  # noqa: E501
            )

    # ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸
    print("\nğŸ¯ ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸:")
    performance_report = await phase_omega.get_cache_performance_report()

    if "error" not in performance_report:
        cache_stats = performance_report["cache_stats"]
        analysis = performance_report["performance_analysis"]

        print(f"ğŸ“Š ìºì‹œ íˆíŠ¸ìœ¨: {cache_stats['hit_rate']:.1f}%")
        print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„±: {'âœ… ë‹¬ì„±' if cache_stats['hit_rate'] >= 80 else 'ğŸ”„ ì§„í–‰ ì¤‘'}")
        print(f"ğŸ“ˆ ì„±ëŠ¥ ë“±ê¸‰: {analysis['hit_rate_category']}")
        print(f"âš¡ ìºì‹œ íš¨ìœ¨ì„±: {analysis['cache_efficiency']}")

        if analysis["recommendations"]:
            print("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for rec in analysis["recommendations"]:
                print(f"  - {rec}")
    else:
        print(f"âŒ ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {performance_report['error']}")

    # í†µí•© ìš”ì•½ ì •ë³´
    summary = await phase_omega.get_integration_summary()
    print("\nğŸ“‹ í†µí•© ìš”ì•½:")
    print(f"ì´ í†µí•© íšŸìˆ˜: {summary['total_integrations']}")
    print(f"ì„±ê³µí•œ í†µí•©: {summary['successful_integrations']}")
    print(f"ì‹¤íŒ¨í•œ í†µí•©: {summary['failed_integrations']}")
    print(f"í‰ê·  ì‹¤í–‰ ì‹œê°„: {summary['average_integration_time']:.2f}ì´ˆ")


if __name__ == "__main__":
    asyncio.run(main())
