#!/usr/bin/env python3
"""
DuRiCore Phase 5.5.3 - ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ
í™˜ê²½ ë³€í™” ê°ì§€ ë° ë™ì  ëŒ€ì‘ ëŠ¥ë ¥ì„ ì œê³µí•˜ëŠ” ì‹œìŠ¤í…œ
"""

import asyncio
import json
import logging
import math
import random
import time
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

# Phase 6.2.5 - CLARION í•™ìŠµ ì‹œìŠ¤í…œ ì¶”ê°€
from clarion_learning_system import (
    CLARIONLearningSystem,
    LearningPhase,
    LearningType,
    ReinforcementType,
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class AdaptationType(Enum):
    """ì ì‘ ìœ í˜•"""

    ENVIRONMENTAL = "environmental"  # í™˜ê²½ ë³€í™” ì ì‘
    BEHAVIORAL = "behavioral"  # í–‰ë™ íŒ¨í„´ ì ì‘
    COGNITIVE = "cognitive"  # ì¸ì§€ì  ì ì‘
    STRATEGIC = "strategic"  # ì „ëµì  ì ì‘
    SOCIAL = "social"  # ì‚¬íšŒì  ì ì‘


class LearningMode(Enum):
    """í•™ìŠµ ëª¨ë“œ"""

    EXPLORATION = "exploration"  # íƒìƒ‰ ëª¨ë“œ
    EXPLOITATION = "exploitation"  # í™œìš© ëª¨ë“œ
    BALANCED = "balanced"  # ê· í˜• ëª¨ë“œ
    ADAPTIVE = "adaptive"  # ì ì‘ ëª¨ë“œ


@dataclass
class AdaptationResult:
    """ì ì‘ ê²°ê³¼"""

    adaptation_type: AdaptationType
    learning_mode: LearningMode
    adaptation_score: float
    environment_changes: List[str]
    behavioral_changes: List[str]
    learning_efficiency: float
    adaptation_speed: float
    success_rate: float
    created_at: str
    success: bool = True


@dataclass
class EnvironmentSnapshot:
    """í™˜ê²½ ìŠ¤ëƒ…ìƒ·"""

    complexity: float
    volatility: float
    predictability: float
    resource_availability: float
    change_rate: float


class AdaptiveLearningSystem:
    """ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ"""

    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.adaptation_history = []
        self.environment_monitor = EnvironmentMonitor()
        self.behavior_analyzer = BehaviorAnalyzer()
        self.learning_optimizer = LearningOptimizer()
        self.adaptation_engine = AdaptationEngine()

        # Phase 6.2.5 - CLARION í•™ìŠµ ì‹œìŠ¤í…œ ì¶”ê°€
        self.clarion_system = CLARIONLearningSystem()

        logger.info("ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (Phase 6.2.5 í¬í•¨)")

    async def adapt_to_environment(
        self,
        current_context: Dict[str, Any],
        target_objectives: Optional[Dict[str, Any]] = None,
    ) -> AdaptationResult:
        """í™˜ê²½ì— ì ì‘"""
        try:
            start_time = time.time()

            # 1. í™˜ê²½ ë³€í™” ê°ì§€
            environment_changes = await self.environment_monitor.detect_changes(
                current_context
            )

            # 2. í–‰ë™ íŒ¨í„´ ë¶„ì„
            behavior_analysis = await self.behavior_analyzer.analyze_behavior(
                current_context
            )

            # 3. í•™ìŠµ ëª¨ë“œ ê²°ì •
            learning_mode = await self._determine_learning_mode(
                environment_changes, behavior_analysis
            )

            # 4. ì ì‘ ì „ëµ ìˆ˜ë¦½
            adaptation_strategy = await self._create_adaptation_strategy(
                environment_changes, behavior_analysis, learning_mode
            )

            # 5. ì ì‘ ì‹¤í–‰
            adaptation_result = await self.adaptation_engine.execute_adaptation(
                current_context, adaptation_strategy
            )

            # 6. CLARION í•™ìŠµ ì‹œìŠ¤í…œ ì‹¤í–‰ (Phase 6.2.5)
            clarion_result = await self._execute_clarion_learning(
                current_context, adaptation_result, learning_mode
            )

            # 7. í•™ìŠµ ìµœì í™” (CLARION ê²°ê³¼ í¬í•¨)
            learning_optimization = await self.learning_optimizer.optimize_learning(
                adaptation_result, learning_mode, clarion_result
            )

            # 8. ì ì‘ ì ìˆ˜ ê³„ì‚°
            adaptation_score = self._calculate_adaptation_score(
                environment_changes, adaptation_result, learning_optimization
            )

            # 8. ì„±ê³µë¥  ê³„ì‚°
            success_rate = self._calculate_success_rate(
                adaptation_result, learning_optimization
            )

            result = AdaptationResult(
                adaptation_type=adaptation_strategy.get(
                    "type", AdaptationType.ENVIRONMENTAL
                ),
                learning_mode=learning_mode,
                adaptation_score=adaptation_score,
                environment_changes=environment_changes.get("changes", []),
                behavioral_changes=adaptation_result.get("behavioral_changes", []),
                learning_efficiency=learning_optimization.get("efficiency", 0.0),
                adaptation_speed=adaptation_result.get("speed", 0.0),
                success_rate=success_rate,
                created_at=datetime.now().isoformat(),
            )

            # ì ì‘ ê¸°ë¡ ì €ì¥
            self.adaptation_history.append(result)

            execution_time = time.time() - start_time
            logger.info(
                f"ì ì‘ ì™„ë£Œ: {adaptation_strategy.get('type', 'unknown')}, "
                f"ì ì‘ì ìˆ˜: {adaptation_score:.2f}, ì‹œê°„: {execution_time:.3f}ì´ˆ"
            )

            return result

        except Exception as e:
            logger.error(f"ì ì‘ ì‹¤íŒ¨: {e}")
            return AdaptationResult(
                adaptation_type=AdaptationType.ENVIRONMENTAL,
                learning_mode=LearningMode.BALANCED,
                adaptation_score=0.0,
                environment_changes=[],
                behavioral_changes=[],
                learning_efficiency=0.0,
                adaptation_speed=0.0,
                success_rate=0.0,
                created_at=datetime.now().isoformat(),
                success=False,
            )

    async def _execute_clarion_learning(
        self,
        context: Dict[str, Any],
        adaptation_result: Dict[str, Any],
        learning_mode: LearningMode,
    ) -> Dict[str, Any]:
        """CLARION í•™ìŠµ ì‹œìŠ¤í…œ ì‹¤í–‰"""
        try:
            # í•™ìŠµ ë¡œê·¸ ë°ì´í„° ìƒì„±
            log_data = {
                "context": context,
                "action": adaptation_result.get("action", "adapt"),
                "outcome": (
                    "success" if adaptation_result.get("success", False) else "failure"
                ),
                "success": adaptation_result.get("success", False),
                "learning_score": adaptation_result.get("adaptation_score", 0.0),
                "reinforcement_history": [],
            }

            # CLARION í•™ìŠµ ì‹œìŠ¤í…œìœ¼ë¡œ ë¡œê·¸ ì²˜ë¦¬
            clarion_result = await self.clarion_system.process_learning_log(log_data)

            # í•™ìŠµ íŒ¨í„´ ë¶„ì„
            pattern_analysis = await self.clarion_system.analyze_learning_patterns()

            return {
                "clarion_result": clarion_result,
                "pattern_analysis": pattern_analysis,
                "learning_type": clarion_result.learning_type.value,
                "reinforcement_type": clarion_result.reinforcement_type.value,
                "learning_phase": clarion_result.learning_phase.value,
                "pattern_strength": clarion_result.pattern_strength,
                "learning_efficiency": clarion_result.learning_efficiency,
                "transfer_ability": clarion_result.transfer_ability,
                "consolidation_level": clarion_result.consolidation_level,
            }

        except Exception as e:
            logger.error(f"CLARION í•™ìŠµ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "clarion_result": None,
                "pattern_analysis": {},
                "learning_type": "explicit",
                "reinforcement_type": "neutral",
                "learning_phase": "acquisition",
                "pattern_strength": 0.0,
                "learning_efficiency": 0.0,
                "transfer_ability": 0.0,
                "consolidation_level": 0.0,
            }

    async def _determine_learning_mode(
        self, environment_changes: Dict[str, Any], behavior_analysis: Dict[str, Any]
    ) -> LearningMode:
        """í•™ìŠµ ëª¨ë“œ ê²°ì •"""
        try:
            # í™˜ê²½ ë³€í™” ì •ë„ì— ë”°ë¥¸ ëª¨ë“œ ê²°ì •
            change_intensity = environment_changes.get("change_intensity", 0.5)
            volatility = environment_changes.get("volatility", 0.5)

            if change_intensity > 0.7 or volatility > 0.7:
                return LearningMode.EXPLORATION
            elif change_intensity < 0.3 and volatility < 0.3:
                return LearningMode.EXPLOITATION
            elif change_intensity > 0.5 or volatility > 0.5:
                return LearningMode.ADAPTIVE
            else:
                return LearningMode.BALANCED

        except Exception as e:
            logger.error(f"í•™ìŠµ ëª¨ë“œ ê²°ì • ì‹¤íŒ¨: {e}")
            return LearningMode.BALANCED

    async def _create_adaptation_strategy(
        self,
        environment_changes: Dict[str, Any],
        behavior_analysis: Dict[str, Any],
        learning_mode: LearningMode,
    ) -> Dict[str, Any]:
        """ì ì‘ ì „ëµ ìˆ˜ë¦½"""
        try:
            strategy = {
                "type": self._determine_adaptation_type(environment_changes),
                "learning_mode": learning_mode,
                "focus_areas": self._identify_focus_areas(
                    environment_changes, behavior_analysis
                ),
                "adaptation_speed": self._calculate_adaptation_speed(
                    environment_changes
                ),
                "risk_tolerance": self._calculate_risk_tolerance(learning_mode),
            }
            return strategy

        except Exception as e:
            logger.error(f"ì ì‘ ì „ëµ ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            return {
                "type": AdaptationType.ENVIRONMENTAL,
                "learning_mode": LearningMode.BALANCED,
                "focus_areas": [],
                "adaptation_speed": 0.5,
                "risk_tolerance": 0.5,
            }

    def _determine_adaptation_type(
        self, environment_changes: Dict[str, Any]
    ) -> AdaptationType:
        """ì ì‘ ìœ í˜• ê²°ì •"""
        change_type = environment_changes.get("change_type", "environmental")

        if change_type == "behavioral":
            return AdaptationType.BEHAVIORAL
        elif change_type == "cognitive":
            return AdaptationType.COGNITIVE
        elif change_type == "strategic":
            return AdaptationType.STRATEGIC
        elif change_type == "social":
            return AdaptationType.SOCIAL
        else:
            return AdaptationType.ENVIRONMENTAL

    def _identify_focus_areas(
        self, environment_changes: Dict[str, Any], behavior_analysis: Dict[str, Any]
    ) -> List[str]:
        """ì¤‘ì  ì˜ì—­ ì‹ë³„"""
        focus_areas = []

        # í™˜ê²½ ë³€í™” ê¸°ë°˜ ì˜ì—­
        changes = environment_changes.get("changes", [])
        for change in changes:
            if "complexity" in change.lower():
                focus_areas.append("ë³µì¡ë„ ê´€ë¦¬")
            elif "speed" in change.lower():
                focus_areas.append("ì†ë„ ì ì‘")
            elif "efficiency" in change.lower():
                focus_areas.append("íš¨ìœ¨ì„± ìµœì í™”")

        # í–‰ë™ ë¶„ì„ ê¸°ë°˜ ì˜ì—­
        patterns = behavior_analysis.get("patterns", [])
        for pattern in patterns:
            if "learning" in pattern.lower():
                focus_areas.append("í•™ìŠµ íŒ¨í„´ ê°œì„ ")
            elif "decision" in pattern.lower():
                focus_areas.append("ì˜ì‚¬ê²°ì • ìµœì í™”")

        return focus_areas

    def _calculate_adaptation_speed(self, environment_changes: Dict[str, Any]) -> float:
        """ì ì‘ ì†ë„ ê³„ì‚°"""
        change_intensity = environment_changes.get("change_intensity", 0.5)
        urgency = environment_changes.get("urgency", 0.5)

        # ë³€í™”ê°€ í´ìˆ˜ë¡ ë¹ ë¥¸ ì ì‘ í•„ìš”
        speed = (change_intensity + urgency) / 2
        return min(max(speed, 0.1), 1.0)

    def _calculate_risk_tolerance(self, learning_mode: LearningMode) -> float:
        """ìœ„í—˜ í—ˆìš©ë„ ê³„ì‚°"""
        tolerances = {
            LearningMode.EXPLORATION: 0.8,  # íƒìƒ‰ ëª¨ë“œ: ë†’ì€ ìœ„í—˜ í—ˆìš©
            LearningMode.EXPLOITATION: 0.2,  # í™œìš© ëª¨ë“œ: ë‚®ì€ ìœ„í—˜ í—ˆìš©
            LearningMode.BALANCED: 0.5,  # ê· í˜• ëª¨ë“œ: ì¤‘ê°„ ìœ„í—˜ í—ˆìš©
            LearningMode.ADAPTIVE: 0.6,  # ì ì‘ ëª¨ë“œ: ì ë‹¹í•œ ìœ„í—˜ í—ˆìš©
        }
        return tolerances.get(learning_mode, 0.5)

    def _calculate_adaptation_score(
        self,
        environment_changes: Dict[str, Any],
        adaptation_result: Dict[str, Any],
        learning_optimization: Dict[str, Any],
    ) -> float:
        """ì ì‘ ì ìˆ˜ ê³„ì‚°"""
        try:
            # í™˜ê²½ ë³€í™” ëŒ€ì‘ ì ìˆ˜
            change_response = adaptation_result.get("change_response", 0.5)

            # í–‰ë™ ë³€í™” ì ìˆ˜
            behavior_change = adaptation_result.get("behavior_change", 0.5)

            # í•™ìŠµ íš¨ìœ¨ì„± ì ìˆ˜
            learning_efficiency = learning_optimization.get("efficiency", 0.5)

            # ì ì‘ ì†ë„ ì ìˆ˜
            adaptation_speed = adaptation_result.get("speed", 0.5)

            # ê°€ì¤‘ í‰ê· 
            score = (
                change_response * 0.3
                + behavior_change * 0.3
                + learning_efficiency * 0.2
                + adaptation_speed * 0.2
            )

            return min(max(score, 0.0), 1.0)

        except Exception as e:
            logger.error(f"ì ì‘ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    def _calculate_success_rate(
        self, adaptation_result: Dict[str, Any], learning_optimization: Dict[str, Any]
    ) -> float:
        """ì„±ê³µë¥  ê³„ì‚°"""
        try:
            # ì ì‘ ì„±ê³µë¥ 
            adaptation_success = adaptation_result.get("success_rate", 0.5)

            # í•™ìŠµ ì„±ê³µë¥ 
            learning_success = learning_optimization.get("success_rate", 0.5)

            # í†µí•© ì„±ê³µë¥ 
            success_rate = (adaptation_success + learning_success) / 2
            return min(max(success_rate, 0.0), 1.0)

        except Exception as e:
            logger.error(f"ì„±ê³µë¥  ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5

    async def get_adaptation_history(self) -> List[Dict[str, Any]]:
        """ì ì‘ ê¸°ë¡ ì¡°íšŒ"""
        return [asdict(result) for result in self.adaptation_history[-10:]]

    async def get_system_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        return {
            "system": "adaptive_learning",
            "status": "active",
            "adaptation_count": len(self.adaptation_history),
            "average_adaptation_score": self._calculate_average_adaptation_score(),
            "last_adaptation": (
                self.adaptation_history[-1].created_at
                if self.adaptation_history
                else None
            ),
        }

    def _calculate_average_adaptation_score(self) -> float:
        """í‰ê·  ì ì‘ ì ìˆ˜ ê³„ì‚°"""
        if not self.adaptation_history:
            return 0.0

        scores = [result.adaptation_score for result in self.adaptation_history]
        return sum(scores) / len(scores)


class EnvironmentMonitor:
    """í™˜ê²½ ëª¨ë‹ˆí„°"""

    async def detect_changes(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """í™˜ê²½ ë³€í™” ê°ì§€"""
        try:
            changes = {
                "changes": self._identify_changes(context),
                "change_intensity": self._calculate_change_intensity(context),
                "change_type": self._determine_change_type(context),
                "volatility": self._calculate_volatility(context),
                "urgency": self._calculate_urgency(context),
            }
            return changes
        except Exception as e:
            logger.error(f"í™˜ê²½ ë³€í™” ê°ì§€ ì‹¤íŒ¨: {e}")
            return {}

    def _identify_changes(self, context: Dict[str, Any]) -> List[str]:
        """ë³€í™” ì‹ë³„"""
        changes = []

        if context.get("complexity") == "high":
            changes.append("ë³µì¡ë„ ì¦ê°€")

        if context.get("urgency") == "high":
            changes.append("ê¸´ê¸‰ë„ ì¦ê°€")

        if context.get("resource_limitation"):
            changes.append("ìì› ì œì•½ ë³€í™”")

        if context.get("technology_change"):
            changes.append("ê¸°ìˆ  ë³€í™”")

        return changes

    def _calculate_change_intensity(self, context: Dict[str, Any]) -> float:
        """ë³€í™” ê°•ë„ ê³„ì‚°"""
        intensity_factors = [
            1.0 if context.get("complexity") == "high" else 0.3,
            1.0 if context.get("urgency") == "high" else 0.3,
            0.8 if context.get("resource_limitation") else 0.2,
            0.7 if context.get("technology_change") else 0.2,
        ]
        return sum(intensity_factors) / len(intensity_factors)

    def _determine_change_type(self, context: Dict[str, Any]) -> str:
        """ë³€í™” ìœ í˜• ê²°ì •"""
        if context.get("behavioral_change"):
            return "behavioral"
        elif context.get("cognitive_change"):
            return "cognitive"
        elif context.get("strategic_change"):
            return "strategic"
        elif context.get("social_change"):
            return "social"
        else:
            return "environmental"

    def _calculate_volatility(self, context: Dict[str, Any]) -> float:
        """ë³€ë™ì„± ê³„ì‚°"""
        volatility_factors = [
            context.get("market_volatility", 0.3),
            context.get("technology_volatility", 0.3),
            context.get("environment_volatility", 0.3),
        ]
        return sum(volatility_factors) / len(volatility_factors)

    def _calculate_urgency(self, context: Dict[str, Any]) -> float:
        """ê¸´ê¸‰ë„ ê³„ì‚°"""
        urgency_factors = [
            1.0 if context.get("urgency") == "high" else 0.3,
            0.8 if context.get("time_constraint") else 0.2,
            0.7 if context.get("priority") == "high" else 0.3,
        ]
        return sum(urgency_factors) / len(urgency_factors)


class BehaviorAnalyzer:
    """í–‰ë™ ë¶„ì„ê¸°"""

    async def analyze_behavior(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """í–‰ë™ ë¶„ì„"""
        try:
            analysis = {
                "patterns": self._identify_patterns(context),
                "efficiency": self._calculate_efficiency(context),
                "adaptability": self._calculate_adaptability(context),
                "learning_rate": self._calculate_learning_rate(context),
            }
            return analysis
        except Exception as e:
            logger.error(f"í–‰ë™ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}

    def _identify_patterns(self, context: Dict[str, Any]) -> List[str]:
        """íŒ¨í„´ ì‹ë³„"""
        patterns = []

        if context.get("systematic_approach"):
            patterns.append("ì²´ê³„ì  ì ‘ê·¼ íŒ¨í„´")

        if context.get("adaptive_behavior"):
            patterns.append("ì ì‘ì  í–‰ë™ íŒ¨í„´")

        if context.get("learning_orientation"):
            patterns.append("í•™ìŠµ ì§€í–¥ íŒ¨í„´")

        return patterns

    def _calculate_efficiency(self, context: Dict[str, Any]) -> float:
        """íš¨ìœ¨ì„± ê³„ì‚°"""
        efficiency_factors = [
            context.get("resource_efficiency", 0.5),
            context.get("time_efficiency", 0.5),
            context.get("process_efficiency", 0.5),
        ]
        return sum(efficiency_factors) / len(efficiency_factors)

    def _calculate_adaptability(self, context: Dict[str, Any]) -> float:
        """ì ì‘ì„± ê³„ì‚°"""
        adaptability_factors = [
            context.get("flexibility", 0.5),
            context.get("responsiveness", 0.5),
            context.get("learning_capacity", 0.5),
        ]
        return sum(adaptability_factors) / len(adaptability_factors)

    def _calculate_learning_rate(self, context: Dict[str, Any]) -> float:
        """í•™ìŠµë¥  ê³„ì‚°"""
        learning_factors = [
            context.get("knowledge_acquisition", 0.5),
            context.get("skill_development", 0.5),
            context.get("experience_integration", 0.5),
        ]
        return sum(learning_factors) / len(learning_factors)


class LearningOptimizer:
    """í•™ìŠµ ìµœì í™”ê¸°"""

    async def optimize_learning(
        self,
        adaptation_result: Dict[str, Any],
        learning_mode: LearningMode,
        clarion_result: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """í•™ìŠµ ìµœì í™” (CLARION ê²°ê³¼ í¬í•¨)"""
        try:
            # ê¸°ë³¸ ìµœì í™” ê³„ì‚°
            base_optimization = {
                "efficiency": self._calculate_learning_efficiency(
                    adaptation_result, learning_mode
                ),
                "speed": self._calculate_learning_speed(
                    adaptation_result, learning_mode
                ),
                "quality": self._calculate_learning_quality(
                    adaptation_result, learning_mode
                ),
                "success_rate": self._calculate_learning_success_rate(
                    adaptation_result, learning_mode
                ),
            }

            # CLARION ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€ ìµœì í™”
            if clarion_result:
                clarion_optimization = self._apply_clarion_optimization(
                    base_optimization, clarion_result
                )
                base_optimization.update(clarion_optimization)

            return base_optimization
        except Exception as e:
            logger.error(f"í•™ìŠµ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {}

    def _calculate_learning_efficiency(
        self, adaptation_result: Dict[str, Any], learning_mode: LearningMode
    ) -> float:
        """í•™ìŠµ íš¨ìœ¨ì„± ê³„ì‚°"""
        base_efficiency = adaptation_result.get("efficiency", 0.5)

        # í•™ìŠµ ëª¨ë“œì— ë”°ë¥¸ íš¨ìœ¨ì„± ì¡°ì •
        mode_multipliers = {
            LearningMode.EXPLORATION: 0.8,  # íƒìƒ‰: íš¨ìœ¨ì„± ë‚®ìŒ
            LearningMode.EXPLOITATION: 1.2,  # í™œìš©: íš¨ìœ¨ì„± ë†’ìŒ
            LearningMode.BALANCED: 1.0,  # ê· í˜•: ê¸°ë³¸ íš¨ìœ¨ì„±
            LearningMode.ADAPTIVE: 1.1,  # ì ì‘: íš¨ìœ¨ì„± ë†’ìŒ
        }

        multiplier = mode_multipliers.get(learning_mode, 1.0)
        return min(base_efficiency * multiplier, 1.0)

    def _calculate_learning_speed(
        self, adaptation_result: Dict[str, Any], learning_mode: LearningMode
    ) -> float:
        """í•™ìŠµ ì†ë„ ê³„ì‚°"""
        base_speed = adaptation_result.get("speed", 0.5)

        # í•™ìŠµ ëª¨ë“œì— ë”°ë¥¸ ì†ë„ ì¡°ì •
        mode_multipliers = {
            LearningMode.EXPLORATION: 0.7,  # íƒìƒ‰: ì†ë„ ëŠë¦¼
            LearningMode.EXPLOITATION: 1.3,  # í™œìš©: ì†ë„ ë¹ ë¦„
            LearningMode.BALANCED: 1.0,  # ê· í˜•: ê¸°ë³¸ ì†ë„
            LearningMode.ADAPTIVE: 1.2,  # ì ì‘: ì†ë„ ë¹ ë¦„
        }

        multiplier = mode_multipliers.get(learning_mode, 1.0)
        return min(base_speed * multiplier, 1.0)

    def _calculate_learning_quality(
        self, adaptation_result: Dict[str, Any], learning_mode: LearningMode
    ) -> float:
        """í•™ìŠµ í’ˆì§ˆ ê³„ì‚°"""
        base_quality = adaptation_result.get("quality", 0.5)

        # í•™ìŠµ ëª¨ë“œì— ë”°ë¥¸ í’ˆì§ˆ ì¡°ì •
        mode_multipliers = {
            LearningMode.EXPLORATION: 0.9,  # íƒìƒ‰: í’ˆì§ˆ ì•½ê°„ ë‚®ìŒ
            LearningMode.EXPLOITATION: 1.1,  # í™œìš©: í’ˆì§ˆ ë†’ìŒ
            LearningMode.BALANCED: 1.0,  # ê· í˜•: ê¸°ë³¸ í’ˆì§ˆ
            LearningMode.ADAPTIVE: 1.05,  # ì ì‘: í’ˆì§ˆ ë†’ìŒ
        }

        multiplier = mode_multipliers.get(learning_mode, 1.0)
        return min(base_quality * multiplier, 1.0)

    def _calculate_learning_success_rate(
        self, adaptation_result: Dict[str, Any], learning_mode: LearningMode
    ) -> float:
        """í•™ìŠµ ì„±ê³µë¥  ê³„ì‚°"""
        base_success = adaptation_result.get("success_rate", 0.5)

        # í•™ìŠµ ëª¨ë“œì— ë”°ë¥¸ ì„±ê³µë¥  ì¡°ì •
        mode_multipliers = {
            LearningMode.EXPLORATION: 0.8,  # íƒìƒ‰: ì„±ê³µë¥  ë‚®ìŒ
            LearningMode.EXPLOITATION: 1.2,  # í™œìš©: ì„±ê³µë¥  ë†’ìŒ
            LearningMode.BALANCED: 1.0,  # ê· í˜•: ê¸°ë³¸ ì„±ê³µë¥ 
            LearningMode.ADAPTIVE: 1.1,  # ì ì‘: ì„±ê³µë¥  ë†’ìŒ
        }

        multiplier = mode_multipliers.get(learning_mode, 1.0)
        return min(base_success * multiplier, 1.0)

    def _apply_clarion_optimization(
        self, base_optimization: Dict[str, Any], clarion_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """CLARION ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¶”ê°€ ìµœì í™”"""
        try:
            clarion_optimization = {}

            # íŒ¨í„´ ê°•ë„ ê¸°ë°˜ íš¨ìœ¨ì„± ë³´ì •
            pattern_strength = clarion_result.get("pattern_strength", 0.5)
            if pattern_strength > 0.7:
                clarion_optimization["pattern_efficiency_boost"] = 0.1
            elif pattern_strength < 0.3:
                clarion_optimization["pattern_efficiency_penalty"] = -0.05

            # í•™ìŠµ ë‹¨ê³„ ê¸°ë°˜ ì†ë„ ì¡°ì •
            learning_phase = clarion_result.get("learning_phase", "acquisition")
            if learning_phase == "consolidation":
                clarion_optimization["consolidation_speed_boost"] = 0.15
            elif learning_phase == "transfer":
                clarion_optimization["transfer_speed_boost"] = 0.2

            # ì „ì´ ëŠ¥ë ¥ ê¸°ë°˜ í’ˆì§ˆ í–¥ìƒ
            transfer_ability = clarion_result.get("transfer_ability", 0.0)
            if transfer_ability > 0.6:
                clarion_optimization["transfer_quality_boost"] = 0.1

            # ê°•í™” ìœ í˜• ê¸°ë°˜ ì„±ê³µë¥  ì¡°ì •
            reinforcement_type = clarion_result.get("reinforcement_type", "neutral")
            if reinforcement_type == "positive":
                clarion_optimization["positive_reinforcement_boost"] = 0.05
            elif reinforcement_type == "negative":
                clarion_optimization["negative_reinforcement_penalty"] = -0.03

            return clarion_optimization

        except Exception as e:
            logger.error(f"CLARION ìµœì í™” ì ìš© ì‹¤íŒ¨: {e}")
            return {}


class AdaptationEngine:
    """ì ì‘ ì—”ì§„"""

    async def execute_adaptation(
        self, context: Dict[str, Any], adaptation_strategy: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì ì‘ ì‹¤í–‰"""
        try:
            adaptation_type = adaptation_strategy.get(
                "type", AdaptationType.ENVIRONMENTAL
            )
            learning_mode = adaptation_strategy.get(
                "learning_mode", LearningMode.BALANCED
            )

            # ì ì‘ ì‹¤í–‰
            if adaptation_type == AdaptationType.ENVIRONMENTAL:
                result = await self._execute_environmental_adaptation(
                    context, adaptation_strategy
                )
            elif adaptation_type == AdaptationType.BEHAVIORAL:
                result = await self._execute_behavioral_adaptation(
                    context, adaptation_strategy
                )
            elif adaptation_type == AdaptationType.COGNITIVE:
                result = await self._execute_cognitive_adaptation(
                    context, adaptation_strategy
                )
            else:
                result = await self._execute_general_adaptation(
                    context, adaptation_strategy
                )

            return result

        except Exception as e:
            logger.error(f"ì ì‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success_rate": 0.5,
                "speed": 0.5,
                "efficiency": 0.5,
                "quality": 0.5,
                "behavioral_changes": [],
                "change_response": 0.5,
                "behavior_change": 0.5,
            }

    async def _execute_environmental_adaptation(
        self, context: Dict[str, Any], strategy: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í™˜ê²½ ì ì‘ ì‹¤í–‰"""
        try:
            # í™˜ê²½ ë³€í™”ì— ëŒ€í•œ ì ì‘
            changes = ["í™˜ê²½ ëª¨ë‹ˆí„°ë§ ê°•í™”", "ì ì‘ì  ì „ëµ ìˆ˜ë¦½", "ë™ì  ëŒ€ì‘ ì²´ê³„ êµ¬ì¶•"]

            return {
                "success_rate": 0.8,
                "speed": strategy.get("adaptation_speed", 0.5),
                "efficiency": 0.7,
                "quality": 0.8,
                "behavioral_changes": changes,
                "change_response": 0.8,
                "behavior_change": 0.7,
            }

        except Exception as e:
            logger.error(f"í™˜ê²½ ì ì‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success_rate": 0.5,
                "speed": 0.5,
                "efficiency": 0.5,
                "quality": 0.5,
                "behavioral_changes": [],
                "change_response": 0.5,
                "behavior_change": 0.5,
            }

    async def _execute_behavioral_adaptation(
        self, context: Dict[str, Any], strategy: Dict[str, Any]
    ) -> Dict[str, Any]:
        """í–‰ë™ ì ì‘ ì‹¤í–‰"""
        try:
            # í–‰ë™ íŒ¨í„´ ì ì‘
            changes = ["í–‰ë™ íŒ¨í„´ ë¶„ì„", "íš¨ìœ¨ì  í–‰ë™ ëª¨ë¸ ì ìš©", "í•™ìŠµ ê¸°ë°˜ í–‰ë™ ê°œì„ "]

            return {
                "success_rate": 0.75,
                "speed": strategy.get("adaptation_speed", 0.5),
                "efficiency": 0.8,
                "quality": 0.75,
                "behavioral_changes": changes,
                "change_response": 0.75,
                "behavior_change": 0.8,
            }

        except Exception as e:
            logger.error(f"í–‰ë™ ì ì‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success_rate": 0.5,
                "speed": 0.5,
                "efficiency": 0.5,
                "quality": 0.5,
                "behavioral_changes": [],
                "change_response": 0.5,
                "behavior_change": 0.5,
            }

    async def _execute_cognitive_adaptation(
        self, context: Dict[str, Any], strategy: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¸ì§€ ì ì‘ ì‹¤í–‰"""
        try:
            # ì¸ì§€ì  ì ì‘
            changes = ["ì¸ì§€ ëª¨ë¸ ì—…ë°ì´íŠ¸", "í•™ìŠµ íŒ¨í„´ ìµœì í™”", "ì§€ì‹ êµ¬ì¡° ì¬êµ¬ì„±"]

            return {
                "success_rate": 0.7,
                "speed": strategy.get("adaptation_speed", 0.5),
                "efficiency": 0.75,
                "quality": 0.8,
                "behavioral_changes": changes,
                "change_response": 0.7,
                "behavior_change": 0.75,
            }

        except Exception as e:
            logger.error(f"ì¸ì§€ ì ì‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success_rate": 0.5,
                "speed": 0.5,
                "efficiency": 0.5,
                "quality": 0.5,
                "behavioral_changes": [],
                "change_response": 0.5,
                "behavior_change": 0.5,
            }

    async def _execute_general_adaptation(
        self, context: Dict[str, Any], strategy: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì¼ë°˜ ì ì‘ ì‹¤í–‰"""
        try:
            # ì¼ë°˜ì  ì ì‘
            changes = ["ì „ë°˜ì  ì ì‘ ì „ëµ ì ìš©", "ê· í˜•ì¡íŒ ê°œì„ ", "ì§€ì†ì  ëª¨ë‹ˆí„°ë§"]

            return {
                "success_rate": 0.65,
                "speed": strategy.get("adaptation_speed", 0.5),
                "efficiency": 0.7,
                "quality": 0.7,
                "behavioral_changes": changes,
                "change_response": 0.65,
                "behavior_change": 0.7,
            }

        except Exception as e:
            logger.error(f"ì¼ë°˜ ì ì‘ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return {
                "success_rate": 0.5,
                "speed": 0.5,
                "efficiency": 0.5,
                "quality": 0.5,
                "behavioral_changes": [],
                "change_response": 0.5,
                "behavior_change": 0.5,
            }


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logger.info("ğŸš€ DuRiCore Phase 5.5.3 ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ ìƒì„±
    adaptive_learning_system = AdaptiveLearningSystem()

    # í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸
    test_context = {
        "complexity": "high",
        "urgency": "medium",
        "resource_limitation": True,
        "technology_change": True,
        "systematic_approach": True,
        "adaptive_behavior": True,
        "learning_orientation": True,
        "flexibility": 0.7,
        "responsiveness": 0.8,
        "learning_capacity": 0.75,
    }

    # ì ì‘ ì‹¤í–‰
    adaptation_result = await adaptive_learning_system.adapt_to_environment(
        test_context
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\n=== ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    print(f"ì ì‘ ìœ í˜•: {adaptation_result.adaptation_type.value}")
    print(f"í•™ìŠµ ëª¨ë“œ: {adaptation_result.learning_mode.value}")
    print(f"ì ì‘ ì ìˆ˜: {adaptation_result.adaptation_score:.2f}")
    print(f"í•™ìŠµ íš¨ìœ¨ì„±: {adaptation_result.learning_efficiency:.2f}")
    print(f"ì ì‘ ì†ë„: {adaptation_result.adaptation_speed:.2f}")
    print(f"ì„±ê³µë¥ : {adaptation_result.success_rate:.2f}")
    print(f"í™˜ê²½ ë³€í™”: {adaptation_result.environment_changes}")
    print(f"í–‰ë™ ë³€í™”: {adaptation_result.behavioral_changes}")

    if adaptation_result.success:
        print("âœ… ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
    else:
        print("âŒ ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

    # ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
    status = await adaptive_learning_system.get_system_status()
    print(f"\nì‹œìŠ¤í…œ ìƒíƒœ: {status}")


if __name__ == "__main__":
    asyncio.run(main())
